{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-29T19:36:44.847344Z",
     "iopub.status.busy": "2025-10-29T19:36:44.846823Z",
     "iopub.status.idle": "2025-10-29T19:36:45.042473Z",
     "shell.execute_reply": "2025-10-29T19:36:45.041800Z",
     "shell.execute_reply.started": "2025-10-29T19:36:44.847323Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Credentials written to: /root/.kaggle/kaggle.json\n",
      "total 16\n",
      "drwxr-xr-x 2 root root 4096 Oct 29 19:36 .\n",
      "drwx------ 1 root root 4096 Oct 29 19:36 ..\n",
      "-rw------- 1 root root   72 Oct 29 19:36 kaggle.json\n"
     ]
    }
   ],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import json, os, pathlib, subprocess, sys\n",
    "\n",
    "# --- 1. Load your secret (full JSON from kaggle.json) ---\n",
    "secret_name = \"kaggle_json\"  # change if you used another name\n",
    "user_secrets = UserSecretsClient()\n",
    "raw = user_secrets.get_secret(secret_name)\n",
    "creds = json.loads(raw)\n",
    "\n",
    "# --- 2. Forcefully recreate ~/.kaggle/kaggle.json ---\n",
    "kaggle_dir = pathlib.Path.home() / \".kaggle\"\n",
    "kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
    "cred_path = kaggle_dir / \"kaggle.json\"\n",
    "cred_path.write_text(json.dumps(creds))\n",
    "os.chmod(cred_path, 0o600)\n",
    "\n",
    "# --- 3. Double-check the file actually exists and is readable ---\n",
    "print(\"✅ Credentials written to:\", cred_path)\n",
    "!ls -la ~/.kaggle/\n",
    "#!cat ~/.kaggle/kaggle.json | head -1\n",
    "\n",
    "# --- 4. Reinstall Kaggle CLI cleanly ---\n",
    "#!pip install --upgrade --force-reinstall kaggle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T19:42:50.595475Z",
     "iopub.status.busy": "2025-10-29T19:42:50.594899Z",
     "iopub.status.idle": "2025-10-29T19:43:59.032875Z",
     "shell.execute_reply": "2025-10-29T19:43:59.031742Z",
     "shell.execute_reply.started": "2025-10-29T19:42:50.595425Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!kaggle competitions files -c aml-competition\n",
    "!kaggle competitions download -c aml-competition -p /kaggle/working --force\n",
    "!mkdir -p /kaggle/working/data\n",
    "!unzip -o /kaggle/working/aml-competition.zip -d /kaggle/working/data\n",
    "!ls -lah /kaggle/working/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T19:37:58.573402Z",
     "iopub.status.busy": "2025-10-29T19:37:58.573086Z",
     "iopub.status.idle": "2025-10-29T19:37:58.693289Z",
     "shell.execute_reply": "2025-10-29T19:37:58.692355Z",
     "shell.execute_reply.started": "2025-10-29T19:37:58.573369Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'challenge' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Mamiglia/challenge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T19:44:11.279324Z",
     "iopub.status.busy": "2025-10-29T19:44:11.278737Z",
     "iopub.status.idle": "2025-10-29T19:44:13.415509Z",
     "shell.execute_reply": "2025-10-29T19:44:13.414691Z",
     "shell.execute_reply.started": "2025-10-29T19:44:11.279285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# runner.py\n",
    "import argparse, json, random, re, time\n",
    "from pathlib import Path\n",
    "from os.path import basename\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from challenge.src.common import load_data, generate_submission\n",
    "\n",
    "# ---------- Paths ----------\n",
    "DATA_ROOT = Path(\"/kaggle/working/data\")\n",
    "TRAIN_DIR = DATA_ROOT / \"train\" / \"train\"\n",
    "TEST_DIR  = DATA_ROOT / \"test\"  / \"test\"\n",
    "TRAIN_NPZ = TRAIN_DIR / \"train.npz\"\n",
    "TEST_NPZ  = TEST_DIR  / \"test.clean.npz\"\n",
    "TRAIN_CAPTIONS = TRAIN_DIR / \"captions.txt\"\n",
    "TEST_CAPTIONS  = TEST_DIR  / \"captions.txt\"\n",
    "\n",
    "# ---------- Determinism ----------\n",
    "def seed_all(s: int):\n",
    "    random.seed(s); np.random.seed(s)\n",
    "    torch.manual_seed(s); torch.cuda.manual_seed_all(s)\n",
    "    torch.backends.cudnn.deterministic=True; torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# ---------- Metadata/safety ----------\n",
    "def _assert_metadata_dims(npz_path: Path, expect_text=1024, expect_img=1536):\n",
    "    d = np.load(npz_path, allow_pickle=True)\n",
    "    md = {k: d[k][0] for k in d.files if k.startswith(\"metadata/\")}\n",
    "    tdim = md.get(\"metadata/embedding_dim_text\", None)\n",
    "    idim = md.get(\"metadata/embedding_dim_image\", None)\n",
    "    print(f\"[meta] text_dim={tdim} | image_dim={idim}\")\n",
    "    assert tdim == expect_text and idim == expect_img, (\n",
    "        f\"Encoder dims mismatch: expected text={expect_text}, image={expect_img} \"\n",
    "        f\"but got text={tdim}, image={idim}. Regenerate NPZ with the fixed encoders.\"\n",
    "    )\n",
    "\n",
    "# ---------- Caption→image matching from captions.txt ----------\n",
    "def _build_image_index(image_ids):\n",
    "    idx_exact = {}; idx_base={}; idx_stem={}\n",
    "    for i, v in enumerate(image_ids):\n",
    "        s = str(v); idx_exact[s]=i\n",
    "        b = basename(s); idx_base[b]=i\n",
    "        stem = b.rsplit(\".\",1)[0] if \".\" in b else b\n",
    "        idx_stem[stem]=i\n",
    "    return idx_exact, idx_base, idx_stem\n",
    "\n",
    "def _iter_targets_from_captions(path: Path, n_text: int, idx_exact, idx_base, idx_stem):\n",
    "    targets=[]\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for raw in f:\n",
    "            if len(targets)>=n_text: break\n",
    "            line=raw.strip()\n",
    "            if not line: continue\n",
    "            # be robust to delimiters\n",
    "            parts=re.split(r'\\||\\t|,| {2,}', line)\n",
    "            if len(parts)==1: parts=line.split(\" \",1)\n",
    "            tok=parts[0].strip().strip('\"').strip(\"'\")\n",
    "            if not tok: continue\n",
    "            def _match(tok_):\n",
    "                if tok_ in idx_exact: return idx_exact[tok_]\n",
    "                b=basename(tok_)\n",
    "                if b in idx_base: return idx_base[b]\n",
    "                stem=b.rsplit(\".\",1)[0] if \".\" in b else b\n",
    "                if stem in idx_stem: return idx_stem[stem]\n",
    "                return None\n",
    "            idx=_match(tok)\n",
    "            if idx is None:\n",
    "                tok2=tok.replace(\"Images/\",\"\").replace(\"./\",\"\")\n",
    "                idx=_match(tok2)\n",
    "            if idx is None:\n",
    "                if \".\" not in tok: continue\n",
    "                raise AssertionError(f\"Could not match image token '{tok}'\")\n",
    "            targets.append(idx)\n",
    "    assert len(targets)==n_text, f\"matched {len(targets)} vs N_text {n_text}\"\n",
    "    return np.asarray(targets, dtype=np.int64)\n",
    "\n",
    "# ---------- Data loaders ----------\n",
    "def load_train(out_dir: Path):\n",
    "    _assert_metadata_dims(TRAIN_NPZ, 1024, 1536)\n",
    "    d=np.load(TRAIN_NPZ, allow_pickle=True)\n",
    "    X=d[\"captions/embeddings\"].astype(np.float32)  # (N_text,1024)\n",
    "    I=d[\"images/embeddings\"].astype(np.float32)    # (N_img,1536)\n",
    "    cap_ids=d.get(\"captions/ids\", np.arange(len(X)).astype(str))\n",
    "    img_names=d.get(\"images/names\", np.arange(len(I)).astype(str))\n",
    "\n",
    "    ex,ba,st=_build_image_index(img_names)\n",
    "    assert TRAIN_CAPTIONS.exists(), f\"Missing {TRAIN_CAPTIONS}\"\n",
    "    targets=_iter_targets_from_captions(TRAIN_CAPTIONS, len(X), ex,ba,st)\n",
    "\n",
    "    Y=I[targets]                       # (N_text, 1536) GT image vec per caption\n",
    "    img_ids_row = img_names[targets]   # image name per caption row (for splitting)\n",
    "    meta={\"n_text\":int(len(X)),\"n_images\":int(len(I))}\n",
    "    (out_dir/\"train_detect.json\").write_text(json.dumps(meta, indent=2))\n",
    "    return X,Y,cap_ids,img_ids_row,I,img_names\n",
    "\n",
    "def load_test_npz():\n",
    "    d_test=np.load(TEST_NPZ, allow_pickle=True)\n",
    "    Q=d_test[\"captions/embeddings\"].astype(np.float32)\n",
    "    q_ids=d_test.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n",
    "    if \"images/embeddings\" in d_test.files:\n",
    "        G=d_test[\"images/embeddings\"].astype(np.float32)\n",
    "        g_ids=d_test.get(\"images/names\", np.arange(len(G)).astype(str))\n",
    "    else:\n",
    "        d_tr=np.load(TRAIN_NPZ, allow_pickle=True)\n",
    "        G=d_tr[\"images/embeddings\"].astype(np.float32)\n",
    "        g_ids=d_tr.get(\"images/names\", np.arange(len(G)).astype(str))\n",
    "    return Q,G,q_ids,g_ids\n",
    "\n",
    "# ---------- Dataset ----------\n",
    "class PairDS(Dataset):\n",
    "    def __init__(self, X, Y): self.X=torch.from_numpy(X); self.Y=torch.from_numpy(Y)\n",
    "    def __len__(self): return self.X.shape[0]\n",
    "    def __getitem__(self, i): return self.X[i], self.Y[i]\n",
    "\n",
    "# ---------- Pooling (no-op per spec) ----------\n",
    "def apply_pooling(x: torch.Tensor, mode: str, n_patches=None):\n",
    "    return x\n",
    "\n",
    "# ---------- Base Models ----------\n",
    "class LinearProj(nn.Module):\n",
    "    def __init__(self, din, dout):\n",
    "        super().__init__()\n",
    "        self.fc=nn.Linear(din,dout)\n",
    "        nn.init.xavier_normal_(self.fc.weight); nn.init.zeros_(self.fc.bias)\n",
    "    def forward(self,x): return self.fc(x)\n",
    "\n",
    "class MLP1(nn.Module):\n",
    "    def __init__(self, din, dout, hidden=512, pdrop=0.1):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(din,hidden), nn.ReLU(), nn.Dropout(pdrop),\n",
    "            nn.Linear(hidden,dout)\n",
    "        )\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class MLP2(nn.Module):\n",
    "    # Spec: 1024→1024→512→1536, dropout=0.1 on hidden layers\n",
    "    def __init__(self, din, dout, h1=1024, h2=512, pdrop=0.1):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(din,h1), nn.ReLU(), nn.Dropout(pdrop),\n",
    "            nn.Linear(h1,h2), nn.ReLU(), nn.Dropout(pdrop),\n",
    "            nn.Linear(h2,dout)\n",
    "        )\n",
    "        for m in self.net:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "# ---------- Geometry-Preserving Linear (Whiten → Procrustes → Re-color) ----------\n",
    "def _cov_eigh(zc, eps):\n",
    "    # zc: (N,D), zero-mean\n",
    "    N = zc.shape[0]\n",
    "    C = (zc.T @ zc) / max(1, N)\n",
    "    # symmetric PSD\n",
    "    S, U = np.linalg.eigh(C)\n",
    "    S = np.clip(S, 0.0, None)\n",
    "    inv_sqrt = 1.0 / np.sqrt(S + eps)\n",
    "    sqrt = np.sqrt(S + eps)\n",
    "    C_mhalf = (U * inv_sqrt) @ U.T     # C^{-1/2}\n",
    "    C_phalf = (U * sqrt) @ U.T         # C^{ 1/2}\n",
    "    return C_mhalf.astype(np.float32), C_phalf.astype(np.float32)\n",
    "\n",
    "def procrustes_closed_form(X, Y, eps=1e-5):\n",
    "    \"\"\"\n",
    "    X: (N, 1024) text, Y: (N, 1536) targets (per-caption image vectors)\n",
    "    Returns A (1536x1024), b (1536,) such that y_hat = A x + b\n",
    "    \"\"\"\n",
    "    # center\n",
    "    mu_x = X.mean(0, dtype=np.float64)\n",
    "    mu_y = Y.mean(0, dtype=np.float64)\n",
    "    Xc = X - mu_x\n",
    "    Yc = Y - mu_y\n",
    "\n",
    "    # whiten both\n",
    "    Cx_mh, _ = _cov_eigh(Xc, eps)      # 1024x1024\n",
    "    Cy_mh, Cy_ph = _cov_eigh(Yc, eps)  # 1536x1536 (only Cy_ph used)\n",
    "    Xw = Xc @ Cx_mh.T                  # (N,1024)\n",
    "    Yw = Yc @ Cy_mh.T                  # (N,1536)\n",
    "\n",
    "    # orthogonal Procrustes: maximize Tr(R^T Xw^T Yw)\n",
    "    M = Xw.T @ Yw                      # (1024,1536)\n",
    "    # SVD on M; for rectangular, do SVD and build R = U V^T in common subspace\n",
    "    U, _, Vt = np.linalg.svd(M, full_matrices=False)\n",
    "    R = U @ Vt                         # (1024,1536) @ (1536,1536) -> (1024,1536) OK since full_matrices=False\n",
    "    # we need R as (1536x1024) mapping whitened X to whitened Y; above is (1024x1536)\n",
    "    R = R.T                            # (1536,1024)\n",
    "\n",
    "    # re-color to Y space\n",
    "    A = (Cy_ph @ R @ Cx_mh).astype(np.float32)     # (1536,1536)*(1536,1024)*(1024,1024) = (1536,1024)\n",
    "    b = (mu_y - (A @ mu_x)).astype(np.float32)     # (1536,)\n",
    "    return A, b\n",
    "\n",
    "class GeomLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    Linear layer with weights initialized from closed-form geometry mapping.\n",
    "    Optionally fine-tunes with tiny LR.\n",
    "    \"\"\"\n",
    "    def __init__(self, A: np.ndarray, b: np.ndarray):\n",
    "        super().__init__()\n",
    "        D_in = A.shape[1]; D_out = A.shape[0]\n",
    "        self.fc = nn.Linear(D_in, D_out, bias=True)\n",
    "        with torch.no_grad():\n",
    "            self.fc.weight.copy_(torch.from_numpy(A))\n",
    "            self.fc.bias.copy_(torch.from_numpy(b))\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# ---------- Loss pieces (for optional fine-tune) ----------\n",
    "def moment_align(pred, tgt):\n",
    "    mu_p, mu_t = pred.mean(0), tgt.mean(0)\n",
    "    sd_p, sd_t = pred.std(0, unbiased=False), tgt.std(0, unbiased=False)\n",
    "    return F.mse_loss(mu_p, mu_t) + F.mse_loss(sd_p, sd_t)\n",
    "\n",
    "def info_nce(pred, tgt):\n",
    "    p = F.normalize(pred, dim=-1)\n",
    "    t = F.normalize(tgt, dim=-1)\n",
    "    logits = p @ t.t()\n",
    "    labels = torch.arange(pred.size(0), device=pred.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "# ---------- Split by image id & mapping ----------\n",
    "def build_image_id_split(img_ids_row, all_img_names, full_img, X, Y, val_ratio, seed, out_dir: Path):\n",
    "    uniq_img_names = np.array(sorted(set(map(str, all_img_names))))\n",
    "    rng = np.random.default_rng(seed); rng.shuffle(uniq_img_names)\n",
    "    n_val = max(1, int(len(uniq_img_names) * val_ratio))\n",
    "    val_images = set(uniq_img_names[:n_val])\n",
    "    tr_images  = set(uniq_img_names[n_val:])\n",
    "    assert len(val_images & tr_images) == 0, \"Leakage in image id split!\"\n",
    "\n",
    "    # Caption masks\n",
    "    cap_is_val = np.array([str(iid) in val_images for iid in img_ids_row], dtype=bool)\n",
    "    cap_is_tr  = ~cap_is_val\n",
    "\n",
    "    # Build VAL gallery (unique images in VAL) as sorted names → local indices\n",
    "    val_img_names_sorted = np.array(sorted(val_images))\n",
    "    name2local = {name:i for i,name in enumerate(val_img_names_sorted)}\n",
    "    name2global = {str(n):i for i,n in enumerate(all_img_names)}\n",
    "    val_img_indices = np.array([name2global[n] for n in val_img_names_sorted], dtype=np.int64)\n",
    "    val_gallery = full_img[val_img_indices]  # (M,1536)\n",
    "\n",
    "    # For each VAL caption row, get local gallery index (no remap later)\n",
    "    cap2gal_local = np.array([name2local[str(n)] for n in img_ids_row[cap_is_val]], dtype=np.int64)\n",
    "\n",
    "    # Persist mapping for debugging/acceptance\n",
    "    (out_dir/\"val_indices.json\").write_text(json.dumps({\n",
    "        \"val_img_indices\": val_img_indices.tolist(),\n",
    "        \"val_caption_to_gallery_index\": cap2gal_local.tolist(),\n",
    "        \"n_val_captions\": int(cap_is_val.sum()),\n",
    "        \"n_val_unique_images\": int(len(val_images))\n",
    "    }, indent=2))\n",
    "\n",
    "    return cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices\n",
    "\n",
    "# ---------- Metrics / evaluator (full gallery, cosine on L2) ----------\n",
    "@torch.no_grad()\n",
    "def validate_retrieval(model, Xv, val_gallery, cap2gal_local, pooling, n_patches, bs=1024):\n",
    "    device=next(model.parameters()).device\n",
    "    Gi = torch.from_numpy(val_gallery).to(device)\n",
    "    Gi = F.normalize(Gi, dim=-1)\n",
    "\n",
    "    ranks=[]\n",
    "    for i in range(0, len(Xv), bs):\n",
    "        xb=torch.from_numpy(Xv[i:i+bs]).to(device)\n",
    "        xb=apply_pooling(xb, pooling, n_patches)   # no-op\n",
    "        pred=model(xb)\n",
    "        pred=F.normalize(pred, dim=-1)\n",
    "        sims=pred @ Gi.t()                         # (b, M)\n",
    "        for j in range(sims.size(0)):\n",
    "            true_idx = int(cap2gal_local[i+j])     # local gallery index\n",
    "            order = torch.argsort(sims[j], descending=True)\n",
    "            rank = (order==true_idx).nonzero(as_tuple=False).item() + 1\n",
    "            ranks.append(rank)\n",
    "\n",
    "    ranks = np.array(ranks)\n",
    "    mrr = float(np.mean(1.0 / ranks))\n",
    "    r1  = float(np.mean(ranks<=1))\n",
    "    r5  = float(np.mean(ranks<=5))\n",
    "    r10 = float(np.mean(ranks<=10))\n",
    "    return {\n",
    "        \"MRR\": mrr,\n",
    "        \"R1\": r1,\n",
    "        \"R5\": r5,\n",
    "        \"R10\": r10,\n",
    "        \"rank_median\": int(np.median(ranks)),\n",
    "        \"rank_p75\": int(np.percentile(ranks, 75))\n",
    "    }\n",
    "\n",
    "def count_params_mb(model):\n",
    "    params=sum(p.numel() for p in model.parameters())\n",
    "    mb = params * 4 / (1024**2)\n",
    "    return params, mb\n",
    "\n",
    "def time_ms_per_query(model, din, pooling, n_patches):\n",
    "    device=next(model.parameters()).device\n",
    "    x=torch.randn(2048, din, device=device)\n",
    "    x=apply_pooling(x, pooling, n_patches)\n",
    "    if device.type==\"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    t0=time.time()\n",
    "    with torch.no_grad(): _=model(x)\n",
    "    if device.type==\"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "    ms_gpu=(time.time()-t0)*1000/len(x)\n",
    "    # CPU\n",
    "    mcpu=model.to(\"cpu\"); xcpu=x.to(\"cpu\")\n",
    "    t1=time.time()\n",
    "    with torch.no_grad(): _=mcpu(xcpu)\n",
    "    ms_cpu=(time.time()-t1)*1000/len(xcpu)\n",
    "    model.to(device)\n",
    "    return ms_gpu, ms_cpu\n",
    "\n",
    "# ---------- Train (for optional fine-tune) ----------\n",
    "def train_one(model, loader, opt, alpha, beta, gamma, moment_w, pooling, n_patches, device):\n",
    "    model.train(); total=0.0\n",
    "    for xb,yb in loader:\n",
    "        xb,yb=xb.to(device), yb.to(device)\n",
    "        xb=apply_pooling(xb, pooling, n_patches)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        pred=model(xb)\n",
    "        # α·(1−cos) + β·MSE + λ·moment_align + γ·InfoNCE\n",
    "        cos = 1 - F.cosine_similarity(pred, yb, dim=-1).mean()\n",
    "        mse = F.mse_loss(pred, yb)\n",
    "        a_loss = moment_w * moment_align(pred, yb) if moment_w>0 else pred.new_tensor(0.0)\n",
    "        ce = info_nce(pred, yb) if gamma>0 else pred.new_tensor(0.0)\n",
    "        loss = alpha*cos + beta*mse + gamma*ce + a_loss\n",
    "        loss.backward(); opt.step()\n",
    "        total += loss.item()*xb.size(0)\n",
    "    return total/len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captions: 125k, Images: 25k ⇒ exactly 5 captions/image (125k / 25k = 5).\n",
    "\n",
    "Train: 112,500 captions over 22,500 images; Val: 12,500 captions over 2,500 images. Clean 90/10 split by unique image ids → good for avoiding leakage. \n",
    "\n",
    "Each listed image shows count = 5. Since all images have 5 captions, there’s no frequency skew in this dataset. Good news: balanced multi-caption coverage.\n",
    "\n",
    "sampling is effectively uniform over images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can safely skip the frequency-aware sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:22.345857Z",
     "iopub.status.busy": "2025-10-29T21:58:22.345520Z",
     "iopub.status.idle": "2025-10-29T21:58:22.359326Z",
     "shell.execute_reply": "2025-10-29T21:58:22.358534Z",
     "shell.execute_reply.started": "2025-10-29T21:58:22.345832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- Residual Adapter + Geom (with Orthogonalization) ----------\n",
    "class ResidualAdapter(nn.Module):\n",
    "    def __init__(self, din=1024, hidden=1024, dout=1536, pdrop=0.1, init_scale=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(din, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, dout)\n",
    "        self.drop = nn.Dropout(pdrop)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, nonlinearity='relu')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        with torch.no_grad():\n",
    "            self.fc1.weight.mul_(init_scale)\n",
    "            self.fc2.weight.mul_(init_scale)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = self.drop(h)\n",
    "        return self.fc2(h)\n",
    "\n",
    "\n",
    "class GeomWithAdapter(nn.Module):\n",
    "    \"\"\"\n",
    "    y_hat = GeomLinear(x) (+ optionally trainable) + Residual(x),\n",
    "    where Residual can be *projected* to the orthogonal complement of span(A) or *penalized* to be orthogonal.\n",
    "\n",
    "    residual_ortho: \"project\" | \"penalty\" | \"none\"\n",
    "    ortho_eps: ridge for projector\n",
    "    ortho_lambda: weight for penalty (if residual_ortho == \"penalty\")\n",
    "    unfreeze_bias: whether to unfreeze geom bias together with weight\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, A: np.ndarray, b: np.ndarray,\n",
    "        din=1024, dout=1536, hidden=1024, pdrop=0.1,\n",
    "        residual_ortho: str = \"project\",\n",
    "        ortho_eps: float = 1e-4,\n",
    "        ortho_lambda: float = 0.05,\n",
    "        unfreeze_bias: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.geom = GeomLinear(A, b)\n",
    "        self.adapter = ResidualAdapter(din=din, hidden=hidden, dout=dout, pdrop=pdrop)\n",
    "\n",
    "        # default: freeze geom at start; training loop may unfreeze weight later\n",
    "        for p in self.geom.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # orthogonalization config\n",
    "        assert residual_ortho in (\"project\", \"penalty\", \"none\")\n",
    "        self.residual_ortho = residual_ortho\n",
    "        self.ortho_lambda = float(ortho_lambda)\n",
    "        self.ortho = ResidualOrthogonalizer(eps=float(ortho_eps))\n",
    "        self._unfreeze_bias = bool(unfreeze_bias)\n",
    "\n",
    "    def unfreeze_geom(self, weight_lr_scale=0.05):\n",
    "        # In training we set per-parameter LRs in the optimizer; here just set requires_grad flags.\n",
    "        self.geom.fc.weight.requires_grad = True\n",
    "        if self._unfreeze_bias:\n",
    "            self.geom.fc.bias.requires_grad = True\n",
    "\n",
    "    def forward(self, x, return_ortho_penalty: bool = False):\n",
    "        \"\"\"\n",
    "        If residual_ortho == \"project\": returns (yhat, 0.0) with hard projection (autocast OFF inside).\n",
    "        If residual_ortho == \"penalty\": returns (yhat, penalty_scalar).\n",
    "        If residual_ortho == \"none\": returns (yhat, 0.0).\n",
    "        \"\"\"\n",
    "        g = self.geom(x)               # (B,1536)\n",
    "        r = self.adapter(x)            # (B,1536)\n",
    "\n",
    "        penalty = None\n",
    "        if self.residual_ortho == \"project\":\n",
    "            # Hard projection of residual into orth complement of span(A) in float32, autocast OFF\n",
    "            A = self.geom.fc.weight     # (1536,1024)\n",
    "            device_type = \"cuda\" if g.device.type == \"cuda\" else \"cpu\"\n",
    "            with torch.autocast(device_type=device_type, enabled=False):\n",
    "                r = self.ortho.project_residual(r, A)\n",
    "            y = g + r\n",
    "            penalty = r.new_tensor(0.0)\n",
    "\n",
    "        elif self.residual_ortho == \"penalty\":\n",
    "            # Soft orthogonality: mean squared cosine between normalized parts\n",
    "            g_n = F.normalize(g, dim=-1)\n",
    "            r_n = F.normalize(r, dim=-1)\n",
    "            dot = torch.sum(g_n * r_n, dim=-1)  # (B,)\n",
    "            penalty = torch.mean(dot * dot)\n",
    "            y = g + r\n",
    "\n",
    "        else:  # \"none\"\n",
    "            y = g + r\n",
    "            penalty = r.new_tensor(0.0)\n",
    "\n",
    "        if return_ortho_penalty:\n",
    "            return y, penalty\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:27.598132Z",
     "iopub.status.busy": "2025-10-29T21:58:27.597322Z",
     "iopub.status.idle": "2025-10-29T21:58:27.608199Z",
     "shell.execute_reply": "2025-10-29T21:58:27.607513Z",
     "shell.execute_reply.started": "2025-10-29T21:58:27.598105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- Residual Orthogonalization Utilities (AMP- & device-safe) ----------\n",
    "class ResidualOrthogonalizer:\n",
    "    \"\"\"\n",
    "    Projects residuals onto the orthogonal complement of span(A) safely under AMP and across devices.\n",
    "\n",
    "    Math (done in float32, autocast OFF):\n",
    "      G = A^T A + eps I   (1024x1024)\n",
    "      invG = G^{-1}       (or cholesky/pinv fallback)\n",
    "      Proj_col(A)(R) = ((R @ A) @ invG) @ A^T\n",
    "      (I - P_A)R = R - Proj_col(A)(R)\n",
    "\n",
    "    We cache invG per A-hash; at use, we always move invG to A.device to avoid CPU/GPU mismatches.\n",
    "    \"\"\"\n",
    "    def __init__(self, eps: float = 1e-4, device: torch.device | None = None):\n",
    "        self.eps = float(eps)\n",
    "        self.device = device\n",
    "        self._cached_invG = None\n",
    "        self._cached_A_hash = None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _hash_weight(self, A: torch.Tensor) -> tuple[int, int]:\n",
    "        h = (A.shape[0], A.shape[1])\n",
    "        sample = A.reshape(-1)[:1024] if A.numel() >= 1024 else A.reshape(-1)\n",
    "        checksum = int(torch.sum((sample.float() * 1e3).round()).item())\n",
    "        return (h[0] * 10_000 + h[1], checksum)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def refresh(self, A: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Ensure invG (float32) is up to date for current A.\n",
    "        Always computes with autocast DISABLED and in float32.\n",
    "        Caches on A.device.\n",
    "        \"\"\"\n",
    "        dev = A.device\n",
    "        device_type = \"cuda\" if dev.type == \"cuda\" else \"cpu\"\n",
    "        with torch.autocast(device_type=device_type, enabled=False):\n",
    "            A32 = A.detach().to(dev, dtype=torch.float32)\n",
    "            key = self._hash_weight(A32)\n",
    "            # If cache hit AND cached tensor already on the right device, reuse\n",
    "            if key == self._cached_A_hash and self._cached_invG is not None and self._cached_invG.device == dev:\n",
    "                return\n",
    "\n",
    "            G = A32.transpose(0, 1) @ A32\n",
    "            G = G + self.eps * torch.eye(G.shape[0], device=dev, dtype=torch.float32)\n",
    "            try:\n",
    "                L = torch.linalg.cholesky(G)\n",
    "                invG = torch.cholesky_inverse(L)\n",
    "            except RuntimeError:\n",
    "                try:\n",
    "                    invG = torch.linalg.inv(G)\n",
    "                except RuntimeError:\n",
    "                    invG = torch.linalg.pinv(G)\n",
    "\n",
    "            self._cached_invG = invG   # stored on A.device\n",
    "            self._cached_A_hash = key\n",
    "\n",
    "    def project_residual(self, R: torch.Tensor, A: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Return (I - P_A) R. Autocast OFF inside, math in float32, cast back to R.dtype at end.\n",
    "        Ensures invG and all operands are on the SAME device as A/R.\n",
    "        \"\"\"\n",
    "        dev = R.device\n",
    "        device_type = \"cuda\" if dev.type == \"cuda\" else \"cpu\"\n",
    "        with torch.autocast(device_type=device_type, enabled=False):\n",
    "            # Make sure the cache matches current A AND is on correct device\n",
    "            self.refresh(A)\n",
    "            A32  = A.to(dtype=torch.float32, device=dev)\n",
    "            R32  = R.to(dtype=torch.float32, device=dev)\n",
    "            invG = self._cached_invG\n",
    "            if invG.device != dev:\n",
    "                invG = invG.to(dev)\n",
    "\n",
    "            # Proj_col(A)(R) = ((R @ A) @ invG) @ A^T\n",
    "            Z = R32 @ A32\n",
    "            Z = Z @ invG\n",
    "            R_proj = Z @ A32.transpose(0, 1)\n",
    "\n",
    "            R_orth = R32 - R_proj\n",
    "            return R_orth.to(dtype=R.dtype, device=dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:28.968559Z",
     "iopub.status.busy": "2025-10-29T21:58:28.968243Z",
     "iopub.status.idle": "2025-10-29T21:58:28.974145Z",
     "shell.execute_reply": "2025-10-29T21:58:28.973384Z",
     "shell.execute_reply.started": "2025-10-29T21:58:28.968536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def agreement_loss(names, preds, eps=1e-8):\n",
    "    \"\"\"\n",
    "    names: list[str] length B (image ids per caption)\n",
    "    preds: (B, D) unnormalized predictions\n",
    "    Returns mean variance across groups (after L2-norm), scalar.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        groups = {}\n",
    "        for i, n in enumerate(map(str, names)):\n",
    "            groups.setdefault(n, []).append(i)\n",
    "        valid = [idxs for idxs in groups.values() if len(idxs) >= 2]\n",
    "    if not valid:\n",
    "        return preds.new_tensor(0.0)\n",
    "    z = F.normalize(preds, dim=-1)\n",
    "    vars_ = []\n",
    "    for idxs in valid:\n",
    "        g = z[idxs]\n",
    "        v = g.var(dim=0, unbiased=False).mean()\n",
    "        vars_.append(v)\n",
    "    return torch.stack(vars_).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:30.419914Z",
     "iopub.status.busy": "2025-10-29T21:58:30.419648Z",
     "iopub.status.idle": "2025-10-29T21:58:30.429114Z",
     "shell.execute_reply": "2025-10-29T21:58:30.428287Z",
     "shell.execute_reply.started": "2025-10-29T21:58:30.419893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ImgQueue:\n",
    "    def __init__(self, dim: int, capacity: int, device: torch.device):\n",
    "        self.capacity = int(capacity)\n",
    "        self.device = device\n",
    "        self.ptr = 0                  # write pointer into a circular buffer\n",
    "        self.full = False\n",
    "        self.bank = torch.zeros(self.capacity, dim, device=device)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def enqueue(self, feats: torch.Tensor):\n",
    "        # store as negatives only; avoid holding computation graphs\n",
    "        feats = feats.detach()\n",
    "        n = feats.size(0)\n",
    "        if n >= self.capacity:\n",
    "            # keep only the most recent 'capacity' entries\n",
    "            self.bank.copy_(feats[-self.capacity:])\n",
    "            self.ptr = 0\n",
    "            self.full = True\n",
    "            return\n",
    "        end = self.ptr + n\n",
    "        if end <= self.capacity:\n",
    "            self.bank[self.ptr:end] = feats\n",
    "        else:\n",
    "            cut = self.capacity - self.ptr\n",
    "            self.bank[self.ptr:] = feats[:cut]\n",
    "            self.bank[:end - self.capacity] = feats[cut:]\n",
    "        self.ptr = (self.ptr + n) % self.capacity\n",
    "        if self.ptr == 0:\n",
    "            self.full = True\n",
    "\n",
    "    def size(self) -> int:\n",
    "        # correct empty vs full handling\n",
    "        if self.full:\n",
    "            return self.capacity\n",
    "        return self.ptr  # 0 when empty\n",
    "\n",
    "    def get(self) -> torch.Tensor:\n",
    "        # return FIFO-ordered contents (oldest -> newest)\n",
    "        if self.size() == 0:\n",
    "            return self.bank[:0]  # empty tensor with correct shape\n",
    "        if self.full:\n",
    "            # [ptr:cap] then [0:ptr] so that tail is the most recent\n",
    "            return torch.cat([self.bank[self.ptr:], self.bank[:self.ptr]], dim=0)\n",
    "        # not full: contents are [0:ptr)\n",
    "        return self.bank[:self.ptr]\n",
    "\n",
    "    def recent(self, max_items: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Return only the freshest 'max_items' features (chronological).\n",
    "        \"\"\"\n",
    "        q = self.get()\n",
    "        if q is None or q.numel() == 0:\n",
    "            return q\n",
    "        if max_items is None or q.size(0) <= int(max_items):\n",
    "            return q\n",
    "        return q[-int(max_items):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:32.364222Z",
     "iopub.status.busy": "2025-10-29T21:58:32.363950Z",
     "iopub.status.idle": "2025-10-29T21:58:32.374719Z",
     "shell.execute_reply": "2025-10-29T21:58:32.373945Z",
     "shell.execute_reply.started": "2025-10-29T21:58:32.364201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============== P×K Sampler (F1.1) ===============\n",
    "class PKBatchSampler(torch.utils.data.Sampler[list[int]]):\n",
    "    \"\"\"\n",
    "    Samples batches with P unique images, each with K captions.\n",
    "    Use in DataLoader(batch_sampler=PKBatchSampler(...)).\n",
    "    \"\"\"\n",
    "    def __init__(self, img_ids: list[str], P: int, K: int, drop_last: bool = True, seed: int = 42):\n",
    "        # group dataset indices by image id\n",
    "        self.by_img = {}\n",
    "        for idx, iid in enumerate(map(str, img_ids)):\n",
    "            self.by_img.setdefault(iid, []).append(idx)\n",
    "        # shuffle within each image's index list\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "        for lst in self.by_img.values():\n",
    "            perm = torch.randperm(len(lst), generator=g).tolist()\n",
    "            lst[:] = [lst[i] for i in perm]\n",
    "\n",
    "        self.P, self.K, self.drop_last = int(P), int(K), bool(drop_last)\n",
    "        self.iids = list(self.by_img.keys())\n",
    "        self.cur = {iid: 0 for iid in self.iids}\n",
    "        self.pool = [iid for iid in self.iids if len(self.by_img[iid]) > 0]\n",
    "\n",
    "    def __iter__(self):\n",
    "        import random\n",
    "        pool = self.pool[:]\n",
    "        random.shuffle(pool)\n",
    "        batch = []\n",
    "        while len(pool) >= self.P:\n",
    "            pick = pool[:self.P]\n",
    "            pool = pool[self.P:]\n",
    "            for iid in pick:\n",
    "                start = self.cur[iid]\n",
    "                end = start + self.K\n",
    "                lst = self.by_img[iid]\n",
    "                if start >= len(lst):\n",
    "                    continue\n",
    "                take = lst[start:min(end, len(lst))]\n",
    "                self.cur[iid] = min(end, len(lst))\n",
    "                batch.extend(take)\n",
    "            if len(batch) == self.P * self.K:\n",
    "                yield batch\n",
    "            else:\n",
    "                if not self.drop_last and len(batch) > 0:\n",
    "                    yield batch\n",
    "                break\n",
    "            batch = []\n",
    "\n",
    "    def __len__(self):\n",
    "        total = sum(len(v) // self.K for v in self.by_img.values())\n",
    "        return max(0, total // self.P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:34.390553Z",
     "iopub.status.busy": "2025-10-29T21:58:34.390233Z",
     "iopub.status.idle": "2025-10-29T21:58:34.401946Z",
     "shell.execute_reply": "2025-10-29T21:58:34.401307Z",
     "shell.execute_reply.started": "2025-10-29T21:58:34.390531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============== Cross-batch Positives Buffer (F1.2) ===============\n",
    "from collections import deque\n",
    "\n",
    "class XBPBuffer:\n",
    "    \"\"\"\n",
    "    Keeps recent predicted caption embeddings as extra positives per image.\n",
    "    Read-only in loss; write after optimizer step.\n",
    "    \"\"\"\n",
    "    def __init__(self, per_image_cap: int = 4, global_cap: int = 32000, device: torch.device = torch.device(\"cpu\")):\n",
    "        self.per_img = {}            # iid -> deque of normalized tensors\n",
    "        self.order = deque()         # (iid, stamp) to enforce global cap\n",
    "        self.per_image_cap = int(per_image_cap)\n",
    "        self.global_cap = int(global_cap)\n",
    "        self.device = device\n",
    "        self._count = 0\n",
    "        self._stamp = 0\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def add(self, img_ids: list[str], pred_feats: torch.Tensor):\n",
    "        feats = F.normalize(pred_feats.detach(), dim=-1)\n",
    "        for iid, f in zip(map(str, img_ids), feats):\n",
    "            dq = self.per_img.setdefault(iid, deque(maxlen=self.per_image_cap))\n",
    "            dq.append(f.to(self.device))\n",
    "            self.order.append((iid, self._stamp))\n",
    "            self._stamp += 1\n",
    "            self._count += 1\n",
    "            # trim global\n",
    "            while self._count > self.global_cap:\n",
    "                old_iid, _ = self.order.popleft()\n",
    "                if self.per_img.get(old_iid):\n",
    "                    try:\n",
    "                        self.per_img[old_iid].popleft()\n",
    "                        self._count -= 1\n",
    "                        if len(self.per_img[old_iid]) == 0:\n",
    "                            self.per_img.pop(old_iid, None)\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "\n",
    "    def build_bank_and_mask(self, batch_img_names: list[str], device: torch.device):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "          xbp_bank: (M, D) stacked positives from XBP across batch (M can be 0)\n",
    "          xbp_pos_cols_per_row: list[list[int]] with column indices into xbp_bank for each row\n",
    "        \"\"\"\n",
    "        rows = [str(x) for x in batch_img_names]\n",
    "        per_row_feats = []\n",
    "        row_counts = []\n",
    "        for iid in rows:\n",
    "            dq = self.per_img.get(iid, None)\n",
    "            if dq is None or len(dq) == 0:\n",
    "                row_counts.append(0)\n",
    "            else:\n",
    "                row_counts.append(len(dq))\n",
    "                per_row_feats.extend(list(dq))\n",
    "        if len(per_row_feats) == 0:\n",
    "            return torch.empty(0, 0, device=device), [[] for _ in rows]\n",
    "        xbp_bank = torch.stack(per_row_feats, dim=0).to(device)\n",
    "        xbp_pos_cols = []\n",
    "        offset = 0\n",
    "        for cnt in row_counts:\n",
    "            if cnt == 0:\n",
    "                xbp_pos_cols.append([])\n",
    "            else:\n",
    "                xbp_pos_cols.append(list(range(offset, offset + cnt)))\n",
    "                offset += cnt\n",
    "        return xbp_bank, xbp_pos_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:36.644292Z",
     "iopub.status.busy": "2025-10-29T21:58:36.643820Z",
     "iopub.status.idle": "2025-10-29T21:58:36.649991Z",
     "shell.execute_reply": "2025-10-29T21:58:36.649047Z",
     "shell.execute_reply.started": "2025-10-29T21:58:36.644268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============== Hard-subset Mining (F2.1) ===============\n",
    "@torch.no_grad()\n",
    "def mine_hard(q_recent: torch.Tensor, pred: torch.Tensor, H: int, exclude_feats: torch.Tensor = None):\n",
    "    \"\"\"\n",
    "    q_recent: (Q,D) normalized features to mine from (negatives pool)\n",
    "    pred:     (B,D) normalized anchor predictions\n",
    "    Returns:\n",
    "      idx: (B,H) indices into q_recent for each anchor\n",
    "      flat_idx: (B*H,) flattened indices\n",
    "      mined: (B*H,D) the mined subset\n",
    "    \"\"\"\n",
    "    if q_recent is None or q_recent.numel() == 0 or H <= 0:\n",
    "        return None, None, None\n",
    "    B = pred.size(0)\n",
    "    Q = q_recent.size(0)\n",
    "    sims = pred @ q_recent.t()  # (B,Q)\n",
    "    H = min(int(H), Q)\n",
    "    _, idx = torch.topk(sims, k=H, dim=1, largest=True, sorted=False)  # (B,H)\n",
    "    flat_idx = idx.reshape(-1)\n",
    "    mined = q_recent.index_select(0, flat_idx)      # (B*H,D)\n",
    "    return idx, flat_idx, mined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T19:45:04.565718Z",
     "iopub.status.busy": "2025-10-29T19:45:04.565397Z",
     "iopub.status.idle": "2025-10-29T19:45:04.570504Z",
     "shell.execute_reply": "2025-10-29T19:45:04.569714Z",
     "shell.execute_reply.started": "2025-10-29T19:45:04.565697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============== Debiased NT-Xent denominator (F2.2) ===============\n",
    "def _debiased_logZ(logits: torch.Tensor, pos_mask: torch.Tensor, class_prior: float = 0.01):\n",
    "    \"\"\"\n",
    "    Chuang et al., 2020 (Debiased Contrastive Learning) — practical variant:\n",
    "      Z* = sum_k exp(l_ik) - π * sum_{j in P_i} exp(l_ij)\n",
    "    \"\"\"\n",
    "    exp_all = torch.exp(logits)          # (B,K)\n",
    "    exp_pos = exp_all * pos_mask\n",
    "    Z = exp_all.sum(dim=1)               # (B,)\n",
    "    corr = class_prior * exp_pos.sum(dim=1)\n",
    "    Z_star = torch.clamp(Z - corr, min=1e-8)\n",
    "    return torch.log(Z_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:38.343142Z",
     "iopub.status.busy": "2025-10-29T21:58:38.342422Z",
     "iopub.status.idle": "2025-10-29T21:58:38.352746Z",
     "shell.execute_reply": "2025-10-29T21:58:38.351956Z",
     "shell.execute_reply.started": "2025-10-29T21:58:38.343117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============== Multi-positive InfoNCE with XBP, Hard Mining, DCL (F1.1+F1.2+F2.1+F2.2) ===============\n",
    "def info_nce_multi(\n",
    "    pred,                                    # (B,D) unnormed\n",
    "    batch_img_targets,                       # (B,D)\n",
    "    batch_img_names,                         # list length B\n",
    "    queue_feats=None,                        # (Q,D) negatives pool\n",
    "    tau: float = 0.07,\n",
    "    xbp_bank: torch.Tensor = None,           # (M,D) extra positives\n",
    "    xbp_pos_cols_per_row: list[list[int]] = None,\n",
    "    hard_subset_H: int = 0,\n",
    "    use_dcl: bool = False,\n",
    "    dcl_prior: float = 0.01,\n",
    "):\n",
    "    p = F.normalize(pred, dim=-1)\n",
    "    t = F.normalize(batch_img_targets, dim=-1)\n",
    "\n",
    "    # base bank block 0: in-batch targets (positives exist here)\n",
    "    bank_blocks = [t]\n",
    "    B = pred.size(0)\n",
    "\n",
    "    # optional hard mining over queue\n",
    "    if queue_feats is not None and queue_feats.numel() > 0:\n",
    "        qn = F.normalize(queue_feats, dim=-1)\n",
    "        if hard_subset_H and hard_subset_H > 0:\n",
    "            _, _, mined_block = mine_hard(qn, p, int(hard_subset_H))\n",
    "            bank_blocks.append(mined_block)\n",
    "        else:\n",
    "            bank_blocks.append(qn)\n",
    "\n",
    "    # optional XBP block\n",
    "    xbp_offsets = None\n",
    "    if xbp_bank is not None and xbp_bank.numel() > 0:\n",
    "        xbp_offsets = sum(b.size(0) for b in bank_blocks)  # start col for XBP block\n",
    "        bank_blocks.append(xbp_bank)\n",
    "\n",
    "    bank = torch.cat(bank_blocks, dim=0) if len(bank_blocks) > 1 else bank_blocks[0]  # (K,D)\n",
    "    logits = (p @ bank.t()) / float(tau)                                              # (B,K)\n",
    "    K = bank.size(0)\n",
    "\n",
    "    # build pos mask: in-batch + XBP\n",
    "    pos_mask = torch.zeros(B, K, dtype=torch.bool, device=pred.device)\n",
    "    names = list(map(str, batch_img_names))\n",
    "    for i in range(B):\n",
    "        for j in range(B):\n",
    "            if names[i] == names[j]:\n",
    "                pos_mask[i, j] = True\n",
    "    if xbp_offsets is not None and xbp_pos_cols_per_row is not None:\n",
    "        for i, cols in enumerate(xbp_pos_cols_per_row):\n",
    "            for c in cols:\n",
    "                pos_mask[i, xbp_offsets + c] = True\n",
    "\n",
    "    assert pos_mask.any(dim=1).all(), \"Every row must have at least one positive.\"\n",
    "\n",
    "    # denominator: standard vs debiased\n",
    "    if not use_dcl:\n",
    "        logZ = torch.logsumexp(logits, dim=1)\n",
    "    else:\n",
    "        logZ = _debiased_logZ(logits, pos_mask, class_prior=float(dcl_prior))\n",
    "\n",
    "    logits_pos = logits.masked_fill(~pos_mask, float('-inf'))\n",
    "    logPos = torch.logsumexp(logits_pos, dim=1)\n",
    "    return (-(logPos - logZ)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:40.966805Z",
     "iopub.status.busy": "2025-10-29T21:58:40.966283Z",
     "iopub.status.idle": "2025-10-29T21:58:40.976973Z",
     "shell.execute_reply": "2025-10-29T21:58:40.976385Z",
     "shell.execute_reply.started": "2025-10-29T21:58:40.966779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =============== Dual Queue: Prediction FIFO (F2.3) ===============\n",
    "class PredQueue:\n",
    "    def __init__(self, dim: int, capacity: int, device: torch.device):\n",
    "        self.capacity = int(capacity)\n",
    "        self.device = device\n",
    "        self.ptr = 0\n",
    "        self.full = False\n",
    "        self.feats = torch.zeros(self.capacity, dim, device=device)  # normalized feats\n",
    "        self.ids = torch.empty(self.capacity, dtype=torch.long, device=device)  # hashed img ids\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def enqueue(self, feats: torch.Tensor, img_ids: list[str]):\n",
    "        feats = F.normalize(feats.detach(), dim=-1)\n",
    "        ids = torch.tensor([hash(str(i)) for i in img_ids], dtype=torch.long, device=self.device)\n",
    "        n = feats.size(0)\n",
    "        if n >= self.capacity:\n",
    "            self.feats.copy_(feats[-self.capacity:])\n",
    "            self.ids.copy_(ids[-self.capacity:])\n",
    "            self.ptr = 0\n",
    "            self.full = True\n",
    "            return\n",
    "        end = self.ptr + n\n",
    "        if end <= self.capacity:\n",
    "            self.feats[self.ptr:end] = feats\n",
    "            self.ids[self.ptr:end] = ids\n",
    "        else:\n",
    "            cut = self.capacity - self.ptr\n",
    "            self.feats[self.ptr:] = feats[:cut]\n",
    "            self.ids[self.ptr:] = ids[:cut]\n",
    "            self.feats[:end - self.capacity] = feats[cut:]\n",
    "            self.ids[:end - self.capacity] = ids[cut:]\n",
    "        self.ptr = (self.ptr + n) % self.capacity\n",
    "        if self.ptr == 0:\n",
    "            self.full = True\n",
    "\n",
    "    def size(self) -> int:\n",
    "        if self.full:\n",
    "            return self.capacity\n",
    "        return self.ptr\n",
    "\n",
    "    def recent(self, max_items: int):\n",
    "        n = self.size()\n",
    "        if n == 0:\n",
    "            return self.feats[:0], self.ids[:0]\n",
    "        k = min(int(max_items), n) if max_items is not None else n\n",
    "        if self.full:\n",
    "            idx = torch.arange(self.ptr - n, self.ptr, device=self.device) % self.capacity\n",
    "        else:\n",
    "            idx = torch.arange(0, n, device=self.device)\n",
    "        idx = idx[-k:]\n",
    "        return self.feats.index_select(0, idx), self.ids.index_select(0, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:43.121540Z",
     "iopub.status.busy": "2025-10-29T21:58:43.120994Z",
     "iopub.status.idle": "2025-10-29T21:58:43.128551Z",
     "shell.execute_reply": "2025-10-29T21:58:43.127493Z",
     "shell.execute_reply.started": "2025-10-29T21:58:43.121517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    arch: str, din: int, dout: int, geom_init_data=None,\n",
    "    residual_ortho: str = \"project\",\n",
    "    ortho_eps: float = 1e-4,\n",
    "    ortho_lambda: float = 0.05,\n",
    "    unfreeze_geom_bias: bool = False,\n",
    "):\n",
    "    a = arch.lower()\n",
    "    if a == \"linear\":\n",
    "        return LinearProj(din, dout)\n",
    "    if a == \"mlp1\":\n",
    "        return MLP1(din, dout, hidden=512, pdrop=0.1)\n",
    "    if a == \"mlp2\":\n",
    "        return MLP2(din, dout, h1=1024, h2=512, pdrop=0.1)\n",
    "    if a == \"geom\":\n",
    "        assert geom_init_data is not None, \"geom_init_data required for arch='geom'.\"\n",
    "        Xtr_np, Ytr_np, eps = geom_init_data\n",
    "        A, b = procrustes_closed_form(Xtr_np, Ytr_np, eps=float(eps))\n",
    "        return GeomLinear(A, b)\n",
    "    if a in (\"geom_adapter\", \"geom+adapter\", \"bigjump\"):\n",
    "        assert geom_init_data is not None, \"geom_init_data required for geom+adapter/bigjump.\"\n",
    "        Xtr_np, Ytr_np, eps = geom_init_data\n",
    "        A, b = procrustes_closed_form(Xtr_np, Ytr_np, eps=float(eps))\n",
    "        return GeomWithAdapter(\n",
    "            A, b, din=din, dout=dout, hidden=1024, pdrop=0.1,\n",
    "            residual_ortho=residual_ortho, ortho_eps=ortho_eps,\n",
    "            ortho_lambda=ortho_lambda, unfreeze_bias=unfreeze_geom_bias\n",
    "        )\n",
    "    if a == \"auto\":\n",
    "        return MLP2(din, dout)\n",
    "    raise ValueError(f\"Unknown arch {arch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:44.829643Z",
     "iopub.status.busy": "2025-10-29T21:58:44.829265Z",
     "iopub.status.idle": "2025-10-29T21:58:44.839627Z",
     "shell.execute_reply": "2025-10-29T21:58:44.838775Z",
     "shell.execute_reply.started": "2025-10-29T21:58:44.829621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- Centroid helpers ----------\n",
    "def _centroids_from_img_ids(X_rows: np.ndarray, Y_rows: np.ndarray, img_names_rows: np.ndarray):\n",
    "    \"\"\"\n",
    "    Build per-image centroids from per-caption rows.\n",
    "    Returns:\n",
    "      Xc: (N_img, 1024)   mean text per image\n",
    "      Yc: (N_img, 1536)   mean image per image (usually equals the single image vector)\n",
    "      order_names: list[str] image names in same order\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    buckets_x = defaultdict(list)\n",
    "    buckets_y = defaultdict(list)\n",
    "    for x, y, n in zip(X_rows, Y_rows, map(str, img_names_rows)):\n",
    "        buckets_x[n].append(x)\n",
    "        buckets_y[n].append(y)\n",
    "    order_names = sorted(buckets_x.keys())\n",
    "    Xc = np.stack([np.mean(buckets_x[n], axis=0) for n in order_names], axis=0).astype(np.float32)\n",
    "    Yc = np.stack([np.mean(buckets_y[n], axis=0) for n in order_names], axis=0).astype(np.float32)\n",
    "    return Xc, Yc, order_names\n",
    "\n",
    "# ---------- Geometry: closed-form (whiten→orthogonal align→recolor) on CENTROIDS ----------\n",
    "def procrustes_closed_form_centroids(X_rows: np.ndarray, Y_rows: np.ndarray, img_names_rows: np.ndarray, eps: float = 1e-5):\n",
    "    \"\"\"\n",
    "    Fit linear A,b using per-image centroids instead of per-caption rows.\n",
    "    \"\"\"\n",
    "    Xc, Yc, _ = _centroids_from_img_ids(X_rows, Y_rows, img_names_rows)\n",
    "\n",
    "    mu_x = Xc.mean(0, dtype=np.float64)\n",
    "    mu_y = Yc.mean(0, dtype=np.float64)\n",
    "    Xzc = Xc - mu_x\n",
    "    Yzc = Yc - mu_y\n",
    "\n",
    "    def _cov_eigh(zc, eps):\n",
    "        S, U = np.linalg.eigh((zc.T @ zc) / max(1, zc.shape[0]))\n",
    "        S = np.clip(S, 0.0, None)\n",
    "        inv_sqrt = 1.0 / np.sqrt(S + eps)\n",
    "        sqrt     = np.sqrt(S + eps)\n",
    "        C_mhalf = (U * inv_sqrt) @ U.T\n",
    "        C_phalf = (U * sqrt)     @ U.T\n",
    "        return C_mhalf.astype(np.float32), C_phalf.astype(np.float32)\n",
    "\n",
    "    Cx_mh, _     = _cov_eigh(Xzc, eps)      # 1024x1024\n",
    "    Cy_mh, Cy_ph = _cov_eigh(Yzc, eps)      # 1536x1536\n",
    "    Xw = Xzc @ Cx_mh.T                      # (Nimg,1024)\n",
    "    Yw = Yzc @ Cy_mh.T                      # (Nimg,1536)\n",
    "\n",
    "    # rectangular orthogonal alignment in whitened space\n",
    "    M = Xw.T @ Yw                           # (1024,1536)\n",
    "    U, _, Vt = np.linalg.svd(M, full_matrices=False)\n",
    "    R = (U @ Vt).T                          # (1536,1024)\n",
    "\n",
    "    # recolor to Y space\n",
    "    A = (Cy_ph @ R @ Cx_mh).astype(np.float32)     # (1536,1024)\n",
    "    b = (mu_y - (A @ mu_x)).astype(np.float32)     # (1536,)\n",
    "    return A, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:46.450130Z",
     "iopub.status.busy": "2025-10-29T21:58:46.449370Z",
     "iopub.status.idle": "2025-10-29T21:58:46.455917Z",
     "shell.execute_reply": "2025-10-29T21:58:46.455094Z",
     "shell.execute_reply.started": "2025-10-29T21:58:46.450091Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- Losses: fixed-τ InfoNCE + Triplet (cosine) ----------\n",
    "def info_nce_fixed(pred: torch.Tensor, tgt: torch.Tensor, tau: float):\n",
    "    # both should be L2-normalized already\n",
    "    logits = (pred @ tgt.t()) / float(tau)                 # (B,B)\n",
    "    labels = torch.arange(pred.size(0), device=pred.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "class TripletCosineLoss(nn.Module):\n",
    "    def __init__(self, margin: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.loss = nn.TripletMarginWithDistanceLoss(\n",
    "            distance_function=lambda x, y: 1 - F.cosine_similarity(x, y),\n",
    "            margin=margin\n",
    "        )\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        return self.loss(anchor, positive, negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:48.566238Z",
     "iopub.status.busy": "2025-10-29T21:58:48.565517Z",
     "iopub.status.idle": "2025-10-29T21:58:48.947970Z",
     "shell.execute_reply": "2025-10-29T21:58:48.947350Z",
     "shell.execute_reply.started": "2025-10-29T21:58:48.566211Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "#   SIMPLE TRAINER \n",
    "# =========================\n",
    "def train_simple(\n",
    "    model,\n",
    "    Xtr, Ytr, img_ids_row_tr,\n",
    "    Xva, val_gallery, cap2gal_local,\n",
    "    batch=512, epochs=25, lr=2e-4, wd=1e-4,\n",
    "    tau_fixed=0.07, triplet_margin=0.2, triplet_w=0.3,\n",
    "    alpha_cos=0.0,            # cosine aux off by default (script-style)\n",
    "    moment_w=0.0,             # moment off by default\n",
    "    use_pk=False, P=192, K_pk=3,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    pooling=\"none\", n_patches=None,\n",
    "    out_dir: \"Path | str\" = None, seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Matches the simple script dynamics:\n",
    "      - outputs L2-normalized\n",
    "      - InfoNCE with fixed tau + Triplet(cosine)\n",
    "      - in-batch negatives only (no queues)\n",
    "      - geometry kept frozen (handled by caller)\n",
    "    \"\"\"\n",
    "    import math, json\n",
    "    from pathlib import Path\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    out_dir = Path(out_dir) if out_dir is not None else Path(\"./outputs/simple\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    seed_all(seed)\n",
    "    model.to(device)\n",
    "\n",
    "    class TripletSet(torch.utils.data.Dataset):\n",
    "        def __init__(self, X_np, Y_np, names_np):\n",
    "            self.X = torch.from_numpy(X_np).float()\n",
    "            self.Y = torch.from_numpy(Y_np).float()\n",
    "            self.N = [str(n) for n in names_np.tolist()]\n",
    "        def __len__(self):  return len(self.X)\n",
    "        def __getitem__(self, i):  return self.X[i], self.Y[i], self.N[i]\n",
    "\n",
    "    ds = TripletSet(Xtr, Ytr, img_ids_row_tr)\n",
    "\n",
    "    if use_pk:\n",
    "        pk_sampler = PKBatchSampler(img_ids_row_tr.tolist(), P=int(P), K=int(K_pk), drop_last=True, seed=seed)\n",
    "        dl = DataLoader(ds, batch_sampler=pk_sampler, num_workers=2, pin_memory=True)\n",
    "    else:\n",
    "        dl = DataLoader(ds, batch_size=batch, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # freeze geometry fully (caller must set requires_grad=False on geom)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    opt = torch.optim.AdamW(params, lr=lr, weight_decay=wd)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=max(1, epochs*len(dl)))\n",
    "\n",
    "    tri = TripletCosineLoss(margin=float(triplet_margin))\n",
    "\n",
    "    best_stats, best_mrr, best_ep = None, -1.0, 0\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        for xb, yb, _ in dl:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            pred = model(xb)                 # (B,1536)\n",
    "            pred = F.normalize(pred, dim=-1)\n",
    "            ybn  = F.normalize(yb,  dim=-1)\n",
    "\n",
    "            # InfoNCE (fixed tau) with in-batch negatives\n",
    "            loss_ce = info_nce_fixed(pred, ybn, tau=float(tau_fixed))\n",
    "\n",
    "            # Triplet: pick negatives by shuffling the batch\n",
    "            idx = torch.randperm(xb.size(0), device=device)\n",
    "            loss_tri = tri(pred, ybn, ybn[idx])\n",
    "\n",
    "            # Optional tiny auxiliaries (default 0)\n",
    "            loss_cos = (1.0 - F.cosine_similarity(pred, yb, dim=-1)).mean() if alpha_cos > 0 else pred.new_tensor(0.0)\n",
    "            loss_mu  = moment_align(pred, yb) if moment_w > 0 else pred.new_tensor(0.0)\n",
    "\n",
    "            loss = (1.0 - float(triplet_w)) * loss_ce + float(triplet_w) * loss_tri \\\n",
    "                   + float(alpha_cos) * loss_cos + float(moment_w) * loss_mu\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(params, 1.0)\n",
    "            opt.step()\n",
    "            running += loss.item() * xb.size(0)\n",
    "\n",
    "        sched.step()\n",
    "        stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "        ep_loss = running / len(ds)\n",
    "        print(f\"[simple {ep:02d}] loss={ep_loss:.6f} | val_MRR={stats['MRR']:.4f} \"\n",
    "              f\"| R@1={stats['R1']:.3f} R@5={stats['R5']:.3f} R@10={stats['R10']:.3f} \"\n",
    "              f\"| median={stats['rank_median']} p75={stats['rank_p75']}\")\n",
    "\n",
    "        if stats[\"MRR\"] > best_mrr:\n",
    "            best_mrr, best_ep, best_stats = stats[\"MRR\"], ep, stats\n",
    "            torch.save({\"model\": model.state_dict(), \"epoch\": ep, \"val\": stats}, out_dir / \"best.pt\")\n",
    "\n",
    "    if best_stats is None:\n",
    "        best_stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "        torch.save({\"model\": model.state_dict(), \"epoch\": 0, \"val\": best_stats}, out_dir / \"best.pt\")\n",
    "\n",
    "    (out_dir / \"val_metrics.json\").write_text(json.dumps(dict(best_epoch=best_ep, **best_stats), indent=2))\n",
    "    return best_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:58:52.518683Z",
     "iopub.status.busy": "2025-10-29T21:58:52.518102Z",
     "iopub.status.idle": "2025-10-29T21:58:52.544671Z",
     "shell.execute_reply": "2025-10-29T21:58:52.543896Z",
     "shell.execute_reply.started": "2025-10-29T21:58:52.518660Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \"\"\"\n",
    "    Main (advanced, two-stage): \n",
    "      - Stage 1: Centroid-Procrustes + Frozen Base + Residual, trained with fixed-τ InfoNCE + Triplet (stable warm-up).\n",
    "      - Stage 2: Continue from Stage 1 and switch to BigJump trainer with a *small, late* queue + light mining + tiny agreement. \n",
    "                 Geometry stays frozen. No hard residual projection.\n",
    "      - Then: evaluate, log efficiency, generate submission.\n",
    "\n",
    "    Assumes these already exist in your file:\n",
    "      load_train, build_image_id_split, procrustes_closed_form_centroids\n",
    "      ResidualAdapter, train_simple, train_bigjump\n",
    "      validate_retrieval, count_params_mb, time_ms_per_query\n",
    "      apply_pooling, load_data, generate_submission, TEST_NPZ\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    # -----------------------\n",
    "    # Setup\n",
    "    # -----------------------\n",
    "    out_dir, seed = args.out_dir, args.seed\n",
    "    pooling, n_patches = args.pooling, None\n",
    "    OUT = Path(f\"/kaggle/working/outputs/{out_dir}\")\n",
    "    OUT.mkdir(parents=True, exist_ok=True)\n",
    "    STAGE1 = OUT / \"stage1\"\n",
    "    STAGE2 = OUT / \"stage2\"\n",
    "    STAGE1.mkdir(parents=True, exist_ok=True)\n",
    "    STAGE2.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Data\n",
    "    # -----------------------\n",
    "    X, Y, cap_ids, img_ids_row, full_img, all_img_ids = load_train(OUT)\n",
    "\n",
    "    # Split by image id (NO LEAKAGE)\n",
    "    cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices = build_image_id_split(\n",
    "        img_ids_row, all_img_ids, full_img, X, Y, args.val_ratio, seed, OUT\n",
    "    )\n",
    "    val_set = set(all_img_ids[val_img_indices])\n",
    "    train_set = set(all_img_ids) - val_set\n",
    "    assert val_set.isdisjoint(train_set), \"Leakage detected between TRAIN and VAL image sets!\"\n",
    "\n",
    "    # Masks to arrays\n",
    "    Xtr, Ytr = X[cap_is_tr], Y[cap_is_tr]\n",
    "    Xva      = X[cap_is_val]\n",
    "\n",
    "    din, dout = X.shape[1], Y.shape[1]\n",
    "    assert din == 1024 and dout == 1536, f\"Dimension mismatch: text={din}, image={dout} (expected 1024→1536)\"\n",
    "\n",
    "    # -----------------------\n",
    "    # Geometry init (CENTROIDS on TRAIN ONLY)\n",
    "    # -----------------------\n",
    "    A, b = procrustes_closed_form_centroids(\n",
    "        Xtr.astype(np.float32),\n",
    "        Ytr.astype(np.float32),\n",
    "        img_ids_row[cap_is_tr],\n",
    "        eps=float(args.geom_eps)\n",
    "    )\n",
    "\n",
    "    # -----------------------\n",
    "    # Model: Frozen base (A,b) + residual adapter\n",
    "    # -----------------------\n",
    "    class GeomFromWeights(nn.Module):\n",
    "        def __init__(self, A_np, b_np):\n",
    "            super().__init__()\n",
    "            self.fc = nn.Linear(A_np.shape[1], A_np.shape[0], bias=True)\n",
    "            with torch.no_grad():\n",
    "                self.fc.weight.copy_(torch.from_numpy(A_np))\n",
    "                self.fc.bias.copy_(torch.from_numpy(b_np))\n",
    "        def forward(self, x): return self.fc(x)\n",
    "\n",
    "    geom = GeomFromWeights(A, b).to(device)\n",
    "    for p in geom.parameters(): p.requires_grad = False  # keep base frozen in both stages\n",
    "\n",
    "    # residual capacity like BigJump adapter\n",
    "    adapter = ResidualAdapter(din=din, hidden=1024, dout=dout, pdrop=0.1)\n",
    "\n",
    "    class GeomPlusAdapter(nn.Module):\n",
    "        def __init__(self, g, a): super().__init__(); self.geom=g; self.adapter=a\n",
    "        def forward(self, x): return self.geom(x) + self.adapter(x)\n",
    "\n",
    "    model = GeomPlusAdapter(geom, adapter).to(device)\n",
    "\n",
    "    # Probe\n",
    "    with torch.no_grad():\n",
    "        _probe = model(torch.zeros(2, din, device=device))\n",
    "    assert _probe.shape[-1] == 1536, f\"Translator output dim { _probe.shape[-1] } != 1536\"\n",
    "\n",
    "    # -----------------------\n",
    "    # Stage 1: simple warm-up (fixed τ InfoNCE + Triplet, in-batch negatives)\n",
    "    # -----------------------\n",
    "    if not args.eval_only:\n",
    "        print(f\"[stage1] τ_fixed={args.tau:.3f} | triplet_w={args.triplet_w} | margin={args.triplet_margin} | epochs={args.stage1_epochs}\")\n",
    "        best_stats_s1 = train_simple(\n",
    "            model,\n",
    "            Xtr, Ytr, img_ids_row[cap_is_tr],\n",
    "            Xva, val_gallery, cap2gal_local,\n",
    "            batch=args.batch, epochs=int(args.stage1_epochs), lr=args.lr, wd=args.wd,\n",
    "            tau_fixed=float(args.tau), triplet_margin=float(args.triplet_margin), triplet_w=float(args.triplet_w),\n",
    "            alpha_cos=float(args.alpha), moment_w=float(args.moment),\n",
    "            use_pk=bool(args.use_pk), P=int(args.P), K_pk=int(args.K_pk),\n",
    "            device=device, pooling=pooling, n_patches=n_patches,\n",
    "            out_dir=str(STAGE1), seed=seed,\n",
    "        )\n",
    "        # Load best from stage1 (ensure we continue from the best)\n",
    "        try:\n",
    "            ckpt1 = torch.load(STAGE1 / \"best.pt\", map_location=device)\n",
    "            model.load_state_dict(ckpt1[\"model\"])\n",
    "            print(f\"[stage1] resume best epoch={ckpt1.get('epoch','?')} MRR={ckpt1.get('val',{}).get('MRR','?')}\")\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    else:\n",
    "        best_stats_s1 = None\n",
    "\n",
    "    # -----------------------\n",
    "    # Stage 2: BigJump+ (small queue, late; light mining; tiny agreement; geometry still frozen)\n",
    "    # -----------------------\n",
    "    if not args.eval_only and args.stage2_epochs > 0:\n",
    "        print(f\"[stage2] queue_warmup={args.queue_warmup_epochs} | recent_k={args.queue_recent_k} | mine_H={args.mine_H} | \"\n",
    "              f\"τ_sched={args.tau_start:.3f}→{args.tau_end:.3f} | agree={args.lambda_agree}\")\n",
    "        # Keep geometry frozen in BigJump\n",
    "        best_stats_s2 = train_bigjump(\n",
    "            model,\n",
    "            Xtr, Ytr, img_ids_row[cap_is_tr],\n",
    "            Xva, val_gallery, cap2gal_local,\n",
    "            batch=args.batch, epochs=int(args.stage2_epochs), base_lr=args.lr, wd=args.wd,\n",
    "            # legacy knobs (we’ll let InfoNCE dominate; keep cosine light, moment tiny/off)\n",
    "            tau=None,                                 # use τ curriculum in stage2\n",
    "            alpha_cos=float(args.alpha_stage2),       # e.g., 0.3\n",
    "            lambda_moment=float(args.moment_stage2),  # e.g., 0.01\n",
    "            queue_size=int(args.queue),\n",
    "            # schedules\n",
    "            tau_start=float(args.tau_start), tau_end=float(args.tau_end),\n",
    "            queue_warmup_epochs=int(args.queue_warmup_epochs),\n",
    "            queue_recent_schedule=tuple(args.queue_recent_k),\n",
    "            lambda_agree=float(args.lambda_agree),\n",
    "            # keep geometry frozen in stage2 as well\n",
    "            geom_unfreeze_epoch=0,\n",
    "            geom_lr_scale=float(args.geom_lr_scale),\n",
    "            # misc\n",
    "            device=device, pooling=pooling, n_patches=n_patches,\n",
    "            out_dir=str(STAGE2), seed=seed,\n",
    "            # NEW knobs\n",
    "            use_pk=bool(args.use_pk), P=int(args.P), K_pk=int(args.K_pk),\n",
    "            xbp_per_img=int(args.xbp_per_img), xbp_global=int(args.xbp_global),\n",
    "            use_dcl=bool(args.use_dcl), dcl_prior=float(args.dcl_prior),\n",
    "            mine_H=int(args.mine_H),\n",
    "            use_pred_queue=False, queue_pred_capacity=int(args.queue_pred_capacity),\n",
    "        )\n",
    "        # Load best from stage2 for final export\n",
    "        try:\n",
    "            ckpt2 = torch.load(STAGE2 / \"best.pt\", map_location=device)\n",
    "            model.load_state_dict(ckpt2[\"model\"])\n",
    "            best_stats_final = ckpt2.get(\"val\", None)\n",
    "            print(f\"[stage2] resume best epoch={ckpt2.get('epoch','?')} MRR={ckpt2.get('val',{}).get('MRR','?')}\")\n",
    "        except FileNotFoundError:\n",
    "            best_stats_final = best_stats_s1\n",
    "    else:\n",
    "        # eval-only: try to load stage2 first, else stage1\n",
    "        best_stats_final = None\n",
    "        if args.eval_only:\n",
    "            for cand in [STAGE2 / \"best.pt\", STAGE1 / \"best.pt\", OUT / \"best.pt\"]:\n",
    "                try:\n",
    "                    ckpt = torch.load(cand, map_location=device)\n",
    "                    model.load_state_dict(ckpt[\"model\"])\n",
    "                    best_stats_final = ckpt.get(\"val\", None)\n",
    "                    print(f\"[resume] loaded {cand} | epoch={ckpt.get('epoch','?')} MRR={ckpt.get('val',{}).get('MRR','?')}\")\n",
    "                    break\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "\n",
    "    # -----------------------\n",
    "    # Efficiency logging\n",
    "    # -----------------------\n",
    "    params, mb = count_params_mb(model)\n",
    "    ms_gpu, ms_cpu = time_ms_per_query(model, din, pooling, n_patches)\n",
    "    eff = {\"params\": params, \"mb_fp32\": mb, \"ms_per_query_gpu\": ms_gpu, \"ms_per_query_cpu\": ms_cpu}\n",
    "    (OUT / \"efficiency.json\").write_text(json.dumps(eff, indent=2))\n",
    "\n",
    "    # -----------------------\n",
    "    # Submission\n",
    "    # -----------------------\n",
    "    test_data = load_data(TEST_NPZ)\n",
    "    Q   = test_data[\"captions/embeddings\"].astype(np.float32)\n",
    "    ids = test_data.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n",
    "    model.eval()\n",
    "    BS, outs = 1024, []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(Q), BS):\n",
    "            q = torch.from_numpy(Q[i:i+BS]).to(device)\n",
    "            q = apply_pooling(q, pooling, n_patches)\n",
    "            z = model(q)\n",
    "            z = F.normalize(z, dim=-1)\n",
    "            outs.append(z.detach().cpu().numpy())\n",
    "    pred_embds = np.concatenate(outs, axis=0)\n",
    "    sub = OUT / \"submission.csv\"\n",
    "    generate_submission(ids, pred_embds, str(sub))\n",
    "    print(f\"[ok] submission written → {sub}\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Final sanity print\n",
    "    # -----------------------\n",
    "    if best_stats_final is None:\n",
    "        best_stats_final = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "\n",
    "    sanity = {\n",
    "        \"dims\": {\"text\": int(din), \"image\": int(dout)},\n",
    "        \"split\": {\n",
    "            \"train_captions\": int(cap_is_tr.sum()),\n",
    "            \"val_captions\": int(cap_is_val.sum()),\n",
    "            \"val_unique_images\": int(val_gallery.shape[0]),\n",
    "            \"leakage\": False\n",
    "        },\n",
    "        \"val_metrics\": best_stats_final,\n",
    "        \"efficiency\": eff,\n",
    "        \"recipe\": {\n",
    "            \"stage1\": {\n",
    "                \"type\": \"simple_fixed_tau_infoNCE+triplet\",\n",
    "                \"tau_fixed\": float(args.tau),\n",
    "                \"triplet_margin\": float(args.triplet_margin),\n",
    "                \"triplet_w\": float(args.triplet_w),\n",
    "                \"alpha_cos\": float(args.alpha),\n",
    "                \"moment_w\": float(args.moment),\n",
    "                \"epochs\": int(args.stage1_epochs),\n",
    "                \"use_pk\": bool(args.use_pk), \"P\": int(args.P), \"K\": int(args.K_pk)\n",
    "            },\n",
    "            \"stage2\": {\n",
    "                \"type\": \"bigjump_plus_small_queue_light_mining\",\n",
    "                \"epochs\": int(args.stage2_epochs),\n",
    "                \"tau_sched\": [float(args.tau_start), float(args.tau_end)],\n",
    "                \"queue_warmup_epochs\": int(args.queue_warmup_epochs),\n",
    "                \"queue_recent_schedule\": list(map(int, args.queue_recent_k)),\n",
    "                \"mine_H\": int(args.mine_H),\n",
    "                \"lambda_agree\": float(args.lambda_agree),\n",
    "                \"geom_unfreeze_epoch\": 0\n",
    "            },\n",
    "            \"centroid_procrustes\": True,\n",
    "            \"geom_frozen\": True,\n",
    "            \"residual_projection\": \"none\"\n",
    "        }\n",
    "    }\n",
    "    print(json.dumps(sanity, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T21:00:25.060355Z",
     "iopub.status.busy": "2025-10-29T21:00:25.059799Z",
     "iopub.status.idle": "2025-10-29T21:04:40.953038Z",
     "shell.execute_reply": "2025-10-29T21:04:40.952121Z",
     "shell.execute_reply.started": "2025-10-29T21:00:25.060331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[meta] text_dim=1024 | image_dim=1536\n",
      "[stage1] τ_fixed=0.070 | triplet_w=0.3 | margin=0.2 | epochs=12\n",
      "[simple 01] loss=2.166024 | val_MRR=0.3573 | R@1=0.232 R@5=0.496 R@10=0.620 | median=6 p75=23\n",
      "[simple 02] loss=2.019182 | val_MRR=0.3671 | R@1=0.241 R@5=0.508 R@10=0.635 | median=5 p75=21\n",
      "[simple 03] loss=1.967485 | val_MRR=0.3740 | R@1=0.246 R@5=0.514 R@10=0.643 | median=5 p75=19\n",
      "[simple 04] loss=1.931230 | val_MRR=0.3808 | R@1=0.251 R@5=0.525 R@10=0.651 | median=5 p75=19\n",
      "[simple 05] loss=1.901381 | val_MRR=0.3852 | R@1=0.256 R@5=0.531 R@10=0.658 | median=5 p75=18\n",
      "[simple 06] loss=1.875517 | val_MRR=0.3887 | R@1=0.259 R@5=0.534 R@10=0.663 | median=5 p75=17\n",
      "[simple 07] loss=1.854193 | val_MRR=0.3924 | R@1=0.261 R@5=0.541 R@10=0.669 | median=5 p75=17\n",
      "[simple 08] loss=1.834112 | val_MRR=0.3955 | R@1=0.266 R@5=0.542 R@10=0.669 | median=4 p75=17\n",
      "[simple 09] loss=1.816755 | val_MRR=0.3977 | R@1=0.267 R@5=0.546 R@10=0.674 | median=5 p75=16\n",
      "[simple 10] loss=1.799566 | val_MRR=0.3992 | R@1=0.269 R@5=0.547 R@10=0.675 | median=4 p75=16\n",
      "[simple 11] loss=1.785649 | val_MRR=0.3987 | R@1=0.267 R@5=0.546 R@10=0.677 | median=4 p75=16\n",
      "[simple 12] loss=1.771600 | val_MRR=0.4017 | R@1=0.270 R@5=0.549 R@10=0.681 | median=4 p75=16\n",
      "[stage1] resume best epoch=12 MRR=0.40171702851521446\n",
      "[stage2] queue_warmup=3 | recent_k=[8000, 16000, 65536] | mine_H=32 | τ_sched=0.100→0.060 | agree=0.02\n",
      "[bigjump 01] loss=2.903003 | val_MRR=0.4041 | R@1=0.273 R@5=0.551 R@10=0.681 | median=4 p75=16 | queue=65536 | tau=0.100 | recentQ=0\n",
      "[bigjump 02] loss=2.679751 | val_MRR=0.4015 | R@1=0.271 R@5=0.548 R@10=0.678 | median=4 p75=16 | queue=65536 | tau=0.099 | recentQ=0\n",
      "[bigjump 03] loss=2.653387 | val_MRR=0.4027 | R@1=0.271 R@5=0.551 R@10=0.681 | median=4 p75=16 | queue=65536 | tau=0.097 | recentQ=0\n",
      "[bigjump 04] loss=4.032444 | val_MRR=0.3864 | R@1=0.255 R@5=0.534 R@10=0.668 | median=5 p75=17 | queue=65536 | tau=0.094 | recentQ=8000\n",
      "[bigjump 05] loss=3.894188 | val_MRR=0.3967 | R@1=0.263 R@5=0.549 R@10=0.680 | median=4 p75=16 | queue=65536 | tau=0.090 | recentQ=16000\n",
      "[bigjump 06] loss=3.850924 | val_MRR=0.4109 | R@1=0.277 R@5=0.564 R@10=0.695 | median=4 p75=15 | queue=65536 | tau=0.085 | recentQ=65536\n",
      "[bigjump 07] loss=3.767136 | val_MRR=0.4188 | R@1=0.286 R@5=0.571 R@10=0.701 | median=4 p75=14 | queue=65536 | tau=0.080 | recentQ=65536\n",
      "[bigjump 08] loss=3.692709 | val_MRR=0.4256 | R@1=0.289 R@5=0.581 R@10=0.710 | median=4 p75=13 | queue=65536 | tau=0.075 | recentQ=65536\n",
      "[bigjump 09] loss=3.629012 | val_MRR=0.4327 | R@1=0.297 R@5=0.591 R@10=0.714 | median=4 p75=13 | queue=65536 | tau=0.070 | recentQ=65536\n",
      "[bigjump 10] loss=3.565447 | val_MRR=0.4383 | R@1=0.302 R@5=0.598 R@10=0.722 | median=4 p75=12 | queue=65536 | tau=0.066 | recentQ=65536\n",
      "[bigjump 11] loss=3.544977 | val_MRR=0.4423 | R@1=0.307 R@5=0.601 R@10=0.723 | median=3 p75=12 | queue=65536 | tau=0.063 | recentQ=65536\n",
      "[bigjump 12] loss=3.535456 | val_MRR=0.4467 | R@1=0.312 R@5=0.601 R@10=0.725 | median=3 p75=12 | queue=65536 | tau=0.061 | recentQ=65536\n",
      "[bigjump 13] loss=3.555670 | val_MRR=0.4474 | R@1=0.313 R@5=0.606 R@10=0.728 | median=3 p75=12 | queue=65536 | tau=0.060 | recentQ=65536\n",
      "[stage2] resume best epoch=13 MRR=0.44740885495820404\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/two_stage_push/submission.csv\n",
      "[ok] submission written → /kaggle/working/outputs/two_stage_push/submission.csv\n",
      "{\n",
      "  \"dims\": {\n",
      "    \"text\": 1024,\n",
      "    \"image\": 1536\n",
      "  },\n",
      "  \"split\": {\n",
      "    \"train_captions\": 112500,\n",
      "    \"val_captions\": 12500,\n",
      "    \"val_unique_images\": 2500,\n",
      "    \"leakage\": false\n",
      "  },\n",
      "  \"val_metrics\": {\n",
      "    \"MRR\": 0.44740885495820404,\n",
      "    \"R1\": 0.31264,\n",
      "    \"R5\": 0.6056,\n",
      "    \"R10\": 0.72752,\n",
      "    \"rank_median\": 3,\n",
      "    \"rank_p75\": 12\n",
      "  },\n",
      "  \"efficiency\": {\n",
      "    \"params\": 4198400,\n",
      "    \"mb_fp32\": 16.015625,\n",
      "    \"ms_per_query_gpu\": 0.0014920951798558235,\n",
      "    \"ms_per_query_cpu\": 0.03991997800767422\n",
      "  },\n",
      "  \"recipe\": {\n",
      "    \"stage1\": {\n",
      "      \"type\": \"simple_fixed_tau_infoNCE+triplet\",\n",
      "      \"tau_fixed\": 0.07,\n",
      "      \"triplet_margin\": 0.2,\n",
      "      \"triplet_w\": 0.3,\n",
      "      \"alpha_cos\": 0.0,\n",
      "      \"moment_w\": 0.0,\n",
      "      \"epochs\": 12,\n",
      "      \"use_pk\": false,\n",
      "      \"P\": 192,\n",
      "      \"K\": 3\n",
      "    },\n",
      "    \"stage2\": {\n",
      "      \"type\": \"bigjump_plus_small_queue_light_mining\",\n",
      "      \"epochs\": 13,\n",
      "      \"tau_sched\": [\n",
      "        0.1,\n",
      "        0.06\n",
      "      ],\n",
      "      \"queue_warmup_epochs\": 3,\n",
      "      \"queue_recent_schedule\": [\n",
      "        8000,\n",
      "        16000,\n",
      "        65536\n",
      "      ],\n",
      "      \"mine_H\": 32,\n",
      "      \"lambda_agree\": 0.02,\n",
      "      \"geom_unfreeze_epoch\": 0\n",
      "    },\n",
      "    \"centroid_procrustes\": true,\n",
      "    \"geom_frozen\": true,\n",
      "    \"residual_projection\": \"none\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "#        ARGPARSE\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    p = argparse.ArgumentParser(description=\"RoBERTa→DINOv2 | 2-Stage (Centroid-Procrustes Warmup → BigJump+)\")\n",
    "\n",
    "    # IO & run mode\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"two_stage_push\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--eval_only\", action=\"store_true\")\n",
    "\n",
    "    # data & split\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.10)\n",
    "\n",
    "    # architecture (we still build geom+adapter internally)\n",
    "    p.add_argument(\"--arch\", type=str, default=\"bigjump\",\n",
    "                   choices=[\"linear\",\"mlp1\",\"mlp2\",\"geom\",\"geom_adapter\",\"geom+adapter\",\"bigjump\"])\n",
    "\n",
    "    # optimization (shared)\n",
    "    p.add_argument(\"--epochs\", type=int, default=0, help=\"(unused; stages have their own epochs)\")\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=2e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "\n",
    "    # geometry init\n",
    "    p.add_argument(\"--geom_eps\", type=float, default=1e-5)\n",
    "\n",
    "    # pooling (no-op)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\"])\n",
    "\n",
    "    # ---------- STAGE 1 (Simple: fixed-τ InfoNCE + Triplet, in-batch negatives) ----------\n",
    "    p.add_argument(\"--stage1_epochs\", type=int, default=12)\n",
    "    p.add_argument(\"--tau\", type=float, default=0.07, help=\"Fixed InfoNCE temperature for Stage 1.\")\n",
    "    p.add_argument(\"--triplet_margin\", type=float, default=0.2)\n",
    "    p.add_argument(\"--triplet_w\", type=float, default=0.3, help=\"Triplet weight; InfoNCE weight = 1 - triplet_w.\")\n",
    "    p.add_argument(\"--alpha\", type=float, default=0.0, help=\"Cosine auxiliary weight in Stage 1.\")\n",
    "    p.add_argument(\"--moment\", type=float, default=0.0, help=\"Moment alignment weight in Stage 1.\")\n",
    "\n",
    "    # Optional PK sampler (both stages)\n",
    "    p.add_argument(\"--use_pk\", action=\"store_true\")\n",
    "    p.add_argument(\"--P\", type=int, default=192)\n",
    "    p.add_argument(\"--K_pk\", type=int, default=3)\n",
    "\n",
    "    # ---------- STAGE 2 (BigJump+: small late queue, light mining, tiny agreement) ----------\n",
    "    p.add_argument(\"--stage2_epochs\", type=int, default=13)\n",
    "    p.add_argument(\"--tau_start\", type=float, default=0.10)\n",
    "    p.add_argument(\"--tau_end\",   type=float, default=0.06)\n",
    "\n",
    "    p.add_argument(\"--queue\", type=int, default=65536)\n",
    "    p.add_argument(\"--queue_warmup_epochs\", type=int, default=3)\n",
    "    p.add_argument(\"--queue_recent_k\", type=int, nargs=3, default=[8000, 16000, 65536])\n",
    "\n",
    "    p.add_argument(\"--mine_H\", type=int, default=32, help=\"Top-H hard negatives per anchor (recent queue slice).\")\n",
    "    p.add_argument(\"--lambda_agree\", type=float, default=0.02, help=\"Caption-agreement weight (tiny).\")\n",
    "    p.add_argument(\"--alpha_stage2\", type=float, default=0.3, help=\"Cosine auxiliary in Stage 2.\")\n",
    "    p.add_argument(\"--moment_stage2\", type=float, default=0.01, help=\"Moment alignment in Stage 2.\")\n",
    "    p.add_argument(\"--geom_lr_scale\", type=float, default=0.05)\n",
    "\n",
    "    # XBP / DCL / dual-queue toggles (kept for completeness; default off/safe)\n",
    "    p.add_argument(\"--xbp_per_img\", type=int, default=4)\n",
    "    p.add_argument(\"--xbp_global\", type=int, default=32000)\n",
    "    p.add_argument(\"--use_dcl\", action=\"store_true\")\n",
    "    p.add_argument(\"--dcl_prior\", type=float, default=0.01)\n",
    "    p.add_argument(\"--queue_pred_capacity\", type=int, default=65536)\n",
    "\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T22:12:09.602521Z",
     "iopub.status.busy": "2025-10-29T22:12:09.601748Z",
     "iopub.status.idle": "2025-10-29T22:20:47.185984Z",
     "shell.execute_reply": "2025-10-29T22:20:47.184961Z",
     "shell.execute_reply.started": "2025-10-29T22:12:09.602494Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[meta] text_dim=1024 | image_dim=1536\n",
      "[geometry] Computing variance-weighted centroid Procrustes...\n",
      "\n",
      "============================================================\n",
      "[STAGE 1] Enhanced warmup with smoother scheduling\n",
      "============================================================\n",
      "τ_fixed=0.070 | triplet_w=0.3 | margin=0.2\n",
      "epochs=15 | warmup_epochs=3 | lr=0.0002\n",
      "[simple 01] loss=2.491584 lr=0.000067 | val_MRR=0.3375 | R@1=0.216 R@5=0.473 R@10=0.593 | median=6 p75=27\n",
      "[simple 02] loss=2.117398 lr=0.000133 | val_MRR=0.3561 | R@1=0.232 R@5=0.493 R@10=0.620 | median=6 p75=23\n",
      "[simple 03] loss=2.036331 lr=0.000200 | val_MRR=0.3671 | R@1=0.240 R@5=0.506 R@10=0.631 | median=5 p75=20\n",
      "[simple 04] loss=1.980336 lr=0.000197 | val_MRR=0.3740 | R@1=0.246 R@5=0.515 R@10=0.644 | median=5 p75=19\n",
      "[simple 05] loss=1.937702 lr=0.000187 | val_MRR=0.3814 | R@1=0.253 R@5=0.524 R@10=0.653 | median=5 p75=18\n",
      "[simple 06] loss=1.904336 lr=0.000171 | val_MRR=0.3864 | R@1=0.258 R@5=0.528 R@10=0.656 | median=5 p75=18\n",
      "[simple 07] loss=1.878786 lr=0.000150 | val_MRR=0.3902 | R@1=0.260 R@5=0.537 R@10=0.663 | median=5 p75=17\n",
      "[simple 08] loss=1.856548 lr=0.000126 | val_MRR=0.3918 | R@1=0.262 R@5=0.539 R@10=0.666 | median=5 p75=17\n",
      "[simple 09] loss=1.839005 lr=0.000100 | val_MRR=0.3956 | R@1=0.265 R@5=0.543 R@10=0.668 | median=5 p75=16\n",
      "[simple 10] loss=1.824579 lr=0.000074 | val_MRR=0.3965 | R@1=0.266 R@5=0.543 R@10=0.671 | median=4 p75=16\n",
      "[simple 11] loss=1.813318 lr=0.000050 | val_MRR=0.3966 | R@1=0.267 R@5=0.543 R@10=0.669 | median=4 p75=16\n",
      "[simple 12] loss=1.805618 lr=0.000029 | val_MRR=0.3982 | R@1=0.268 R@5=0.546 R@10=0.674 | median=4 p75=16\n",
      "[simple 13] loss=1.799783 lr=0.000013 | val_MRR=0.3971 | R@1=0.266 R@5=0.544 R@10=0.676 | median=4 p75=16\n",
      "[simple 14] loss=1.796882 lr=0.000003 | val_MRR=0.3989 | R@1=0.269 R@5=0.545 R@10=0.672 | median=4 p75=16\n",
      "[simple 15] loss=1.795731 lr=0.000000 | val_MRR=0.3987 | R@1=0.268 R@5=0.547 R@10=0.675 | median=4 p75=16\n",
      "\n",
      "[stage1] Loaded best checkpoint: epoch=14 MRR=0.3989\n",
      "\n",
      "============================================================\n",
      "[STAGE 2] Enhanced BigJump++ with curriculum & EMA\n",
      "============================================================\n",
      "queue_warmup=5 | queue_schedule=[8000, 16000, 32000, 65536]\n",
      "mine_H=64 (curriculum) | τ_sched=0.100→0.050\n",
      "agree=0.02 | label_smoothing=0.05\n",
      "[bigjump 01] loss=2.069920 lr=0.000099 | val_MRR=0.3969 | R@1=0.267 R@5=0.542 R@10=0.673 | median=5 p75=16 | queue=OFF | tau=0.100 | recentQ=0\n",
      "[bigjump 02] loss=1.589986 lr=0.000097 | val_MRR=0.3987 | R@1=0.268 R@5=0.546 R@10=0.671 | median=4 p75=16 | queue=OFF | tau=0.097 | recentQ=0\n",
      "[bigjump 03] loss=1.505820 lr=0.000093 | val_MRR=0.3988 | R@1=0.268 R@5=0.546 R@10=0.673 | median=4 p75=16 | queue=OFF | tau=0.094 | recentQ=0\n",
      "[bigjump 04] loss=1.428583 lr=0.000088 | val_MRR=0.4014 | R@1=0.270 R@5=0.550 R@10=0.675 | median=4 p75=16 | queue=OFF | tau=0.091 | recentQ=0\n",
      "[bigjump 05] loss=1.364654 lr=0.000082 | val_MRR=0.4004 | R@1=0.269 R@5=0.551 R@10=0.674 | median=4 p75=16 | queue=OFF | tau=0.088 | recentQ=0\n",
      "[bigjump 06] loss=1.904947 lr=0.000075 | val_MRR=0.3984 | R@1=0.266 R@5=0.548 R@10=0.675 | median=4 p75=16 | queue=65536 | tau=0.085 | recentQ=8000\n",
      "[bigjump 07] loss=1.767747 lr=0.000067 | val_MRR=0.3967 | R@1=0.264 R@5=0.548 R@10=0.677 | median=4 p75=16 | queue=65536 | tau=0.082 | recentQ=8000\n",
      "[bigjump 08] loss=1.721908 lr=0.000059 | val_MRR=0.3979 | R@1=0.265 R@5=0.549 R@10=0.676 | median=4 p75=16 | queue=65536 | tau=0.079 | recentQ=8000\n",
      "[bigjump 09] loss=1.667368 lr=0.000050 | val_MRR=0.3996 | R@1=0.267 R@5=0.552 R@10=0.681 | median=4 p75=16 | queue=65536 | tau=0.076 | recentQ=16000\n",
      "[bigjump 10] loss=1.610115 lr=0.000042 | val_MRR=0.4028 | R@1=0.270 R@5=0.554 R@10=0.683 | median=4 p75=15 | queue=65536 | tau=0.074 | recentQ=16000\n",
      "[bigjump 11] loss=1.557463 lr=0.000034 | val_MRR=0.4050 | R@1=0.271 R@5=0.559 R@10=0.687 | median=4 p75=15 | queue=65536 | tau=0.071 | recentQ=16000\n",
      "[bigjump 12] loss=1.508977 lr=0.000026 | val_MRR=0.4084 | R@1=0.275 R@5=0.562 R@10=0.689 | median=4 p75=15 | queue=65536 | tau=0.068 | recentQ=32000\n",
      "[bigjump 13] loss=1.451780 lr=0.000019 | val_MRR=0.4125 | R@1=0.278 R@5=0.567 R@10=0.696 | median=4 p75=15 | queue=65536 | tau=0.065 | recentQ=32000\n",
      "[bigjump 14] loss=1.411566 lr=0.000013 | val_MRR=0.4174 | R@1=0.283 R@5=0.573 R@10=0.699 | median=4 p75=14 | queue=65536 | tau=0.062 | recentQ=32000\n",
      "[bigjump 15] loss=1.363872 lr=0.000008 | val_MRR=0.4206 | R@1=0.285 R@5=0.578 R@10=0.702 | median=4 p75=14 | queue=65536 | tau=0.059 | recentQ=65536\n",
      "[bigjump 16] loss=1.317391 lr=0.000004 | val_MRR=0.4287 | R@1=0.295 R@5=0.582 R@10=0.708 | median=4 p75=14 | queue=65536 | tau=0.056 | recentQ=65536\n",
      "[bigjump 17] loss=1.255629 lr=0.000002 | val_MRR=0.4302 | R@1=0.296 R@5=0.587 R@10=0.711 | median=4 p75=13 | queue=65536 | tau=0.053 | recentQ=65536\n",
      "[bigjump 18] loss=1.224884 lr=0.000001 | val_MRR=0.4321 | R@1=0.296 R@5=0.590 R@10=0.712 | median=4 p75=13 | queue=65536 | tau=0.050 | recentQ=65536\n",
      "[stage2] Loading EMA checkpoint\n",
      "\n",
      "[stage2] Loaded best checkpoint: epoch=18 MRR=0.4321\n",
      "\n",
      "============================================================\n",
      "[SUBMISSION] Generating predictions...\n",
      "============================================================\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/enhanced_two_stage/submission.csv\n",
      "✓ Submission saved to /kaggle/working/outputs/enhanced_two_stage/submission.csv\n",
      "\n",
      "============================================================\n",
      "[FINAL REPORT]\n",
      "============================================================\n",
      "{\n",
      "  \"dims\": {\n",
      "    \"text\": 1024,\n",
      "    \"image\": 1536\n",
      "  },\n",
      "  \"split\": {\n",
      "    \"train_captions\": 112500,\n",
      "    \"val_captions\": 12500,\n",
      "    \"val_unique_images\": 2500,\n",
      "    \"leakage\": false\n",
      "  },\n",
      "  \"val_metrics\": {\n",
      "    \"MRR\": 0.43212303553710374,\n",
      "    \"R1\": 0.296,\n",
      "    \"R5\": 0.58984,\n",
      "    \"R10\": 0.71248,\n",
      "    \"rank_median\": 4,\n",
      "    \"rank_p75\": 13\n",
      "  },\n",
      "  \"efficiency\": {\n",
      "    \"params\": 4200448,\n",
      "    \"mb_fp32\": 16.0234375,\n",
      "    \"ms_per_query_gpu\": 0.0015586847439408302,\n",
      "    \"ms_per_query_cpu\": 0.04755903501063585\n",
      "  },\n",
      "  \"recipe\": {\n",
      "    \"geometry\": {\n",
      "      \"type\": \"variance_weighted_centroid_procrustes\",\n",
      "      \"eps\": 1e-05,\n",
      "      \"frozen\": true\n",
      "    },\n",
      "    \"stage1\": {\n",
      "      \"type\": \"enhanced_warmup_infoNCE+triplet\",\n",
      "      \"tau_fixed\": 0.07,\n",
      "      \"triplet_margin\": 0.2,\n",
      "      \"triplet_w\": 0.3,\n",
      "      \"alpha_cos\": 0.0,\n",
      "      \"moment_w\": 0.0,\n",
      "      \"epochs\": 15,\n",
      "      \"warmup_epochs\": 3,\n",
      "      \"lr_schedule\": \"cosine_with_warmup\",\n",
      "      \"use_pk\": false,\n",
      "      \"P\": 192,\n",
      "      \"K\": 3\n",
      "    },\n",
      "    \"stage2\": {\n",
      "      \"type\": \"bigjump_plus_plus_curriculum_ema\",\n",
      "      \"epochs\": 18,\n",
      "      \"tau_sched\": [\n",
      "        0.1,\n",
      "        0.05\n",
      "      ],\n",
      "      \"queue_warmup_epochs\": 5,\n",
      "      \"queue_recent_schedule\": [\n",
      "        8000,\n",
      "        16000,\n",
      "        32000,\n",
      "        65536\n",
      "      ],\n",
      "      \"mine_H\": 64,\n",
      "      \"mine_curriculum\": true,\n",
      "      \"lambda_agree\": 0.02,\n",
      "      \"label_smoothing\": 0.05,\n",
      "      \"use_ema\": true,\n",
      "      \"ema_decay\": 0.999,\n",
      "      \"alpha_cos\": 0.2,\n",
      "      \"moment\": 0.01\n",
      "    },\n",
      "    \"adapter\": {\n",
      "      \"hidden\": 1024,\n",
      "      \"dropout\": 0.1,\n",
      "      \"init_scale\": 0.25,\n",
      "      \"layernorm\": true,\n",
      "      \"orthogonalization\": \"svd\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "============================================================\n",
      "✓ Pipeline complete!\n",
      "  Best MRR: 0.4321\n",
      "  R@1: 0.296\n",
      "  R@5: 0.590\n",
      "  R@10: 0.712\n",
      "  Median rank: 4\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ResidualAdapter(nn.Module):\n",
    "    \"\"\"\n",
    "    Improved adapter with:\n",
    "    - Larger initialization for faster convergence\n",
    "    - Optional skip connection\n",
    "    - Layernorm for stability\n",
    "    \"\"\"\n",
    "    def __init__(self, din=1024, hidden=1024, dout=1536, pdrop=0.1, init_scale=0.25, use_layernorm=True):\n",
    "        super().__init__()\n",
    "        self.use_layernorm = use_layernorm\n",
    "        if use_layernorm:\n",
    "            self.ln = nn.LayerNorm(din)\n",
    "        self.fc1 = nn.Linear(din, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, dout)\n",
    "        self.drop = nn.Dropout(pdrop)\n",
    "        \n",
    "        # Better initialization\n",
    "        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_in', nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        \n",
    "        # Scale up initialization for faster learning\n",
    "        with torch.no_grad():\n",
    "            self.fc1.weight.mul_(init_scale)\n",
    "            self.fc2.weight.mul_(init_scale)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.use_layernorm:\n",
    "            x = self.ln(x)\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = self.drop(h)\n",
    "        return self.fc2(h)\n",
    "\n",
    "\n",
    "class GeomWithAdapter(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced geometry + residual model with:\n",
    "    - Better orthogonalization (uses SVD-based projection)\n",
    "    - Optional EMA for stability\n",
    "    - Gradient checkpointing support\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, A: np.ndarray, b: np.ndarray,\n",
    "        din=1024, dout=1536, hidden=1024, pdrop=0.1,\n",
    "        residual_ortho: str = \"project\",\n",
    "        ortho_eps: float = 1e-4,\n",
    "        ortho_lambda: float = 0.05,\n",
    "        unfreeze_bias: bool = False,\n",
    "        use_layernorm: bool = True,\n",
    "        init_scale: float = 0.25,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.geom = GeomLinear(A, b)\n",
    "        self.adapter = ResidualAdapter(\n",
    "            din=din, hidden=hidden, dout=dout, pdrop=pdrop, \n",
    "            init_scale=init_scale, use_layernorm=use_layernorm\n",
    "        )\n",
    "        \n",
    "        # Freeze geometry initially\n",
    "        for p in self.geom.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # Orthogonalization config\n",
    "        assert residual_ortho in (\"project\", \"penalty\", \"none\", \"svd\")\n",
    "        self.residual_ortho = residual_ortho\n",
    "        self.ortho_lambda = float(ortho_lambda)\n",
    "        self.ortho = ResidualOrthogonalizer(eps=float(ortho_eps))\n",
    "        self._unfreeze_bias = bool(unfreeze_bias)\n",
    "        \n",
    "        # Cache for SVD-based projection (faster than iterative)\n",
    "        self._svd_projector = None\n",
    "        self._last_A_hash = None\n",
    "    \n",
    "    def unfreeze_geom(self, weight_lr_scale=0.05):\n",
    "        self.geom.fc.weight.requires_grad = True\n",
    "        if self._unfreeze_bias:\n",
    "            self.geom.fc.bias.requires_grad = True\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _build_svd_projector(self, A: torch.Tensor):\n",
    "        \"\"\"Build orthogonal projector using SVD (more stable than Gram inverse)\"\"\"\n",
    "        A_hash = hash(A.data_ptr())\n",
    "        if self._svd_projector is not None and self._last_A_hash == A_hash:\n",
    "            return self._svd_projector\n",
    "        \n",
    "        device = A.device\n",
    "        A32 = A.detach().to(dtype=torch.float32)\n",
    "        \n",
    "        # U @ S @ Vt = A, shape (1536, 1024)\n",
    "        U, S, Vt = torch.linalg.svd(A32, full_matrices=False)\n",
    "        # Projector onto column space: P = U @ U^T\n",
    "        # Orthogonal complement: I - P\n",
    "        # For residual r in R^1536, we want (I - UU^T)r\n",
    "        \n",
    "        self._svd_projector = U @ U.T  # (1536, 1536)\n",
    "        self._last_A_hash = A_hash\n",
    "        return self._svd_projector\n",
    "    \n",
    "    def forward(self, x, return_ortho_penalty: bool = False):\n",
    "        g = self.geom(x)  # (B, 1536)\n",
    "        r = self.adapter(x)  # (B, 1536)\n",
    "        \n",
    "        penalty = r.new_tensor(0.0)\n",
    "        \n",
    "        if self.residual_ortho == \"svd\":\n",
    "            # Fast SVD-based projection\n",
    "            A = self.geom.fc.weight\n",
    "            P = self._build_svd_projector(A).to(r.device)\n",
    "            device_type = \"cuda\" if r.device.type == \"cuda\" else \"cpu\"\n",
    "            with torch.autocast(device_type=device_type, enabled=False):\n",
    "                r32 = r.to(torch.float32)\n",
    "                # Project out the column space: r_orth = r - P @ r\n",
    "                r_orth = r32 - (P @ r32.T).T\n",
    "                r = r_orth.to(r.dtype)\n",
    "            y = g + r\n",
    "            \n",
    "        elif self.residual_ortho == \"project\":\n",
    "            # Original Gram-based projection\n",
    "            A = self.geom.fc.weight\n",
    "            device_type = \"cuda\" if g.device.type == \"cuda\" else \"cpu\"\n",
    "            with torch.autocast(device_type=device_type, enabled=False):\n",
    "                r = self.ortho.project_residual(r, A)\n",
    "            y = g + r\n",
    "            \n",
    "        elif self.residual_ortho == \"penalty\":\n",
    "            # Soft orthogonality penalty\n",
    "            g_n = F.normalize(g, dim=-1)\n",
    "            r_n = F.normalize(r, dim=-1)\n",
    "            dot = torch.sum(g_n * r_n, dim=-1)\n",
    "            penalty = torch.mean(dot * dot)\n",
    "            y = g + r\n",
    "            \n",
    "        else:  # \"none\"\n",
    "            y = g + r\n",
    "        \n",
    "        if return_ortho_penalty:\n",
    "            return y, penalty\n",
    "        return y\n",
    "\n",
    "\n",
    "# ---------- Residual Orthogonalization with SVD fallback ----------\n",
    "class ResidualOrthogonalizer:\n",
    "    \"\"\"Enhanced orthogonalizer with SVD fallback for numerical stability\"\"\"\n",
    "    def __init__(self, eps: float = 1e-4, use_svd_fallback: bool = True):\n",
    "        self.eps = float(eps)\n",
    "        self.use_svd_fallback = use_svd_fallback\n",
    "        self._cached_invG = None\n",
    "        self._cached_A_hash = None\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _hash_weight(self, A: torch.Tensor) -> tuple[int, int]:\n",
    "        h = (A.shape[0], A.shape[1])\n",
    "        sample = A.reshape(-1)[:1024] if A.numel() >= 1024 else A.reshape(-1)\n",
    "        checksum = int(torch.sum((sample.float() * 1e3).round()).item())\n",
    "        return (h[0] * 10_000 + h[1], checksum)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def refresh(self, A: torch.Tensor):\n",
    "        dev = A.device\n",
    "        device_type = \"cuda\" if dev.type == \"cuda\" else \"cpu\"\n",
    "        with torch.autocast(device_type=device_type, enabled=False):\n",
    "            A32 = A.detach().to(dev, dtype=torch.float32)\n",
    "            key = self._hash_weight(A32)\n",
    "            \n",
    "            if key == self._cached_A_hash and self._cached_invG is not None and self._cached_invG.device == dev:\n",
    "                return\n",
    "            \n",
    "            G = A32.transpose(0, 1) @ A32  # (1024, 1024)\n",
    "            G = G + self.eps * torch.eye(G.shape[0], device=dev, dtype=torch.float32)\n",
    "            \n",
    "            try:\n",
    "                L = torch.linalg.cholesky(G)\n",
    "                invG = torch.cholesky_inverse(L)\n",
    "            except RuntimeError:\n",
    "                if self.use_svd_fallback:\n",
    "                    # Use SVD-based pseudoinverse\n",
    "                    U, S, Vt = torch.linalg.svd(G)\n",
    "                    S_inv = torch.where(S > self.eps, 1.0 / S, torch.zeros_like(S))\n",
    "                    invG = (Vt.T * S_inv) @ Vt\n",
    "                else:\n",
    "                    try:\n",
    "                        invG = torch.linalg.inv(G)\n",
    "                    except RuntimeError:\n",
    "                        invG = torch.linalg.pinv(G)\n",
    "            \n",
    "            self._cached_invG = invG\n",
    "            self._cached_A_hash = key\n",
    "    \n",
    "    def project_residual(self, R: torch.Tensor, A: torch.Tensor) -> torch.Tensor:\n",
    "        dev = R.device\n",
    "        device_type = \"cuda\" if dev.type == \"cuda\" else \"cpu\"\n",
    "        with torch.autocast(device_type=device_type, enabled=False):\n",
    "            self.refresh(A)\n",
    "            A32 = A.to(dtype=torch.float32, device=dev)\n",
    "            R32 = R.to(dtype=torch.float32, device=dev)\n",
    "            invG = self._cached_invG\n",
    "            if invG.device != dev:\n",
    "                invG = invG.to(dev)\n",
    "            \n",
    "            Z = R32 @ A32\n",
    "            Z = Z @ invG\n",
    "            R_proj = Z @ A32.transpose(0, 1)\n",
    "            R_orth = R32 - R_proj\n",
    "            return R_orth.to(dtype=R.dtype, device=dev)\n",
    "\n",
    "\n",
    "# ---------- Enhanced Agreement Loss with Temperature ----------\n",
    "def agreement_loss(names, preds, eps=1e-8, temperature=0.5):\n",
    "    \"\"\"\n",
    "    Enhanced agreement loss with temperature scaling.\n",
    "    Encourages captions of the same image to have similar predictions.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        groups = {}\n",
    "        for i, n in enumerate(map(str, names)):\n",
    "            groups.setdefault(n, []).append(i)\n",
    "        valid = [idxs for idxs in groups.values() if len(idxs) >= 2]\n",
    "    \n",
    "    if not valid:\n",
    "        return preds.new_tensor(0.0)\n",
    "    \n",
    "    z = F.normalize(preds, dim=-1)\n",
    "    vars_ = []\n",
    "    \n",
    "    for idxs in valid:\n",
    "        g = z[idxs]  # (K, D)\n",
    "        # Compute pairwise cosine similarities within group\n",
    "        sims = g @ g.T  # (K, K)\n",
    "        # Apply temperature to sharpen/soften\n",
    "        sims = sims / temperature\n",
    "        # We want high similarity, so loss is negative mean off-diagonal\n",
    "        mask = ~torch.eye(len(idxs), dtype=torch.bool, device=sims.device)\n",
    "        if mask.sum() > 0:\n",
    "            group_coherence = sims[mask].mean()\n",
    "            # Loss is negative similarity (we want to maximize similarity)\n",
    "            vars_.append(-group_coherence)\n",
    "    \n",
    "    if len(vars_) == 0:\n",
    "        return preds.new_tensor(0.0)\n",
    "    \n",
    "    return torch.stack(vars_).mean()\n",
    "\n",
    "\n",
    "# ---------- Enhanced Image Queue with Diversity Tracking ----------\n",
    "class ImgQueue:\n",
    "    \"\"\"Enhanced queue with diversity tracking to avoid redundant negatives\"\"\"\n",
    "    def __init__(self, dim: int, capacity: int, device: torch.device, track_diversity: bool = True):\n",
    "        self.capacity = int(capacity)\n",
    "        self.device = device\n",
    "        self.ptr = 0\n",
    "        self.full = False\n",
    "        self.bank = torch.zeros(self.capacity, dim, device=device)\n",
    "        self.track_diversity = track_diversity\n",
    "        \n",
    "        if track_diversity:\n",
    "            # Track image IDs to avoid duplicate negatives from same image\n",
    "            self.img_ids = torch.zeros(self.capacity, dtype=torch.long, device=device)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def enqueue(self, feats: torch.Tensor, img_ids: list[str] = None):\n",
    "        feats = feats.detach()\n",
    "        n = feats.size(0)\n",
    "        \n",
    "        if n >= self.capacity:\n",
    "            self.bank.copy_(feats[-self.capacity:])\n",
    "            if self.track_diversity and img_ids is not None:\n",
    "                ids = torch.tensor([hash(str(i)) for i in img_ids[-self.capacity:]], \n",
    "                                 dtype=torch.long, device=self.device)\n",
    "                self.img_ids.copy_(ids)\n",
    "            self.ptr = 0\n",
    "            self.full = True\n",
    "            return\n",
    "        \n",
    "        end = self.ptr + n\n",
    "        if end <= self.capacity:\n",
    "            self.bank[self.ptr:end] = feats\n",
    "            if self.track_diversity and img_ids is not None:\n",
    "                ids = torch.tensor([hash(str(i)) for i in img_ids], \n",
    "                                 dtype=torch.long, device=self.device)\n",
    "                self.img_ids[self.ptr:end] = ids\n",
    "        else:\n",
    "            cut = self.capacity - self.ptr\n",
    "            self.bank[self.ptr:] = feats[:cut]\n",
    "            self.bank[:end - self.capacity] = feats[cut:]\n",
    "            if self.track_diversity and img_ids is not None:\n",
    "                ids = torch.tensor([hash(str(i)) for i in img_ids], \n",
    "                                 dtype=torch.long, device=self.device)\n",
    "                self.img_ids[self.ptr:] = ids[:cut]\n",
    "                self.img_ids[:end - self.capacity] = ids[cut:]\n",
    "        \n",
    "        self.ptr = (self.ptr + n) % self.capacity\n",
    "        if self.ptr == 0:\n",
    "            self.full = True\n",
    "    \n",
    "    def size(self) -> int:\n",
    "        if self.full:\n",
    "            return self.capacity\n",
    "        return self.ptr\n",
    "    \n",
    "    def get(self) -> torch.Tensor:\n",
    "        if self.size() == 0:\n",
    "            return self.bank[:0]\n",
    "        if self.full:\n",
    "            return torch.cat([self.bank[self.ptr:], self.bank[:self.ptr]], dim=0)\n",
    "        return self.bank[:self.ptr]\n",
    "    \n",
    "    def recent(self, max_items: int) -> torch.Tensor:\n",
    "        q = self.get()\n",
    "        if q is None or q.numel() == 0:\n",
    "            return q\n",
    "        if max_items is None or q.size(0) <= int(max_items):\n",
    "            return q\n",
    "        return q[-int(max_items):]\n",
    "    \n",
    "    def get_with_ids(self):\n",
    "        \"\"\"Return features and image IDs together\"\"\"\n",
    "        feats = self.get()\n",
    "        if not self.track_diversity or feats.numel() == 0:\n",
    "            return feats, None\n",
    "        \n",
    "        if self.full:\n",
    "            ids = torch.cat([self.img_ids[self.ptr:], self.img_ids[:self.ptr]], dim=0)\n",
    "        else:\n",
    "            ids = self.img_ids[:self.ptr]\n",
    "        return feats, ids\n",
    "\n",
    "\n",
    "# ---------- Enhanced Hard Mining with Curriculum ----------\n",
    "@torch.no_grad()\n",
    "def mine_hard_curriculum(\n",
    "    q_recent: torch.Tensor, \n",
    "    pred: torch.Tensor, \n",
    "    H: int, \n",
    "    epoch: int,\n",
    "    total_epochs: int,\n",
    "    curriculum_start_H: int = 16,\n",
    "    batch_img_ids: list[str] = None,\n",
    "    queue_img_ids: torch.Tensor = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Hard negative mining with curriculum:\n",
    "    - Start with easier negatives (medium similarity)\n",
    "    - Gradually increase difficulty (high similarity)\n",
    "    - Filter out false negatives (same image ID)\n",
    "    \"\"\"\n",
    "    if q_recent is None or q_recent.numel() == 0 or H <= 0:\n",
    "        return None, None, None\n",
    "    \n",
    "    B = pred.size(0)\n",
    "    Q = q_recent.size(0)\n",
    "    sims = pred @ q_recent.t()  # (B, Q)\n",
    "    \n",
    "    # Curriculum: gradually increase H from curriculum_start_H to H\n",
    "    progress = epoch / max(1, total_epochs)\n",
    "    current_H = int(curriculum_start_H + (H - curriculum_start_H) * progress)\n",
    "    current_H = min(current_H, Q)\n",
    "    \n",
    "    # Filter out false negatives (captions from same image)\n",
    "    if batch_img_ids is not None and queue_img_ids is not None:\n",
    "        batch_ids_hashed = torch.tensor([hash(str(i)) for i in batch_img_ids], \n",
    "                                       device=pred.device, dtype=torch.long)\n",
    "        # Create mask: (B, Q) where True means \"valid negative\"\n",
    "        mask = torch.ones(B, Q, dtype=torch.bool, device=pred.device)\n",
    "        for i, bid in enumerate(batch_ids_hashed):\n",
    "            mask[i, :] = queue_img_ids != bid\n",
    "        # Set invalid negatives to very low similarity\n",
    "        sims = sims.masked_fill(~mask, -1e9)\n",
    "    \n",
    "    # Mine top-K hardest\n",
    "    _, idx = torch.topk(sims, k=current_H, dim=1, largest=True, sorted=False)\n",
    "    flat_idx = idx.reshape(-1)\n",
    "    mined = q_recent.index_select(0, flat_idx)\n",
    "    \n",
    "    return idx, flat_idx, mined\n",
    "\n",
    "\n",
    "# ---------- Enhanced Multi-Positive InfoNCE ----------\n",
    "def info_nce_multi_enhanced(\n",
    "    pred,\n",
    "    batch_img_targets,\n",
    "    batch_img_names,\n",
    "    queue_feats=None,\n",
    "    queue_img_ids=None,\n",
    "    tau: float = 0.07,\n",
    "    xbp_bank: torch.Tensor = None,\n",
    "    xbp_pos_cols_per_row: list[list[int]] = None,\n",
    "    hard_subset_H: int = 0,\n",
    "    use_dcl: bool = False,\n",
    "    dcl_prior: float = 0.01,\n",
    "    epoch: int = 0,\n",
    "    total_epochs: int = 1,\n",
    "    label_smoothing: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced InfoNCE with:\n",
    "    - Curriculum hard mining\n",
    "    - Label smoothing\n",
    "    - Better false negative filtering\n",
    "    \"\"\"\n",
    "    p = F.normalize(pred, dim=-1)\n",
    "    t = F.normalize(batch_img_targets, dim=-1)\n",
    "    \n",
    "    bank_blocks = [t]\n",
    "    B = pred.size(0)\n",
    "    \n",
    "    # Hard mining with curriculum\n",
    "    if queue_feats is not None and queue_feats.numel() > 0:\n",
    "        qn = F.normalize(queue_feats, dim=-1)\n",
    "        if hard_subset_H and hard_subset_H > 0:\n",
    "            _, _, mined_block = mine_hard_curriculum(\n",
    "                qn, p, hard_subset_H, epoch, total_epochs,\n",
    "                curriculum_start_H=max(8, hard_subset_H // 4),\n",
    "                batch_img_ids=batch_img_names,\n",
    "                queue_img_ids=queue_img_ids,\n",
    "            )\n",
    "            if mined_block is not None:\n",
    "                bank_blocks.append(mined_block)\n",
    "        else:\n",
    "            bank_blocks.append(qn)\n",
    "    \n",
    "    # XBP block\n",
    "    xbp_offsets = None\n",
    "    if xbp_bank is not None and xbp_bank.numel() > 0:\n",
    "        xbp_offsets = sum(b.size(0) for b in bank_blocks)\n",
    "        bank_blocks.append(xbp_bank)\n",
    "    \n",
    "    bank = torch.cat(bank_blocks, dim=0) if len(bank_blocks) > 1 else bank_blocks[0]\n",
    "    logits = (p @ bank.t()) / float(tau)\n",
    "    K = bank.size(0)\n",
    "    \n",
    "    # Build positive mask\n",
    "    pos_mask = torch.zeros(B, K, dtype=torch.bool, device=pred.device)\n",
    "    names = list(map(str, batch_img_names))\n",
    "    for i in range(B):\n",
    "        for j in range(B):\n",
    "            if names[i] == names[j]:\n",
    "                pos_mask[i, j] = True\n",
    "    \n",
    "    if xbp_offsets is not None and xbp_pos_cols_per_row is not None:\n",
    "        for i, cols in enumerate(xbp_pos_cols_per_row):\n",
    "            for c in cols:\n",
    "                pos_mask[i, xbp_offsets + c] = True\n",
    "    \n",
    "    assert pos_mask.any(dim=1).all(), \"Every row must have at least one positive.\"\n",
    "    \n",
    "    # Denominator\n",
    "    if not use_dcl:\n",
    "        logZ = torch.logsumexp(logits, dim=1)\n",
    "    else:\n",
    "        logZ = _debiased_logZ(logits, pos_mask, class_prior=float(dcl_prior))\n",
    "    \n",
    "    # Numerator with label smoothing\n",
    "    logits_pos = logits.masked_fill(~pos_mask, float('-inf'))\n",
    "    logPos = torch.logsumexp(logits_pos, dim=1)\n",
    "    \n",
    "    loss = -(logPos - logZ).mean()\n",
    "    \n",
    "    # Apply label smoothing if specified\n",
    "    if label_smoothing > 0:\n",
    "        # Uniform distribution over all negatives\n",
    "        logits_neg = logits.masked_fill(pos_mask, float('-inf'))\n",
    "        smooth_loss = -torch.logsumexp(logits_neg, dim=1).mean()\n",
    "        loss = (1 - label_smoothing) * loss + label_smoothing * smooth_loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def _debiased_logZ(logits: torch.Tensor, pos_mask: torch.Tensor, class_prior: float = 0.01):\n",
    "    \"\"\"Debiased contrastive learning denominator\"\"\"\n",
    "    exp_all = torch.exp(logits)\n",
    "    exp_pos = exp_all * pos_mask\n",
    "    Z = exp_all.sum(dim=1)\n",
    "    corr = class_prior * exp_pos.sum(dim=1)\n",
    "    Z_star = torch.clamp(Z - corr, min=1e-8)\n",
    "    return torch.log(Z_star)\n",
    "\n",
    "\n",
    "# ---------- Variance-Weighted Procrustes ----------\n",
    "def procrustes_closed_form_centroids_weighted(\n",
    "    X_rows: np.ndarray, \n",
    "    Y_rows: np.ndarray, \n",
    "    img_names_rows: np.ndarray, \n",
    "    eps: float = 1e-5,\n",
    "    use_variance_weighting: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced Procrustes with optional variance weighting:\n",
    "    - Images with more diverse captions get higher weight\n",
    "    - Prevents overfitting to images with homogeneous captions\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    buckets_x = defaultdict(list)\n",
    "    buckets_y = defaultdict(list)\n",
    "    for x, y, n in zip(X_rows, Y_rows, map(str, img_names_rows)):\n",
    "        buckets_x[n].append(x)\n",
    "        buckets_y[n].append(y)\n",
    "    \n",
    "    order_names = sorted(buckets_x.keys())\n",
    "    \n",
    "    # Compute centroids and optionally weights\n",
    "    Xc_list, Yc_list, weights = [], [], []\n",
    "    for n in order_names:\n",
    "        x_group = np.array(buckets_x[n])\n",
    "        y_group = np.array(buckets_y[n])\n",
    "        \n",
    "        xc = np.mean(x_group, axis=0)\n",
    "        yc = np.mean(y_group, axis=0)\n",
    "        \n",
    "        Xc_list.append(xc)\n",
    "        Yc_list.append(yc)\n",
    "        \n",
    "        if use_variance_weighting:\n",
    "            # Weight by caption diversity (variance in text embeddings)\n",
    "            var = np.mean(np.var(x_group, axis=0))\n",
    "            weights.append(np.sqrt(var + 1e-8))\n",
    "        else:\n",
    "            weights.append(1.0)\n",
    "    \n",
    "    Xc = np.stack(Xc_list, axis=0).astype(np.float32)\n",
    "    Yc = np.stack(Yc_list, axis=0).astype(np.float32)\n",
    "    weights = np.array(weights, dtype=np.float32)\n",
    "    weights = weights / (weights.mean() + 1e-8)  # Normalize\n",
    "    \n",
    "    # Weighted Procrustes\n",
    "    W = np.diag(weights)\n",
    "    XcW = Xc * weights[:, None]\n",
    "    YcW = Yc * weights[:, None]\n",
    "    \n",
    "    mu_x = np.average(Xc, axis=0, weights=weights)\n",
    "    mu_y = np.average(Yc, axis=0, weights=weights)\n",
    "    \n",
    "    Xzc = XcW - mu_x\n",
    "    Yzc = YcW - mu_y\n",
    "    \n",
    "    def _cov_eigh(zc, eps):\n",
    "        S, U = np.linalg.eigh((zc.T @ zc) / max(1, zc.shape[0]))\n",
    "        S = np.clip(S, 0.0, None)\n",
    "        inv_sqrt = 1.0 / np.sqrt(S + eps)\n",
    "        sqrt = np.sqrt(S + eps)\n",
    "        C_mhalf = (U * inv_sqrt) @ U.T\n",
    "        C_phalf = (U * sqrt) @ U.T\n",
    "        return C_mhalf.astype(np.float32), C_phalf.astype(np.float32)\n",
    "    \n",
    "    Cx_mh, _ = _cov_eigh(Xzc, eps)\n",
    "    Cy_mh, Cy_ph = _cov_eigh(Yzc, eps)\n",
    "    \n",
    "    Xw = Xzc @ Cx_mh.T\n",
    "    Yw = Yzc @ Cy_mh.T\n",
    "    \n",
    "    M = Xw.T @ Yw\n",
    "    U, _, Vt = np.linalg.svd(M, full_matrices=False)\n",
    "    R = (U @ Vt).T\n",
    "    \n",
    "    A = (Cy_ph @ R @ Cx_mh).astype(np.float32)\n",
    "    b = (mu_y - (A @ mu_x)).astype(np.float32)\n",
    "    \n",
    "    return A, b\n",
    "\n",
    "\n",
    "# ---------- Keep existing PKBatchSampler, XBPBuffer, PredQueue, TripletCosineLoss ----------\n",
    "class PKBatchSampler(torch.utils.data.Sampler[list[int]]):\n",
    "    def __init__(self, img_ids: list[str], P: int, K: int, drop_last: bool = True, seed: int = 42):\n",
    "        self.by_img = {}\n",
    "        for idx, iid in enumerate(map(str, img_ids)):\n",
    "            self.by_img.setdefault(iid, []).append(idx)\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(seed)\n",
    "        for lst in self.by_img.values():\n",
    "            perm = torch.randperm(len(lst), generator=g).tolist()\n",
    "            lst[:] = [lst[i] for i in perm]\n",
    "        self.P, self.K, self.drop_last = int(P), int(K), bool(drop_last)\n",
    "        self.iids = list(self.by_img.keys())\n",
    "        self.cur = {iid: 0 for iid in self.iids}\n",
    "        self.pool = [iid for iid in self.iids if len(self.by_img[iid]) > 0]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        import random\n",
    "        pool = self.pool[:]\n",
    "        random.shuffle(pool)\n",
    "        batch = []\n",
    "        while len(pool) >= self.P:\n",
    "            pick = pool[:self.P]\n",
    "            pool = pool[self.P:]\n",
    "            for iid in pick:\n",
    "                start = self.cur[iid]\n",
    "                end = start + self.K\n",
    "                lst = self.by_img[iid]\n",
    "                if start >= len(lst):\n",
    "                    continue\n",
    "                take = lst[start:min(end, len(lst))]\n",
    "                self.cur[iid] = min(end, len(lst))\n",
    "                batch.extend(take)\n",
    "            if len(batch) == self.P * self.K:\n",
    "                yield batch\n",
    "            else:\n",
    "                if not self.drop_last and len(batch) > 0:\n",
    "                    yield batch\n",
    "                break\n",
    "            batch = []\n",
    "    \n",
    "    def __len__(self):\n",
    "        total = sum(len(v) // self.K for v in self.by_img.values())\n",
    "        return max(0, total // self.P)\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "class XBPBuffer:\n",
    "    def __init__(self, per_image_cap: int = 4, global_cap: int = 32000, device: torch.device = torch.device(\"cpu\")):\n",
    "        self.per_img = {}\n",
    "        self.order = deque()\n",
    "        self.per_image_cap = int(per_image_cap)\n",
    "        self.global_cap = int(global_cap)\n",
    "        self.device = device\n",
    "        self._count = 0\n",
    "        self._stamp = 0\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def add(self, img_ids: list[str], pred_feats: torch.Tensor):\n",
    "        feats = F.normalize(pred_feats.detach(), dim=-1)\n",
    "        for iid, f in zip(map(str, img_ids), feats):\n",
    "            dq = self.per_img.setdefault(iid, deque(maxlen=self.per_image_cap))\n",
    "            dq.append(f.to(self.device))\n",
    "            self.order.append((iid, self._stamp))\n",
    "            self._stamp += 1\n",
    "            self._count += 1\n",
    "            while self._count > self.global_cap:\n",
    "                old_iid, _ = self.order.popleft()\n",
    "                if self.per_img.get(old_iid):\n",
    "                    try:\n",
    "                        self.per_img[old_iid].popleft()\n",
    "                        self._count -= 1\n",
    "                        if len(self.per_img[old_iid]) == 0:\n",
    "                            self.per_img.pop(old_iid, None)\n",
    "                    except IndexError:\n",
    "                        pass\n",
    "    \n",
    "    def build_bank_and_mask(self, batch_img_names: list[str], device: torch.device):\n",
    "        rows = [str(x) for x in batch_img_names]\n",
    "        per_row_feats = []\n",
    "        row_counts = []\n",
    "        for iid in rows:\n",
    "            dq = self.per_img.get(iid, None)\n",
    "            if dq is None or len(dq) == 0:\n",
    "                row_counts.append(0)\n",
    "            else:\n",
    "                row_counts.append(len(dq))\n",
    "                per_row_feats.extend(list(dq))\n",
    "        if len(per_row_feats) == 0:\n",
    "            return torch.empty(0, 0, device=device), [[] for _ in rows]\n",
    "        xbp_bank = torch.stack(per_row_feats, dim=0).to(device)\n",
    "        xbp_pos_cols = []\n",
    "        offset = 0\n",
    "        for cnt in row_counts:\n",
    "            if cnt == 0:\n",
    "                xbp_pos_cols.append([])\n",
    "            else:\n",
    "                xbp_pos_cols.append(list(range(offset, offset + cnt)))\n",
    "                offset += cnt\n",
    "        return xbp_bank, xbp_pos_cols\n",
    "\n",
    "\n",
    "class PredQueue:\n",
    "    def __init__(self, dim: int, capacity: int, device: torch.device):\n",
    "        self.capacity = int(capacity)\n",
    "        self.device = device\n",
    "        self.ptr = 0\n",
    "        self.full = False\n",
    "        self.feats = torch.zeros(self.capacity, dim, device=device)\n",
    "        self.ids = torch.empty(self.capacity, dtype=torch.long, device=device)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def enqueue(self, feats: torch.Tensor, img_ids: list[str]):\n",
    "        feats = F.normalize(feats.detach(), dim=-1)\n",
    "        ids = torch.tensor([hash(str(i)) for i in img_ids], dtype=torch.long, device=self.device)\n",
    "        n = feats.size(0)\n",
    "        if n >= self.capacity:\n",
    "            self.feats.copy_(feats[-self.capacity:])\n",
    "            self.ids.copy_(ids[-self.capacity:])\n",
    "            self.ptr = 0\n",
    "            self.full = True\n",
    "            return\n",
    "        end = self.ptr + n\n",
    "        if end <= self.capacity:\n",
    "            self.feats[self.ptr:end] = feats\n",
    "            self.ids[self.ptr:end] = ids\n",
    "        else:\n",
    "            cut = self.capacity - self.ptr\n",
    "            self.feats[self.ptr:] = feats[:cut]\n",
    "            self.ids[self.ptr:] = ids[:cut]\n",
    "            self.feats[:end - self.capacity] = feats[cut:]\n",
    "            self.ids[:end - self.capacity] = ids[cut:]\n",
    "        self.ptr = (self.ptr + n) % self.capacity\n",
    "        if self.ptr == 0:\n",
    "            self.full = True\n",
    "    \n",
    "    def size(self) -> int:\n",
    "        if self.full:\n",
    "            return self.capacity\n",
    "        return self.ptr\n",
    "    \n",
    "    def recent(self, max_items: int):\n",
    "        n = self.size()\n",
    "        if n == 0:\n",
    "            return self.feats[:0], self.ids[:0]\n",
    "        k = min(int(max_items), n) if max_items is not None else n\n",
    "        if self.full:\n",
    "            idx = torch.arange(self.ptr - n, self.ptr, device=self.device) % self.capacity\n",
    "        else:\n",
    "            idx = torch.arange(0, n, device=self.device)\n",
    "        idx = idx[-k:]\n",
    "        return self.feats.index_select(0, idx), self.ids.index_select(0, idx)\n",
    "\n",
    "\n",
    "def info_nce_fixed(pred: torch.Tensor, tgt: torch.Tensor, tau: float):\n",
    "    logits = (pred @ tgt.t()) / float(tau)\n",
    "    labels = torch.arange(pred.size(0), device=pred.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "\n",
    "class TripletCosineLoss(nn.Module):\n",
    "    def __init__(self, margin: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.loss = nn.TripletMarginWithDistanceLoss(\n",
    "            distance_function=lambda x, y: 1 - F.cosine_similarity(x, y),\n",
    "            margin=margin\n",
    "        )\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        return self.loss(anchor, positive, negative)\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   ENHANCED STAGE 1 TRAINER\n",
    "# =========================\n",
    "def train_simple_enhanced(\n",
    "    model,\n",
    "    Xtr, Ytr, img_ids_row_tr,\n",
    "    Xva, val_gallery, cap2gal_local,\n",
    "    batch=512, epochs=25, lr=2e-4, wd=1e-4,\n",
    "    tau_fixed=0.07, triplet_margin=0.2, triplet_w=0.3,\n",
    "    alpha_cos=0.0,\n",
    "    moment_w=0.0,\n",
    "    use_pk=False, P=192, K_pk=3,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    pooling=\"none\", n_patches=None,\n",
    "    out_dir: \"Path | str\" = None, seed=42,\n",
    "    warmup_epochs=3,\n",
    "    use_cosine_schedule=True,\n",
    "    gradient_clip=1.0,\n",
    "):\n",
    "    \"\"\"Enhanced Stage 1 with warmup, cosine schedule, and better optimization\"\"\"\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    out_dir = Path(out_dir) if out_dir is not None else Path(\"./outputs/simple\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    seed_all(seed)\n",
    "    model.to(device)\n",
    "    \n",
    "    class TripletSet(torch.utils.data.Dataset):\n",
    "        def __init__(self, X_np, Y_np, names_np):\n",
    "            self.X = torch.from_numpy(X_np).float()\n",
    "            self.Y = torch.from_numpy(Y_np).float()\n",
    "            self.N = [str(n) for n in names_np.tolist()]\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "        def __getitem__(self, i):\n",
    "            return self.X[i], self.Y[i], self.N[i]\n",
    "    \n",
    "    ds = TripletSet(Xtr, Ytr, img_ids_row_tr)\n",
    "    \n",
    "    if use_pk:\n",
    "        pk_sampler = PKBatchSampler(img_ids_row_tr.tolist(), P=int(P), K=int(K_pk), drop_last=True, seed=seed)\n",
    "        dl = DataLoader(ds, batch_sampler=pk_sampler, num_workers=2, pin_memory=True)\n",
    "    else:\n",
    "        dl = DataLoader(ds, batch_size=batch, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    opt = torch.optim.AdamW(params, lr=lr, weight_decay=wd, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    # Enhanced scheduling with warmup\n",
    "    total_steps = epochs * len(dl)\n",
    "    warmup_steps = warmup_epochs * len(dl)\n",
    "    \n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            # Linear warmup\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        if use_cosine_schedule:\n",
    "            # Cosine annealing after warmup\n",
    "            progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "            return 0.5 * (1.0 + np.cos(np.pi * progress))\n",
    "        return 1.0\n",
    "    \n",
    "    sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
    "    \n",
    "    tri = TripletCosineLoss(margin=float(triplet_margin))\n",
    "    \n",
    "    best_stats, best_mrr, best_ep = None, -1.0, 0\n",
    "    \n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        \n",
    "        for xb, yb, _ in dl:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            \n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            \n",
    "            pred = model(xb)\n",
    "            pred = F.normalize(pred, dim=-1)\n",
    "            ybn = F.normalize(yb, dim=-1)\n",
    "            \n",
    "            # InfoNCE with fixed tau\n",
    "            loss_ce = info_nce_fixed(pred, ybn, tau=float(tau_fixed))\n",
    "            \n",
    "            # Triplet with shuffled negatives\n",
    "            idx = torch.randperm(xb.size(0), device=device)\n",
    "            loss_tri = tri(pred, ybn, ybn[idx])\n",
    "            \n",
    "            # Optional auxiliaries\n",
    "            loss_cos = (1.0 - F.cosine_similarity(pred, yb, dim=-1)).mean() if alpha_cos > 0 else pred.new_tensor(0.0)\n",
    "            loss_mu = moment_align(pred, yb) if moment_w > 0 else pred.new_tensor(0.0)\n",
    "            \n",
    "            loss = (1.0 - float(triplet_w)) * loss_ce + float(triplet_w) * loss_tri \\\n",
    "                   + float(alpha_cos) * loss_cos + float(moment_w) * loss_mu\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if gradient_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(params, gradient_clip)\n",
    "            \n",
    "            opt.step()\n",
    "            sched.step()\n",
    "            running += loss.item() * xb.size(0)\n",
    "        \n",
    "        stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "        ep_loss = running / len(ds)\n",
    "        current_lr = opt.param_groups[0]['lr']\n",
    "        \n",
    "        print(f\"[simple {ep:02d}] loss={ep_loss:.6f} lr={current_lr:.6f} | val_MRR={stats['MRR']:.4f} \"\n",
    "              f\"| R@1={stats['R1']:.3f} R@5={stats['R5']:.3f} R@10={stats['R10']:.3f} \"\n",
    "              f\"| median={stats['rank_median']} p75={stats['rank_p75']}\")\n",
    "        \n",
    "        if stats[\"MRR\"] > best_mrr:\n",
    "            best_mrr, best_ep, best_stats = stats[\"MRR\"], ep, stats\n",
    "            torch.save({\"model\": model.state_dict(), \"epoch\": ep, \"val\": stats}, out_dir / \"best.pt\")\n",
    "    \n",
    "    if best_stats is None:\n",
    "        best_stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "        torch.save({\"model\": model.state_dict(), \"epoch\": 0, \"val\": best_stats}, out_dir / \"best.pt\")\n",
    "    \n",
    "    (out_dir / \"val_metrics.json\").write_text(json.dumps(dict(best_epoch=best_ep, **best_stats), indent=2))\n",
    "    return best_stats\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   ENHANCED STAGE 2 TRAINER (BigJump++)\n",
    "# =========================\n",
    "def train_bigjump_enhanced(\n",
    "    model,\n",
    "    Xtr, Ytr, img_ids_row_tr,\n",
    "    Xva, val_gallery, cap2gal_local,\n",
    "    batch=512, epochs=20, base_lr=2e-4, wd=1e-4,\n",
    "    tau_start=0.10, tau_end=0.05,\n",
    "    queue_size=65536,\n",
    "    queue_warmup_epochs=4,\n",
    "    queue_recent_schedule=(8000, 16000, 32000, 65536),\n",
    "    mine_H=64,\n",
    "    lambda_agree=0.02,\n",
    "    alpha_cos=0.2,\n",
    "    lambda_moment=0.01,\n",
    "    use_pk=False, P=192, K_pk=3,\n",
    "    xbp_per_img=6,\n",
    "    xbp_global=48000,\n",
    "    use_dcl=False,\n",
    "    dcl_prior=0.01,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    pooling=\"none\", n_patches=None,\n",
    "    out_dir: \"Path | str\" = None,\n",
    "    seed=42,\n",
    "    use_ema=True,\n",
    "    ema_decay=0.999,\n",
    "    gradient_clip=1.0,\n",
    "    label_smoothing=0.05,\n",
    "):\n",
    "    \"\"\"\n",
    "    Enhanced BigJump trainer with:\n",
    "    - Smoother temperature schedule\n",
    "    - Later queue warmup\n",
    "    - Curriculum hard mining\n",
    "    - Optional EMA\n",
    "    - Label smoothing\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    out_dir = Path(out_dir) if out_dir is not None else Path(\"./outputs/bigjump\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    seed_all(seed)\n",
    "    model.to(device)\n",
    "    \n",
    "    class TripletSet(torch.utils.data.Dataset):\n",
    "        def __init__(self, X_np, Y_np, names_np):\n",
    "            self.X = torch.from_numpy(X_np).float()\n",
    "            self.Y = torch.from_numpy(Y_np).float()\n",
    "            self.N = [str(n) for n in names_np.tolist()]\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "        def __getitem__(self, i):\n",
    "            return self.X[i], self.Y[i], self.N[i]\n",
    "    \n",
    "    ds = TripletSet(Xtr, Ytr, img_ids_row_tr)\n",
    "    \n",
    "    if use_pk:\n",
    "        pk_sampler = PKBatchSampler(img_ids_row_tr.tolist(), P=int(P), K=int(K_pk), drop_last=True, seed=seed)\n",
    "        dl = DataLoader(ds, batch_sampler=pk_sampler, num_workers=2, pin_memory=True)\n",
    "    else:\n",
    "        dl = DataLoader(ds, batch_size=batch, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    opt = torch.optim.AdamW(params, lr=base_lr, weight_decay=wd, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    # Smoother cosine schedule\n",
    "    total_steps = epochs * len(dl)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=total_steps, eta_min=base_lr * 0.01)\n",
    "    \n",
    "    # EMA model (optional)\n",
    "    ema_model = None\n",
    "    if use_ema:\n",
    "        import copy\n",
    "        ema_model = copy.deepcopy(model)\n",
    "        for p in ema_model.parameters():\n",
    "            p.requires_grad = False\n",
    "    \n",
    "    # Queues and buffers\n",
    "    img_queue = ImgQueue(dim=1536, capacity=queue_size, device=device, track_diversity=True)\n",
    "    xbp_buffer = XBPBuffer(per_image_cap=xbp_per_img, global_cap=xbp_global, device=device)\n",
    "    \n",
    "    best_stats, best_mrr, best_ep = None, -1.0, 0\n",
    "    \n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Dynamic temperature (smoother curve)\n",
    "        progress = (ep - 1) / max(1, epochs - 1)\n",
    "        tau = tau_start * (1 - progress) + tau_end * progress\n",
    "        \n",
    "        # Dynamic queue size (gradual schedule)\n",
    "        if ep <= queue_warmup_epochs:\n",
    "            recent_k = None  # No queue during warmup\n",
    "        else:\n",
    "            warmup_progress = (ep - queue_warmup_epochs) / max(1, epochs - queue_warmup_epochs)\n",
    "            schedule_idx = int(warmup_progress * len(queue_recent_schedule))\n",
    "            schedule_idx = min(schedule_idx, len(queue_recent_schedule) - 1)\n",
    "            recent_k = queue_recent_schedule[schedule_idx]\n",
    "        \n",
    "        for xb, yb, names_b in dl:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            \n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            \n",
    "            pred = model(xb)\n",
    "            pred_norm = F.normalize(pred, dim=-1)\n",
    "            \n",
    "            # Get queue negatives\n",
    "            if recent_k is not None and img_queue.size() > 0:\n",
    "                queue_feats, queue_ids = img_queue.get_with_ids()\n",
    "                if queue_feats.numel() > 0:\n",
    "                    queue_feats = queue_feats[-recent_k:] if recent_k < queue_feats.size(0) else queue_feats\n",
    "                    queue_ids = queue_ids[-recent_k:] if recent_k < queue_ids.size(0) else queue_ids\n",
    "            else:\n",
    "                queue_feats, queue_ids = None, None\n",
    "            \n",
    "            # Get XBP positives\n",
    "            xbp_bank, xbp_pos_cols = xbp_buffer.build_bank_and_mask(names_b, device)\n",
    "            \n",
    "            # Enhanced InfoNCE with curriculum mining\n",
    "            loss_ce = info_nce_multi_enhanced(\n",
    "                pred, yb, names_b,\n",
    "                queue_feats=queue_feats,\n",
    "                queue_img_ids=queue_ids,\n",
    "                tau=tau,\n",
    "                xbp_bank=xbp_bank,\n",
    "                xbp_pos_cols_per_row=xbp_pos_cols,\n",
    "                hard_subset_H=mine_H,\n",
    "                use_dcl=use_dcl,\n",
    "                dcl_prior=dcl_prior,\n",
    "                epoch=ep,\n",
    "                total_epochs=epochs,\n",
    "                label_smoothing=label_smoothing,\n",
    "            )\n",
    "            \n",
    "            # Agreement loss (caption consistency)\n",
    "            loss_agree = agreement_loss(names_b, pred, temperature=0.5) if lambda_agree > 0 else pred.new_tensor(0.0)\n",
    "            \n",
    "            # Auxiliary losses\n",
    "            loss_cos = (1.0 - F.cosine_similarity(pred, yb, dim=-1)).mean() if alpha_cos > 0 else pred.new_tensor(0.0)\n",
    "            loss_mu = moment_align(pred, yb) if lambda_moment > 0 else pred.new_tensor(0.0)\n",
    "            \n",
    "            # Total loss\n",
    "            loss = loss_ce + lambda_agree * loss_agree + alpha_cos * loss_cos + lambda_moment * loss_mu\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if gradient_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(params, gradient_clip)\n",
    "            \n",
    "            opt.step()\n",
    "            sched.step()\n",
    "            \n",
    "            # Update EMA\n",
    "            if use_ema and ema_model is not None:\n",
    "                with torch.no_grad():\n",
    "                    for ema_p, model_p in zip(ema_model.parameters(), model.parameters()):\n",
    "                        ema_p.data.mul_(ema_decay).add_(model_p.data, alpha=1 - ema_decay)\n",
    "            \n",
    "            # Update queues (detached, after backward)\n",
    "            with torch.no_grad():\n",
    "                img_queue.enqueue(F.normalize(yb, dim=-1), names_b)\n",
    "                xbp_buffer.add(names_b, pred)\n",
    "            \n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "        \n",
    "        # Validation (use EMA model if available)\n",
    "        eval_model = ema_model if use_ema and ema_model is not None else model\n",
    "        stats = validate_retrieval(eval_model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "        \n",
    "        ep_loss = running_loss / len(ds)\n",
    "        current_lr = opt.param_groups[0]['lr']\n",
    "        queue_info = f\"queue={img_queue.size()}\" if recent_k else \"queue=OFF\"\n",
    "        recent_info = f\"recentQ={recent_k}\" if recent_k else \"recentQ=0\"\n",
    "        \n",
    "        print(f\"[bigjump {ep:02d}] loss={ep_loss:.6f} lr={current_lr:.6f} | val_MRR={stats['MRR']:.4f} \"\n",
    "              f\"| R@1={stats['R1']:.3f} R@5={stats['R5']:.3f} R@10={stats['R10']:.3f} \"\n",
    "              f\"| median={stats['rank_median']} p75={stats['rank_p75']} | {queue_info} | tau={tau:.3f} | {recent_info}\")\n",
    "        \n",
    "        if stats[\"MRR\"] > best_mrr:\n",
    "            best_mrr, best_ep, best_stats = stats[\"MRR\"], ep, stats\n",
    "            # Save the actual model (not EMA) for consistency\n",
    "            torch.save({\"model\": model.state_dict(), \"epoch\": ep, \"val\": stats}, out_dir / \"best.pt\")\n",
    "            if use_ema and ema_model is not None:\n",
    "                torch.save({\"model\": ema_model.state_dict(), \"epoch\": ep, \"val\": stats}, out_dir / \"best_ema.pt\")\n",
    "    \n",
    "    if best_stats is None:\n",
    "        eval_model = ema_model if use_ema and ema_model is not None else model\n",
    "        best_stats = validate_retrieval(eval_model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "        torch.save({\"model\": model.state_dict(), \"epoch\": 0, \"val\": best_stats}, out_dir / \"best.pt\")\n",
    "    \n",
    "    (out_dir / \"val_metrics.json\").write_text(json.dumps(dict(best_epoch=best_ep, **best_stats), indent=2))\n",
    "    return best_stats\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   ENHANCED MAIN\n",
    "# =========================\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    Enhanced two-stage pipeline with:\n",
    "    - Variance-weighted Procrustes\n",
    "    - SVD-based orthogonalization\n",
    "    - Smoother schedules\n",
    "    - EMA\n",
    "    - Better hard mining\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    out_dir, seed = args.out_dir, args.seed\n",
    "    pooling, n_patches = args.pooling, None\n",
    "    OUT = Path(f\"/kaggle/working/outputs/{out_dir}\")\n",
    "    OUT.mkdir(parents=True, exist_ok=True)\n",
    "    STAGE1 = OUT / \"stage1\"\n",
    "    STAGE2 = OUT / \"stage2\"\n",
    "    STAGE1.mkdir(parents=True, exist_ok=True)\n",
    "    STAGE2.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load data\n",
    "    X, Y, cap_ids, img_ids_row, full_img, all_img_ids = load_train(OUT)\n",
    "    \n",
    "    # Image-level split (no leakage)\n",
    "    cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices = build_image_id_split(\n",
    "        img_ids_row, all_img_ids, full_img, X, Y, args.val_ratio, seed, OUT\n",
    "    )\n",
    "    \n",
    "    val_set = set(all_img_ids[val_img_indices])\n",
    "    train_set = set(all_img_ids) - val_set\n",
    "    assert val_set.isdisjoint(train_set), \"Leakage detected!\"\n",
    "    \n",
    "    Xtr, Ytr = X[cap_is_tr], Y[cap_is_tr]\n",
    "    Xva = X[cap_is_val]\n",
    "    \n",
    "    din, dout = X.shape[1], Y.shape[1]\n",
    "    assert din == 1024 and dout == 1536\n",
    "    \n",
    "    # Enhanced Procrustes with variance weighting\n",
    "    print(\"[geometry] Computing variance-weighted centroid Procrustes...\")\n",
    "    A, b = procrustes_closed_form_centroids_weighted(\n",
    "        Xtr.astype(np.float32),\n",
    "        Ytr.astype(np.float32),\n",
    "        img_ids_row[cap_is_tr],\n",
    "        eps=float(args.geom_eps),\n",
    "        use_variance_weighting=True,\n",
    "    )\n",
    "    \n",
    "    # Build model with SVD orthogonalization\n",
    "    class GeomFromWeights(nn.Module):\n",
    "        def __init__(self, A_np, b_np):\n",
    "            super().__init__()\n",
    "            self.fc = nn.Linear(A_np.shape[1], A_np.shape[0], bias=True)\n",
    "            with torch.no_grad():\n",
    "                self.fc.weight.copy_(torch.from_numpy(A_np))\n",
    "                self.fc.bias.copy_(torch.from_numpy(b_np))\n",
    "        def forward(self, x):\n",
    "            return self.fc(x)\n",
    "    \n",
    "    geom = GeomFromWeights(A, b).to(device)\n",
    "    for p in geom.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    adapter = ResidualAdapter(\n",
    "        din=din, hidden=1024, dout=dout, pdrop=0.1,\n",
    "        init_scale=0.25,  # Larger init\n",
    "        use_layernorm=True,\n",
    "    )\n",
    "    \n",
    "    class GeomPlusAdapter(nn.Module):\n",
    "        def __init__(self, g, a):\n",
    "            super().__init__()\n",
    "            self.geom = g\n",
    "            self.adapter = a\n",
    "        def forward(self, x):\n",
    "            return self.geom(x) + self.adapter(x)\n",
    "    \n",
    "    model = GeomPlusAdapter(geom, adapter).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _probe = model(torch.zeros(2, din, device=device))\n",
    "    assert _probe.shape[-1] == 1536\n",
    "    \n",
    "    # Stage 1: Enhanced warmup\n",
    "    if not args.eval_only:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[STAGE 1] Enhanced warmup with smoother scheduling\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"τ_fixed={args.tau:.3f} | triplet_w={args.triplet_w} | margin={args.triplet_margin}\")\n",
    "        print(f\"epochs={args.stage1_epochs} | warmup_epochs=3 | lr={args.lr}\")\n",
    "        \n",
    "        best_stats_s1 = train_simple_enhanced(\n",
    "            model,\n",
    "            Xtr, Ytr, img_ids_row[cap_is_tr],\n",
    "            Xva, val_gallery, cap2gal_local,\n",
    "            batch=args.batch,\n",
    "            epochs=int(args.stage1_epochs),\n",
    "            lr=args.lr,\n",
    "            wd=args.wd,\n",
    "            tau_fixed=float(args.tau),\n",
    "            triplet_margin=float(args.triplet_margin),\n",
    "            triplet_w=float(args.triplet_w),\n",
    "            alpha_cos=float(args.alpha),\n",
    "            moment_w=float(args.moment),\n",
    "            use_pk=bool(args.use_pk),\n",
    "            P=int(args.P),\n",
    "            K_pk=int(args.K_pk),\n",
    "            device=device,\n",
    "            pooling=pooling,\n",
    "            n_patches=n_patches,\n",
    "            out_dir=str(STAGE1),\n",
    "            seed=seed,\n",
    "            warmup_epochs=3,\n",
    "            use_cosine_schedule=True,\n",
    "            gradient_clip=1.0,\n",
    "        )\n",
    "        \n",
    "        # Load best from stage 1\n",
    "        try:\n",
    "            ckpt1 = torch.load(STAGE1 / \"best.pt\", map_location=device)\n",
    "            model.load_state_dict(ckpt1[\"model\"])\n",
    "            print(f\"\\n[stage1] Loaded best checkpoint: epoch={ckpt1.get('epoch','?')} MRR={ckpt1.get('val',{}).get('MRR','?'):.4f}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"[stage1] Warning: No checkpoint found, continuing with current weights\")\n",
    "    else:\n",
    "        best_stats_s1 = None\n",
    "    \n",
    "    # Stage 2: Enhanced BigJump\n",
    "    if not args.eval_only and args.stage2_epochs > 0:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[STAGE 2] Enhanced BigJump++ with curriculum & EMA\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"queue_warmup={args.queue_warmup_epochs} | queue_schedule={args.queue_recent_k}\")\n",
    "        print(f\"mine_H={args.mine_H} (curriculum) | τ_sched={args.tau_start:.3f}→{args.tau_end:.3f}\")\n",
    "        print(f\"agree={args.lambda_agree} | label_smoothing={args.label_smoothing}\")\n",
    "        \n",
    "        best_stats_s2 = train_bigjump_enhanced(\n",
    "            model,\n",
    "            Xtr, Ytr, img_ids_row[cap_is_tr],\n",
    "            Xva, val_gallery, cap2gal_local,\n",
    "            batch=args.batch,\n",
    "            epochs=int(args.stage2_epochs),\n",
    "            base_lr=args.lr * 0.5,  # Lower LR for stage 2\n",
    "            wd=args.wd,\n",
    "            tau_start=float(args.tau_start),\n",
    "            tau_end=float(args.tau_end),\n",
    "            queue_size=int(args.queue),\n",
    "            queue_warmup_epochs=int(args.queue_warmup_epochs),\n",
    "            queue_recent_schedule=tuple(args.queue_recent_k),\n",
    "            mine_H=int(args.mine_H),\n",
    "            lambda_agree=float(args.lambda_agree),\n",
    "            alpha_cos=float(args.alpha_stage2),\n",
    "            lambda_moment=float(args.moment_stage2),\n",
    "            use_pk=bool(args.use_pk),\n",
    "            P=int(args.P),\n",
    "            K_pk=int(args.K_pk),\n",
    "            xbp_per_img=int(args.xbp_per_img),\n",
    "            xbp_global=int(args.xbp_global),\n",
    "            use_dcl=bool(args.use_dcl),\n",
    "            dcl_prior=float(args.dcl_prior),\n",
    "            device=device,\n",
    "            pooling=pooling,\n",
    "            n_patches=n_patches,\n",
    "            out_dir=str(STAGE2),\n",
    "            seed=seed,\n",
    "            use_ema=args.use_ema,\n",
    "            ema_decay=args.ema_decay,\n",
    "            gradient_clip=1.0,\n",
    "            label_smoothing=args.label_smoothing,\n",
    "        )\n",
    "        \n",
    "        # Load best from stage 2 (prefer EMA if available)\n",
    "        try:\n",
    "            if args.use_ema and (STAGE2 / \"best_ema.pt\").exists():\n",
    "                ckpt2 = torch.load(STAGE2 / \"best_ema.pt\", map_location=device)\n",
    "                print(f\"[stage2] Loading EMA checkpoint\")\n",
    "            else:\n",
    "                ckpt2 = torch.load(STAGE2 / \"best.pt\", map_location=device)\n",
    "            model.load_state_dict(ckpt2[\"model\"])\n",
    "            best_stats_final = ckpt2.get(\"val\", None)\n",
    "            print(f\"\\n[stage2] Loaded best checkpoint: epoch={ckpt2.get('epoch','?')} MRR={ckpt2.get('val',{}).get('MRR','?'):.4f}\")\n",
    "        except FileNotFoundError:\n",
    "            best_stats_final = best_stats_s1\n",
    "            print(\"[stage2] Warning: No checkpoint found, using stage1 results\")\n",
    "    else:\n",
    "        best_stats_final = None\n",
    "        if args.eval_only:\n",
    "            for cand in [STAGE2 / \"best_ema.pt\", STAGE2 / \"best.pt\", STAGE1 / \"best.pt\", OUT / \"best.pt\"]:\n",
    "                try:\n",
    "                    ckpt = torch.load(cand, map_location=device)\n",
    "                    model.load_state_dict(ckpt[\"model\"])\n",
    "                    best_stats_final = ckpt.get(\"val\", None)\n",
    "                    print(f\"[resume] Loaded {cand} | epoch={ckpt.get('epoch','?')} MRR={ckpt.get('val',{}).get('MRR','?'):.4f}\")\n",
    "                    break\n",
    "                except FileNotFoundError:\n",
    "                    continue\n",
    "    \n",
    "    # Efficiency logging\n",
    "    params, mb = count_params_mb(model)\n",
    "    ms_gpu, ms_cpu = time_ms_per_query(model, din, pooling, n_patches)\n",
    "    eff = {\n",
    "        \"params\": params,\n",
    "        \"mb_fp32\": mb,\n",
    "        \"ms_per_query_gpu\": ms_gpu,\n",
    "        \"ms_per_query_cpu\": ms_cpu\n",
    "    }\n",
    "    (OUT / \"efficiency.json\").write_text(json.dumps(eff, indent=2))\n",
    "    \n",
    "    # Generate submission\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"[SUBMISSION] Generating predictions...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    test_data = load_data(TEST_NPZ)\n",
    "    Q = test_data[\"captions/embeddings\"].astype(np.float32)\n",
    "    ids = test_data.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n",
    "    \n",
    "    model.eval()\n",
    "    BS, outs = 1024, []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(Q), BS):\n",
    "            q = torch.from_numpy(Q[i:i+BS]).to(device)\n",
    "            q = apply_pooling(q, pooling, n_patches)\n",
    "            z = model(q)\n",
    "            z = F.normalize(z, dim=-1)\n",
    "            outs.append(z.detach().cpu().numpy())\n",
    "    \n",
    "    pred_embds = np.concatenate(outs, axis=0)\n",
    "    sub = OUT / \"submission.csv\"\n",
    "    generate_submission(ids, pred_embds, str(sub))\n",
    "    print(f\"✓ Submission saved to {sub}\")\n",
    "    \n",
    "    # Final validation\n",
    "    if best_stats_final is None:\n",
    "        best_stats_final = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "    \n",
    "    # Summary report\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"[FINAL REPORT]\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    sanity = {\n",
    "        \"dims\": {\"text\": int(din), \"image\": int(dout)},\n",
    "        \"split\": {\n",
    "            \"train_captions\": int(cap_is_tr.sum()),\n",
    "            \"val_captions\": int(cap_is_val.sum()),\n",
    "            \"val_unique_images\": int(val_gallery.shape[0]),\n",
    "            \"leakage\": False\n",
    "        },\n",
    "        \"val_metrics\": best_stats_final,\n",
    "        \"efficiency\": eff,\n",
    "        \"recipe\": {\n",
    "            \"geometry\": {\n",
    "                \"type\": \"variance_weighted_centroid_procrustes\",\n",
    "                \"eps\": float(args.geom_eps),\n",
    "                \"frozen\": True\n",
    "            },\n",
    "            \"stage1\": {\n",
    "                \"type\": \"enhanced_warmup_infoNCE+triplet\",\n",
    "                \"tau_fixed\": float(args.tau),\n",
    "                \"triplet_margin\": float(args.triplet_margin),\n",
    "                \"triplet_w\": float(args.triplet_w),\n",
    "                \"alpha_cos\": float(args.alpha),\n",
    "                \"moment_w\": float(args.moment),\n",
    "                \"epochs\": int(args.stage1_epochs),\n",
    "                \"warmup_epochs\": 3,\n",
    "                \"lr_schedule\": \"cosine_with_warmup\",\n",
    "                \"use_pk\": bool(args.use_pk),\n",
    "                \"P\": int(args.P),\n",
    "                \"K\": int(args.K_pk)\n",
    "            },\n",
    "            \"stage2\": {\n",
    "                \"type\": \"bigjump_plus_plus_curriculum_ema\",\n",
    "                \"epochs\": int(args.stage2_epochs),\n",
    "                \"tau_sched\": [float(args.tau_start), float(args.tau_end)],\n",
    "                \"queue_warmup_epochs\": int(args.queue_warmup_epochs),\n",
    "                \"queue_recent_schedule\": list(map(int, args.queue_recent_k)),\n",
    "                \"mine_H\": int(args.mine_H),\n",
    "                \"mine_curriculum\": True,\n",
    "                \"lambda_agree\": float(args.lambda_agree),\n",
    "                \"label_smoothing\": float(args.label_smoothing),\n",
    "                \"use_ema\": bool(args.use_ema),\n",
    "                \"ema_decay\": float(args.ema_decay),\n",
    "                \"alpha_cos\": float(args.alpha_stage2),\n",
    "                \"moment\": float(args.moment_stage2)\n",
    "            },\n",
    "            \"adapter\": {\n",
    "                \"hidden\": 1024,\n",
    "                \"dropout\": 0.1,\n",
    "                \"init_scale\": 0.25,\n",
    "                \"layernorm\": True,\n",
    "                \"orthogonalization\": \"svd\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(json.dumps(sanity, indent=2))\n",
    "    (OUT / \"summary.json\").write_text(json.dumps(sanity, indent=2))\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"✓ Pipeline complete!\")\n",
    "    print(f\"  Best MRR: {best_stats_final['MRR']:.4f}\")\n",
    "    print(f\"  R@1: {best_stats_final['R1']:.3f}\")\n",
    "    print(f\"  R@5: {best_stats_final['R5']:.3f}\")\n",
    "    print(f\"  R@10: {best_stats_final['R10']:.3f}\")\n",
    "    print(f\"  Median rank: {best_stats_final['rank_median']}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   ARGPARSE (Enhanced)\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Enhanced RoBERTa→DINOv2 | 2-Stage with Curriculum, EMA & Better Optimization\",\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    \n",
    "    # IO & run mode\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"enhanced_two_stage\",\n",
    "                   help=\"Output directory name\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42,\n",
    "                   help=\"Random seed\")\n",
    "    p.add_argument(\"--eval_only\", action=\"store_true\",\n",
    "                   help=\"Skip training, only evaluate and generate submission\")\n",
    "    \n",
    "    # Data & split\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.10,\n",
    "                   help=\"Validation split ratio (image-level)\")\n",
    "    \n",
    "    # Architecture\n",
    "    p.add_argument(\"--arch\", type=str, default=\"bigjump\",\n",
    "                   choices=[\"linear\", \"mlp1\", \"mlp2\", \"geom\", \"geom_adapter\", \"geom+adapter\", \"bigjump\"],\n",
    "                   help=\"Model architecture (internal use)\")\n",
    "    \n",
    "    # Optimization (shared)\n",
    "    p.add_argument(\"--batch\", type=int, default=512,\n",
    "                   help=\"Batch size\")\n",
    "    p.add_argument(\"--lr\", type=float, default=2e-4,\n",
    "                   help=\"Base learning rate\")\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4,\n",
    "                   help=\"Weight decay\")\n",
    "    \n",
    "    # Geometry initialization\n",
    "    p.add_argument(\"--geom_eps\", type=float, default=1e-5,\n",
    "                   help=\"Regularization epsilon for Procrustes covariance\")\n",
    "    \n",
    "    # Pooling\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\", choices=[\"CLS\"],\n",
    "                   help=\"Pooling strategy (CLS only)\")\n",
    "    \n",
    "    # ==================== STAGE 1 ====================\n",
    "    stage1_group = p.add_argument_group('Stage 1 (Warmup)', 'Enhanced warmup with fixed-τ InfoNCE + Triplet')\n",
    "    stage1_group.add_argument(\"--stage1_epochs\", type=int, default=15,\n",
    "                              help=\"Stage 1 epochs (increased from 12)\")\n",
    "    stage1_group.add_argument(\"--tau\", type=float, default=0.07,\n",
    "                              help=\"Fixed InfoNCE temperature\")\n",
    "    stage1_group.add_argument(\"--triplet_margin\", type=float, default=0.2,\n",
    "                              help=\"Triplet loss margin\")\n",
    "    stage1_group.add_argument(\"--triplet_w\", type=float, default=0.3,\n",
    "                              help=\"Triplet weight (InfoNCE weight = 1 - triplet_w)\")\n",
    "    stage1_group.add_argument(\"--alpha\", type=float, default=0.0,\n",
    "                              help=\"Cosine auxiliary weight\")\n",
    "    stage1_group.add_argument(\"--moment\", type=float, default=0.0,\n",
    "                              help=\"Moment alignment weight\")\n",
    "    \n",
    "    # ==================== STAGE 2 ====================\n",
    "    stage2_group = p.add_argument_group('Stage 2 (BigJump++)', 'Enhanced contrastive learning with curriculum')\n",
    "    stage2_group.add_argument(\"--stage2_epochs\", type=int, default=18,\n",
    "                              help=\"Stage 2 epochs (increased from 13)\")\n",
    "    stage2_group.add_argument(\"--tau_start\", type=float, default=0.10,\n",
    "                              help=\"Starting temperature (smoother than before)\")\n",
    "    stage2_group.add_argument(\"--tau_end\", type=float, default=0.05,\n",
    "                              help=\"Ending temperature (lower for harder negatives)\")\n",
    "    stage2_group.add_argument(\"--queue\", type=int, default=65536,\n",
    "                              help=\"Queue capacity\")\n",
    "    stage2_group.add_argument(\"--queue_warmup_epochs\", type=int, default=5,\n",
    "                              help=\"Epochs before enabling queue (increased from 3)\")\n",
    "    stage2_group.add_argument(\"--queue_recent_k\", type=int, nargs='+', \n",
    "                              default=[8000, 16000, 32000, 65536],\n",
    "                              help=\"Queue size schedule (4 stages)\")\n",
    "    stage2_group.add_argument(\"--mine_H\", type=int, default=64,\n",
    "                              help=\"Top-H hard negatives (doubled from 32)\")\n",
    "    stage2_group.add_argument(\"--lambda_agree\", type=float, default=0.02,\n",
    "                              help=\"Caption agreement weight\")\n",
    "    stage2_group.add_argument(\"--alpha_stage2\", type=float, default=0.2,\n",
    "                              help=\"Cosine auxiliary in Stage 2\")\n",
    "    stage2_group.add_argument(\"--moment_stage2\", type=float, default=0.01,\n",
    "                              help=\"Moment alignment in Stage 2\")\n",
    "    stage2_group.add_argument(\"--label_smoothing\", type=float, default=0.05,\n",
    "                              help=\"Label smoothing (NEW)\")\n",
    "    \n",
    "    # ==================== EMA ====================\n",
    "    ema_group = p.add_argument_group('EMA', 'Exponential Moving Average for stability')\n",
    "    ema_group.add_argument(\"--use_ema\", action=\"store_true\", default=True,\n",
    "                           help=\"Use EMA model (recommended)\")\n",
    "    ema_group.add_argument(\"--ema_decay\", type=float, default=0.999,\n",
    "                           help=\"EMA decay rate\")\n",
    "    \n",
    "    # ==================== PK SAMPLER ====================\n",
    "    pk_group = p.add_argument_group('PK Sampler', 'P images × K captions per batch')\n",
    "    pk_group.add_argument(\"--use_pk\", action=\"store_true\",\n",
    "                          help=\"Use P×K batch sampling\")\n",
    "    pk_group.add_argument(\"--P\", type=int, default=192,\n",
    "                          help=\"Number of unique images per batch\")\n",
    "    pk_group.add_argument(\"--K_pk\", type=int, default=3,\n",
    "                          help=\"Number of captions per image\")\n",
    "    \n",
    "    # ==================== XBP & DCL ====================\n",
    "    advanced_group = p.add_argument_group('Advanced Features', 'XBP buffer and DCL')\n",
    "    advanced_group.add_argument(\"--xbp_per_img\", type=int, default=6,\n",
    "                                help=\"XBP buffer size per image (increased)\")\n",
    "    advanced_group.add_argument(\"--xbp_global\", type=int, default=48000,\n",
    "                                help=\"XBP global capacity (increased)\")\n",
    "    advanced_group.add_argument(\"--use_dcl\", action=\"store_true\",\n",
    "                                help=\"Use debiased contrastive learning\")\n",
    "    advanced_group.add_argument(\"--dcl_prior\", type=float, default=0.01,\n",
    "                                help=\"DCL class prior\")\n",
    "    \n",
    "    # Legacy args (kept for compatibility)\n",
    "    p.add_argument(\"--epochs\", type=int, default=0,\n",
    "                   help=\"(unused, kept for compatibility)\")\n",
    "    p.add_argument(\"--geom_lr_scale\", type=float, default=0.05,\n",
    "                   help=\"(unused, geometry frozen)\")\n",
    "    p.add_argument(\"--queue_pred_capacity\", type=int, default=65536,\n",
    "                   help=\"(unused)\")\n",
    "    \n",
    "    args, _ = p.parse_known_args()\n",
    "    \n",
    "    # Validate arguments\n",
    "    if len(args.queue_recent_k) < 2:\n",
    "        print(\"Warning: queue_recent_k should have at least 2 values for gradual schedule\")\n",
    "        args.queue_recent_k = [8000, 16000, 32000, 65536]\n",
    "    \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T22:40:57.642317Z",
     "iopub.status.busy": "2025-10-29T22:40:57.641494Z",
     "iopub.status.idle": "2025-10-29T22:52:48.620116Z",
     "shell.execute_reply": "2025-10-29T22:52:48.619215Z",
     "shell.execute_reply.started": "2025-10-29T22:40:57.642284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[meta] text_dim=1024 | image_dim=1536\n",
      "[geometry] Computing variance-weighted centroid Procrustes...\n",
      "\n",
      "============================================================\n",
      "[STAGE 1] Enhanced warmup\n",
      "============================================================\n",
      "[simple 01] loss=2.471956 lr=0.000067 | val_MRR=0.3408 | R@1=0.219 R@5=0.475 R@10=0.598 | median=6 p75=27\n",
      "[simple 02] loss=2.103471 lr=0.000133 | val_MRR=0.3584 | R@1=0.234 R@5=0.494 R@10=0.622 | median=6 p75=22\n",
      "[simple 03] loss=2.011080 lr=0.000200 | val_MRR=0.3706 | R@1=0.244 R@5=0.511 R@10=0.637 | median=5 p75=20\n",
      "[simple 04] loss=1.940317 lr=0.000197 | val_MRR=0.3772 | R@1=0.249 R@5=0.517 R@10=0.648 | median=5 p75=18\n",
      "[simple 05] loss=1.881534 lr=0.000187 | val_MRR=0.3823 | R@1=0.251 R@5=0.530 R@10=0.659 | median=5 p75=17\n",
      "[simple 06] loss=1.832789 lr=0.000171 | val_MRR=0.3914 | R@1=0.262 R@5=0.536 R@10=0.671 | median=5 p75=17\n",
      "[simple 07] loss=1.793071 lr=0.000150 | val_MRR=0.3947 | R@1=0.263 R@5=0.543 R@10=0.675 | median=5 p75=16\n",
      "[simple 08] loss=1.757707 lr=0.000126 | val_MRR=0.3995 | R@1=0.269 R@5=0.547 R@10=0.677 | median=4 p75=16\n",
      "[simple 09] loss=1.728539 lr=0.000100 | val_MRR=0.4009 | R@1=0.268 R@5=0.550 R@10=0.683 | median=4 p75=15\n",
      "[simple 10] loss=1.702999 lr=0.000074 | val_MRR=0.4014 | R@1=0.270 R@5=0.548 R@10=0.682 | median=4 p75=15\n",
      "[simple 11] loss=1.683554 lr=0.000050 | val_MRR=0.4016 | R@1=0.268 R@5=0.552 R@10=0.685 | median=4 p75=15\n",
      "[simple 12] loss=1.667796 lr=0.000029 | val_MRR=0.4046 | R@1=0.273 R@5=0.553 R@10=0.684 | median=4 p75=16\n",
      "[simple 13] loss=1.656111 lr=0.000013 | val_MRR=0.4047 | R@1=0.271 R@5=0.557 R@10=0.686 | median=4 p75=15\n",
      "[simple 14] loss=1.649779 lr=0.000003 | val_MRR=0.4057 | R@1=0.272 R@5=0.556 R@10=0.685 | median=4 p75=15\n",
      "[simple 15] loss=1.646595 lr=0.000000 | val_MRR=0.4034 | R@1=0.270 R@5=0.555 R@10=0.686 | median=4 p75=15\n",
      "\n",
      "[stage1] Loaded best: epoch=14 MRR=0.4057\n",
      "\n",
      "============================================================\n",
      "[STAGE 2] FIXED BigJump++ with Flow\n",
      "============================================================\n",
      "queue_warmup=8 | gradual_schedule=8 stages\n",
      "flow=ENABLED | flow_layers=3\n",
      "[bigjump 01] loss=3.102249 lr=0.000042 | val_MRR=0.4125 | R@1=0.280 R@5=0.564 R@10=0.690 | median=4 p75=15 | queue=OFF | tau=0.080 | recentK=0\n",
      "[bigjump 02] loss=1.329774 lr=0.000083 | val_MRR=0.4217 | R@1=0.289 R@5=0.578 R@10=0.700 | median=4 p75=14 | queue=OFF | tau=0.074 | recentK=0\n",
      "[bigjump 03] loss=1.212486 lr=0.000100 | val_MRR=0.4254 | R@1=0.290 R@5=0.582 R@10=0.705 | median=4 p75=14 | queue=OFF | tau=0.071 | recentK=0\n",
      "[bigjump 04] loss=1.138627 lr=0.000099 | val_MRR=0.4279 | R@1=0.292 R@5=0.584 R@10=0.706 | median=4 p75=14 | queue=OFF | tau=0.069 | recentK=0\n",
      "[bigjump 05] loss=1.093624 lr=0.000097 | val_MRR=0.4304 | R@1=0.295 R@5=0.589 R@10=0.712 | median=4 p75=14 | queue=OFF | tau=0.067 | recentK=0\n",
      "[bigjump 06] loss=1.052258 lr=0.000094 | val_MRR=0.4303 | R@1=0.294 R@5=0.590 R@10=0.712 | median=4 p75=14 | queue=OFF | tau=0.066 | recentK=0\n",
      "[bigjump 07] loss=1.017717 lr=0.000090 | val_MRR=0.4342 | R@1=0.299 R@5=0.593 R@10=0.712 | median=4 p75=13 | queue=OFF | tau=0.065 | recentK=0\n",
      "[bigjump 08] loss=0.983129 lr=0.000086 | val_MRR=0.4361 | R@1=0.300 R@5=0.595 R@10=0.716 | median=3 p75=13 | queue=OFF | tau=0.063 | recentK=0\n",
      "[bigjump 09] loss=1.524462 lr=0.000081 | val_MRR=0.4166 | R@1=0.283 R@5=0.573 R@10=0.699 | median=4 p75=14 | queue=65536 | tau=0.062 | recentK=500\n",
      "[bigjump 10] loss=1.458137 lr=0.000075 | val_MRR=0.4201 | R@1=0.284 R@5=0.577 R@10=0.705 | median=4 p75=14 | queue=65536 | tau=0.061 | recentK=1000\n",
      "[bigjump 11] loss=1.430076 lr=0.000069 | val_MRR=0.4237 | R@1=0.289 R@5=0.581 R@10=0.704 | median=4 p75=14 | queue=65536 | tau=0.060 | recentK=1000\n",
      "[bigjump 12] loss=1.414669 lr=0.000063 | val_MRR=0.4303 | R@1=0.294 R@5=0.590 R@10=0.710 | median=4 p75=13 | queue=65536 | tau=0.059 | recentK=2000\n",
      "[bigjump 13] loss=1.393777 lr=0.000056 | val_MRR=0.4310 | R@1=0.295 R@5=0.593 R@10=0.715 | median=4 p75=13 | queue=65536 | tau=0.058 | recentK=2000\n",
      "[bigjump 14] loss=1.385730 lr=0.000050 | val_MRR=0.4332 | R@1=0.298 R@5=0.594 R@10=0.716 | median=4 p75=13 | queue=65536 | tau=0.057 | recentK=4000\n",
      "[bigjump 15] loss=1.373810 lr=0.000043 | val_MRR=0.4367 | R@1=0.300 R@5=0.600 R@10=0.719 | median=3 p75=13 | queue=65536 | tau=0.057 | recentK=4000\n",
      "[bigjump 16] loss=1.365015 lr=0.000037 | val_MRR=0.4409 | R@1=0.304 R@5=0.605 R@10=0.721 | median=3 p75=13 | queue=65536 | tau=0.056 | recentK=8000\n",
      "[bigjump 17] loss=1.346472 lr=0.000031 | val_MRR=0.4418 | R@1=0.307 R@5=0.602 R@10=0.721 | median=3 p75=13 | queue=65536 | tau=0.055 | recentK=8000\n",
      "[bigjump 18] loss=1.349089 lr=0.000026 | val_MRR=0.4432 | R@1=0.306 R@5=0.610 R@10=0.723 | median=3 p75=13 | queue=65536 | tau=0.054 | recentK=16000\n",
      "[bigjump 19] loss=1.330569 lr=0.000021 | val_MRR=0.4452 | R@1=0.308 R@5=0.611 R@10=0.726 | median=3 p75=12 | queue=65536 | tau=0.053 | recentK=16000\n",
      "[bigjump 20] loss=1.323379 lr=0.000017 | val_MRR=0.4501 | R@1=0.316 R@5=0.609 R@10=0.727 | median=3 p75=12 | queue=65536 | tau=0.053 | recentK=32000\n",
      "[bigjump 21] loss=1.316156 lr=0.000014 | val_MRR=0.4513 | R@1=0.314 R@5=0.614 R@10=0.729 | median=3 p75=12 | queue=65536 | tau=0.052 | recentK=32000\n",
      "[bigjump 22] loss=1.322201 lr=0.000012 | val_MRR=0.4536 | R@1=0.317 R@5=0.616 R@10=0.732 | median=3 p75=12 | queue=65536 | tau=0.051 | recentK=65536\n",
      "[bigjump 23] loss=1.309950 lr=0.000010 | val_MRR=0.4552 | R@1=0.319 R@5=0.618 R@10=0.733 | median=3 p75=12 | queue=65536 | tau=0.051 | recentK=65536\n",
      "[bigjump 24] loss=1.303158 lr=0.000010 | val_MRR=0.4556 | R@1=0.319 R@5=0.620 R@10=0.734 | median=3 p75=12 | queue=65536 | tau=0.050 | recentK=65536\n",
      "\n",
      "[stage2] Loaded best: epoch=24 MRR=0.4556\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/flow_enhanced/submission.csv\n",
      "✓ Submission: /kaggle/working/outputs/flow_enhanced/submission.csv\n",
      "\n",
      "============================================================\n",
      "[FINAL RESULTS]\n",
      "============================================================\n",
      "{\n",
      "  \"dims\": {\n",
      "    \"text\": 1024,\n",
      "    \"image\": 1536\n",
      "  },\n",
      "  \"split\": {\n",
      "    \"train_captions\": 112500,\n",
      "    \"val_captions\": 12500,\n",
      "    \"val_unique_images\": 2500,\n",
      "    \"leakage\": false\n",
      "  },\n",
      "  \"val_metrics\": {\n",
      "    \"MRR\": 0.4556481766110607,\n",
      "    \"R1\": 0.31888,\n",
      "    \"R5\": 0.62024,\n",
      "    \"R10\": 0.73392,\n",
      "    \"rank_median\": 3,\n",
      "    \"rank_p75\": 12\n",
      "  },\n",
      "  \"efficiency\": {\n",
      "    \"params\": 10502656,\n",
      "    \"mb_fp32\": 40.064453125,\n",
      "    \"ms_per_query_gpu\": 0.004656030796468258,\n",
      "    \"ms_per_query_cpu\": 0.11513265781104565\n",
      "  },\n",
      "  \"recipe\": {\n",
      "    \"geometry\": {\n",
      "      \"type\": \"variance_weighted_centroid_procrustes\",\n",
      "      \"frozen\": true\n",
      "    },\n",
      "    \"flow\": {\n",
      "      \"enabled\": true,\n",
      "      \"layers\": 3,\n",
      "      \"type\": \"RealNVP\"\n",
      "    },\n",
      "    \"stage1\": {\n",
      "      \"type\": \"enhanced_warmup\",\n",
      "      \"epochs\": 15,\n",
      "      \"tau\": 0.07\n",
      "    },\n",
      "    \"stage2\": {\n",
      "      \"type\": \"fixed_bigjump_gradual_queue\",\n",
      "      \"epochs\": 24,\n",
      "      \"queue_warmup\": 8,\n",
      "      \"queue_stages\": 8,\n",
      "      \"tau_schedule\": [\n",
      "        0.08,\n",
      "        0.05\n",
      "      ],\n",
      "      \"mine_H\": 64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "✓ Best MRR: 0.4556\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "#   UPDATED ARGPARSE (KAGGLE NOTEBOOK FIX)\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    \n",
    "    p = argparse.ArgumentParser(\n",
    "        description=\"Enhanced RoBERTa→DINOv2 with Normalizing Flows\",\n",
    "        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n",
    "    )\n",
    "    \n",
    "    # IO\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"flow_enhanced\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--eval_only\", action=\"store_true\")\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.10)\n",
    "    p.add_argument(\"--arch\", type=str, default=\"bigjump\")\n",
    "    \n",
    "    # Optimization\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=2e-4)\n",
    "    p.add_argument(\"--lr_stage2\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--geom_eps\", type=float, default=1e-5)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\")\n",
    "    \n",
    "    # Flow\n",
    "    p.add_argument(\"--use_flow\", action=\"store_true\", default=True)\n",
    "    p.add_argument(\"--flow_layers\", type=int, default=3)\n",
    "    p.add_argument(\"--lambda_flow\", type=float, default=0.01)\n",
    "    \n",
    "    # Stage 1\n",
    "    p.add_argument(\"--stage1_epochs\", type=int, default=15)\n",
    "    p.add_argument(\"--tau\", type=float, default=0.07)\n",
    "    p.add_argument(\"--triplet_margin\", type=float, default=0.2)\n",
    "    p.add_argument(\"--triplet_w\", type=float, default=0.3)\n",
    "    p.add_argument(\"--alpha\", type=float, default=0.0)\n",
    "    p.add_argument(\"--moment\", type=float, default=0.0)\n",
    "    \n",
    "    # Stage 2\n",
    "    p.add_argument(\"--stage2_epochs\", type=int, default=24)\n",
    "    p.add_argument(\"--tau_start\", type=float, default=0.08)\n",
    "    p.add_argument(\"--tau_end\", type=float, default=0.05)\n",
    "    p.add_argument(\"--queue\", type=int, default=65536)\n",
    "    p.add_argument(\"--queue_warmup_epochs\", type=int, default=8)\n",
    "    p.add_argument(\"--queue_recent_k\", type=int, nargs='+',\n",
    "                    default=[500, 1000, 2000, 4000, 8000, 16000, 32000, 65536])\n",
    "    p.add_argument(\"--mine_H\", type=int, default=64)\n",
    "    p.add_argument(\"--lambda_agree\", type=float, default=0.015)\n",
    "    p.add_argument(\"--alpha_stage2\", type=float, default=0.15)\n",
    "    p.add_argument(\"--moment_stage2\", type=float, default=0.005)\n",
    "    p.add_argument(\"--label_smoothing\", type=float, default=0.03)\n",
    "    \n",
    "    # EMA\n",
    "    p.add_argument(\"--use_ema\", action=\"store_true\", default=None)\n",
    "    p.add_argument(\"--ema_decay\", type=float, default=0)\n",
    "    \n",
    "    # PK Sampler\n",
    "    p.add_argument(\"--use_pk\", action=\"store_true\")\n",
    "    p.add_argument(\"--P\", type=int, default=192)\n",
    "    p.add_argument(\"--K_pk\", type=int, default=3)\n",
    "    \n",
    "    # XBP & DCL\n",
    "    p.add_argument(\"--xbp_per_img\", type=int, default=6)\n",
    "    p.add_argument(\"--xbp_global\", type=int, default=48000)\n",
    "    p.add_argument(\"--use_dcl\", action=\"store_true\")\n",
    "    p.add_argument(\"--dcl_prior\", type=float, default=0.01)\n",
    "    \n",
    "    # Legacy\n",
    "    p.add_argument(\"--epochs\", type=int, default=0)\n",
    "    p.add_argument(\"--geom_lr_scale\", type=float, default=0.05)\n",
    "    p.add_argument(\"--queue_pred_capacity\", type=int, default=65536)\n",
    "    \n",
    "    # FIXED: parse_known_args returns tuple (args, unknown)\n",
    "    args, unknown = p.parse_known_args()\n",
    "    \n",
    "    # Validate and fix queue schedule if needed\n",
    "    if not hasattr(args, 'queue_recent_k') or args.queue_recent_k is None:\n",
    "        args.queue_recent_k = [500, 1000, 2000, 4000, 8000, 16000, 32000, 65536]\n",
    "    elif len(args.queue_recent_k) < 4:\n",
    "        print(\"Warning: queue_recent_k too short, using default 8-stage schedule\")\n",
    "        args.queue_recent_k = [500, 1000, 2000, 4000, 8000, 16000, 32000, 65536]\n",
    "    \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T22:57:11.424791Z",
     "iopub.status.busy": "2025-10-29T22:57:11.424429Z",
     "iopub.status.idle": "2025-10-29T23:14:56.032100Z",
     "shell.execute_reply": "2025-10-29T23:14:56.031149Z",
     "shell.execute_reply.started": "2025-10-29T22:57:11.424765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[meta] text_dim=1024 | image_dim=1536\n",
      "[geometry] Variance-weighted Procrustes...\n",
      "\n",
      "============================================================\n",
      "[STAGE 1] Warmup\n",
      "============================================================\n",
      "[simple 01] loss=2.475841 lr=0.000067 | val_MRR=0.3401 | R@1=0.219 R@5=0.474 R@10=0.595 | median=6 p75=27\n",
      "[simple 02] loss=2.108213 lr=0.000133 | val_MRR=0.3576 | R@1=0.233 R@5=0.493 R@10=0.620 | median=6 p75=22\n",
      "[simple 03] loss=2.012987 lr=0.000200 | val_MRR=0.3701 | R@1=0.244 R@5=0.510 R@10=0.637 | median=5 p75=20\n",
      "[simple 04] loss=1.939724 lr=0.000197 | val_MRR=0.3771 | R@1=0.249 R@5=0.518 R@10=0.648 | median=5 p75=18\n",
      "[simple 05] loss=1.877276 lr=0.000187 | val_MRR=0.3838 | R@1=0.253 R@5=0.530 R@10=0.662 | median=5 p75=17\n",
      "[simple 06] loss=1.825146 lr=0.000171 | val_MRR=0.3923 | R@1=0.263 R@5=0.538 R@10=0.672 | median=5 p75=17\n",
      "[simple 07] loss=1.782118 lr=0.000150 | val_MRR=0.3947 | R@1=0.263 R@5=0.543 R@10=0.676 | median=5 p75=16\n",
      "[simple 08] loss=1.743567 lr=0.000126 | val_MRR=0.3999 | R@1=0.269 R@5=0.548 R@10=0.678 | median=4 p75=16\n",
      "[simple 09] loss=1.711573 lr=0.000100 | val_MRR=0.4017 | R@1=0.270 R@5=0.550 R@10=0.682 | median=4 p75=15\n",
      "[simple 10] loss=1.683550 lr=0.000074 | val_MRR=0.4029 | R@1=0.271 R@5=0.552 R@10=0.681 | median=4 p75=15\n",
      "[simple 11] loss=1.661948 lr=0.000050 | val_MRR=0.4029 | R@1=0.271 R@5=0.552 R@10=0.685 | median=4 p75=15\n",
      "[simple 12] loss=1.644228 lr=0.000029 | val_MRR=0.4041 | R@1=0.272 R@5=0.553 R@10=0.684 | median=4 p75=15\n",
      "[simple 13] loss=1.631616 lr=0.000013 | val_MRR=0.4045 | R@1=0.271 R@5=0.559 R@10=0.686 | median=4 p75=15\n",
      "[simple 14] loss=1.624565 lr=0.000003 | val_MRR=0.4052 | R@1=0.271 R@5=0.557 R@10=0.685 | median=4 p75=15\n",
      "[simple 15] loss=1.620948 lr=0.000000 | val_MRR=0.4045 | R@1=0.273 R@5=0.554 R@10=0.685 | median=4 p75=15\n",
      "[stage1] Best MRR=0.4052\n",
      "\n",
      "============================================================\n",
      "[STAGE 2] ULTRA MODE - ALL TECHNIQUES\n",
      "============================================================\n",
      "[ultra 01] loss=4.274606 lr=0.000023 | MRR=0.4056 R@1=0.272 R@5=0.558 R@10=0.688 | med=4 p75=15 | tau=0.090 | recentK=0\n",
      "[ultra 02] loss=1.911060 lr=0.000046 | MRR=0.4069 R@1=0.274 R@5=0.559 R@10=0.686 | med=4 p75=15 | tau=0.085 | recentK=0\n",
      "[ultra 03] loss=1.631296 lr=0.000069 | MRR=0.4071 R@1=0.274 R@5=0.557 R@10=0.687 | med=4 p75=15 | tau=0.082 | recentK=0\n",
      "[ultra 04] loss=1.481768 lr=0.000080 | MRR=0.4106 R@1=0.277 R@5=0.563 R@10=0.692 | med=4 p75=15 | tau=0.079 | recentK=0\n",
      "[ultra 05] loss=1.576833 lr=0.000079 | MRR=0.4127 R@1=0.280 R@5=0.566 R@10=0.694 | med=4 p75=15 | tau=0.077 | recentK=0\n",
      "[ultra 06] loss=1.489917 lr=0.000078 | MRR=0.4147 R@1=0.281 R@5=0.568 R@10=0.695 | med=4 p75=15 | tau=0.075 | recentK=0\n",
      "[ultra 07] loss=2.347421 lr=0.000077 | MRR=0.4129 R@1=0.279 R@5=0.566 R@10=0.693 | med=4 p75=15 | tau=0.073 | recentK=1000\n",
      "[ultra 08] loss=2.537798 lr=0.000074 | MRR=0.4133 R@1=0.279 R@5=0.566 R@10=0.695 | med=4 p75=15 | tau=0.071 | recentK=1000\n",
      "[ultra 09] loss=2.413710 lr=0.000072 | MRR=0.4127 R@1=0.278 R@5=0.566 R@10=0.695 | med=4 p75=14 | tau=0.069 | recentK=2000\n",
      "[ultra 10] loss=2.073393 lr=0.000069 | MRR=0.4165 R@1=0.283 R@5=0.571 R@10=0.697 | med=4 p75=14 | tau=0.067 | recentK=2000\n",
      "[ultra 11] loss=2.302081 lr=0.000065 | MRR=0.4150 R@1=0.280 R@5=0.571 R@10=0.697 | med=4 p75=14 | tau=0.065 | recentK=2000\n",
      "[ultra 12] loss=2.191368 lr=0.000062 | MRR=0.4173 R@1=0.281 R@5=0.576 R@10=0.702 | med=4 p75=14 | tau=0.063 | recentK=4000\n",
      "[ultra 13] loss=2.244027 lr=0.000058 | MRR=0.4203 R@1=0.286 R@5=0.575 R@10=0.703 | med=4 p75=14 | tau=0.062 | recentK=4000\n",
      "[ultra 14] loss=2.281139 lr=0.000054 | MRR=0.4226 R@1=0.287 R@5=0.580 R@10=0.704 | med=4 p75=14 | tau=0.060 | recentK=4000\n",
      "[ultra 15] loss=1.949155 lr=0.000049 | MRR=0.4249 R@1=0.289 R@5=0.584 R@10=0.708 | med=4 p75=14 | tau=0.058 | recentK=8000\n",
      "[ultra 16] loss=2.151333 lr=0.000045 | MRR=0.4253 R@1=0.290 R@5=0.579 R@10=0.709 | med=4 p75=13 | tau=0.057 | recentK=8000\n",
      "[ultra 17] loss=2.073945 lr=0.000041 | MRR=0.4291 R@1=0.293 R@5=0.587 R@10=0.711 | med=4 p75=13 | tau=0.055 | recentK=16000\n",
      "[ultra 18] loss=2.013654 lr=0.000036 | MRR=0.4307 R@1=0.295 R@5=0.589 R@10=0.712 | med=4 p75=13 | tau=0.054 | recentK=16000\n",
      "[ultra 19] loss=1.873291 lr=0.000032 | MRR=0.4329 R@1=0.296 R@5=0.594 R@10=0.717 | med=4 p75=13 | tau=0.052 | recentK=16000\n",
      "[ultra 20] loss=2.040153 lr=0.000028 | MRR=0.4353 R@1=0.299 R@5=0.596 R@10=0.718 | med=4 p75=13 | tau=0.051 | recentK=32000\n",
      "[ultra 21] loss=2.288578 lr=0.000025 | MRR=0.4389 R@1=0.302 R@5=0.597 R@10=0.721 | med=3 p75=13 | tau=0.049 | recentK=32000\n",
      "[ultra 22] loss=1.877711 lr=0.000022 | MRR=0.4398 R@1=0.303 R@5=0.601 R@10=0.722 | med=3 p75=12 | tau=0.048 | recentK=32000\n",
      "[ultra 23] loss=2.068647 lr=0.000019 | MRR=0.4424 R@1=0.306 R@5=0.601 R@10=0.726 | med=3 p75=12 | tau=0.047 | recentK=65536\n",
      "[ultra 24] loss=2.106361 lr=0.000016 | MRR=0.4455 R@1=0.310 R@5=0.605 R@10=0.724 | med=3 p75=12 | tau=0.045 | recentK=65536\n",
      "[ultra 25] loss=1.437288 lr=0.000014 | MRR=0.4474 R@1=0.311 R@5=0.609 R@10=0.727 | med=3 p75=12 | tau=0.044 | recentK=65536\n",
      "[ultra 26] loss=1.536259 lr=0.000013 | MRR=0.4486 R@1=0.311 R@5=0.612 R@10=0.730 | med=3 p75=12 | tau=0.043 | recentK=98304\n",
      "[ultra 27] loss=1.798891 lr=0.000012 | MRR=0.4503 R@1=0.314 R@5=0.610 R@10=0.731 | med=3 p75=12 | tau=0.041 | recentK=98304\n",
      "[ultra 28] loss=1.958536 lr=0.000012 | MRR=0.4543 R@1=0.318 R@5=0.615 R@10=0.732 | med=3 p75=12 | tau=0.040 | recentK=98304\n",
      "[stage2] Best MRR=0.4543\n",
      "\n",
      "============================================================\n",
      "[SUBMISSION] TTA Ensemble\n",
      "============================================================\n",
      "[TTA] Running 5 augmented forward passes...\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/ultra_final/submission.csv\n",
      "✓ Enhanced submission with 5x TTA: /kaggle/working/outputs/ultra_final/submission.csv\n",
      "\n",
      "✓ DONE! Best val MRR: 0.4543\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "#   ENSEMBLE PREDICTION + TEST-TIME AUGMENTATION\n",
    "# =========================\n",
    "def generate_submission_enhanced(model, test_data, pooling, n_patches, device, out_path, num_tta=5):\n",
    "    \"\"\"\n",
    "    Enhanced submission with:\n",
    "    - Test-Time Augmentation (TTA)\n",
    "    - Multiple forward passes with dropout\n",
    "    - Ensemble averaging\n",
    "    \"\"\"\n",
    "    Q = test_data[\"captions/embeddings\"].astype(np.float32)\n",
    "    ids = test_data.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n",
    "    \n",
    "    model.eval()\n",
    "    # Enable dropout during inference for TTA\n",
    "    if hasattr(model, 'adapter'):\n",
    "        for m in model.adapter.modules():\n",
    "            if isinstance(m, nn.Dropout):\n",
    "                m.train()\n",
    "    \n",
    "    BS = 1024\n",
    "    all_predictions = []\n",
    "    \n",
    "    print(f\"[TTA] Running {num_tta} augmented forward passes...\")\n",
    "    \n",
    "    for tta_idx in range(num_tta):\n",
    "        outs = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(Q), BS):\n",
    "                q = torch.from_numpy(Q[i:i+BS]).to(device)\n",
    "                \n",
    "                # Add slight noise for augmentation\n",
    "                if tta_idx > 0:\n",
    "                    noise = torch.randn_like(q) * 0.01\n",
    "                    q = q + noise\n",
    "                \n",
    "                q = apply_pooling(q, pooling, n_patches)\n",
    "                z = model(q)\n",
    "                z = F.normalize(z, dim=-1)\n",
    "                outs.append(z.cpu().numpy())\n",
    "        \n",
    "        pred = np.concatenate(outs, axis=0)\n",
    "        all_predictions.append(pred)\n",
    "    \n",
    "    # Average all TTA predictions and re-normalize\n",
    "    ensemble_pred = np.mean(all_predictions, axis=0)\n",
    "    ensemble_pred = ensemble_pred / (np.linalg.norm(ensemble_pred, axis=1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    generate_submission(ids, ensemble_pred, str(out_path))\n",
    "    print(f\"✓ Enhanced submission with {num_tta}x TTA: {out_path}\")\n",
    "    return ensemble_pred\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   SELF-DISTILLATION LOSS\n",
    "# =========================\n",
    "def self_distillation_loss(student_logits, teacher_logits, temperature=2.0):\n",
    "    \"\"\"\n",
    "    Distill knowledge from teacher (EMA) to student (current model)\n",
    "    \"\"\"\n",
    "    student_log_probs = F.log_softmax(student_logits / temperature, dim=1)\n",
    "    teacher_probs = F.softmax(teacher_logits / temperature, dim=1)\n",
    "    return F.kl_div(student_log_probs, teacher_probs, reduction='batchmean') * (temperature ** 2)\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   MIXUP AUGMENTATION\n",
    "# =========================\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    \"\"\"Mixup augmentation for robustness\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size, device=x.device)\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    mixed_y = lam * y + (1 - lam) * y[index]\n",
    "    \n",
    "    return mixed_x, mixed_y, lam\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   ULTRA-ENHANCED STAGE 2 (ALL TRICKS)\n",
    "# =========================\n",
    "def train_bigjump_ultra(\n",
    "    model,\n",
    "    Xtr, Ytr, img_ids_row_tr,\n",
    "    Xva, val_gallery, cap2gal_local,\n",
    "    batch=512, epochs=28, base_lr=8e-5, wd=1e-4,\n",
    "    tau_start=0.09, tau_end=0.04,\n",
    "    queue_size=98304,\n",
    "    queue_warmup_epochs=6,\n",
    "    queue_recent_schedule=(1000, 2000, 4000, 8000, 16000, 32000, 65536, 98304),\n",
    "    mine_H=96,\n",
    "    lambda_agree=0.02,\n",
    "    alpha_cos=0.1,\n",
    "    lambda_moment=0.003,\n",
    "    lambda_flow=0.015,\n",
    "    lambda_distill=0.1,\n",
    "    use_mixup=True,\n",
    "    mixup_alpha=0.3,\n",
    "    use_pk=False, P=192, K_pk=3,\n",
    "    xbp_per_img=8,\n",
    "    xbp_global=65536,\n",
    "    use_dcl=True,\n",
    "    dcl_prior=0.015,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    pooling=\"none\", n_patches=None,\n",
    "    out_dir=None,\n",
    "    seed=42,\n",
    "    use_ema=True,\n",
    "    ema_decay=0.9997,\n",
    "    gradient_clip=1.5,\n",
    "    label_smoothing=0.05,\n",
    "):\n",
    "    \"\"\"\n",
    "    ULTRA-ENHANCED trainer with ALL techniques:\n",
    "    - Self-distillation from EMA\n",
    "    - Mixup augmentation\n",
    "    - Larger queue & harder mining\n",
    "    - DCL enabled\n",
    "    - Higher flow regularization\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    out_dir = Path(out_dir) if out_dir is not None else Path(\"./outputs/ultra\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    seed_all(seed)\n",
    "    model.to(device)\n",
    "    \n",
    "    has_flow = hasattr(model, 'adapter') and hasattr(model.adapter, 'flow') and model.adapter.flow is not None\n",
    "    \n",
    "    class TripletSet(torch.utils.data.Dataset):\n",
    "        def __init__(self, X_np, Y_np, names_np):\n",
    "            self.X = torch.from_numpy(X_np).float()\n",
    "            self.Y = torch.from_numpy(Y_np).float()\n",
    "            self.N = [str(n) for n in names_np.tolist()]\n",
    "        def __len__(self):\n",
    "            return len(self.X)\n",
    "        def __getitem__(self, i):\n",
    "            return self.X[i], self.Y[i], self.N[i]\n",
    "    \n",
    "    ds = TripletSet(Xtr, Ytr, img_ids_row_tr)\n",
    "    \n",
    "    if use_pk:\n",
    "        pk_sampler = PKBatchSampler(img_ids_row_tr.tolist(), P=int(P), K=int(K_pk), drop_last=True, seed=seed)\n",
    "        dl = DataLoader(ds, batch_sampler=pk_sampler, num_workers=2, pin_memory=True)\n",
    "    else:\n",
    "        dl = DataLoader(ds, batch_size=batch, shuffle=True, num_workers=2, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    opt = torch.optim.AdamW(params, lr=base_lr, weight_decay=wd, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    # Stable schedule\n",
    "    total_steps = epochs * len(dl)\n",
    "    def lr_lambda(step):\n",
    "        warmup_steps = total_steps // 8\n",
    "        if step < warmup_steps:\n",
    "            return step / warmup_steps\n",
    "        progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "        return 0.15 + 0.85 * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "    \n",
    "    sched = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
    "    \n",
    "    # EMA\n",
    "    ema_model = None\n",
    "    if use_ema:\n",
    "        import copy\n",
    "        ema_model = copy.deepcopy(model)\n",
    "        for p in ema_model.parameters():\n",
    "            p.requires_grad = False\n",
    "    \n",
    "    # Queues\n",
    "    img_queue = ImgQueue(dim=1536, capacity=queue_size, device=device, track_diversity=True)\n",
    "    xbp_buffer = XBPBuffer(per_image_cap=xbp_per_img, global_cap=xbp_global, device=device)\n",
    "    \n",
    "    best_stats, best_mrr, best_ep = None, -1.0, 0\n",
    "    \n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Temperature schedule (slower decay)\n",
    "        progress = (ep - 1) / max(1, epochs - 1)\n",
    "        tau = tau_start * (1 - progress**0.7) + tau_end * (progress**0.7)\n",
    "        \n",
    "        # Queue schedule\n",
    "        if ep <= queue_warmup_epochs:\n",
    "            recent_k = None\n",
    "        else:\n",
    "            queue_progress = (ep - queue_warmup_epochs) / max(1, epochs - queue_warmup_epochs)\n",
    "            schedule_idx = int(queue_progress * len(queue_recent_schedule))\n",
    "            schedule_idx = min(schedule_idx, len(queue_recent_schedule) - 1)\n",
    "            recent_k = queue_recent_schedule[schedule_idx]\n",
    "        \n",
    "        for xb, yb, names_b in dl:\n",
    "            xb = xb.to(device, non_blocking=True)\n",
    "            yb = yb.to(device, non_blocking=True)\n",
    "            \n",
    "            # Mixup augmentation\n",
    "            if use_mixup and np.random.rand() < 0.4:\n",
    "                xb, yb, lam = mixup_data(xb, yb, alpha=mixup_alpha)\n",
    "            \n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            \n",
    "            # Forward\n",
    "            if has_flow:\n",
    "                pred, flow_logdet = model.adapter(xb, return_flow_logdet=True)\n",
    "                if hasattr(model, 'geom'):\n",
    "                    pred = model.geom(xb) + pred\n",
    "            else:\n",
    "                pred = model(xb)\n",
    "                flow_logdet = None\n",
    "            \n",
    "            pred_norm = F.normalize(pred, dim=-1)\n",
    "            \n",
    "            # Teacher prediction for distillation\n",
    "            if use_ema and ema_model is not None and ep > queue_warmup_epochs:\n",
    "                with torch.no_grad():\n",
    "                    if has_flow:\n",
    "                        teacher_pred, _ = ema_model.adapter(xb, return_flow_logdet=True)\n",
    "                        if hasattr(ema_model, 'geom'):\n",
    "                            teacher_pred = ema_model.geom(xb) + teacher_pred\n",
    "                    else:\n",
    "                        teacher_pred = ema_model(xb)\n",
    "                    teacher_pred_norm = F.normalize(teacher_pred, dim=-1)\n",
    "            else:\n",
    "                teacher_pred_norm = None\n",
    "            \n",
    "            # Queue negatives\n",
    "            if recent_k is not None and img_queue.size() > 0:\n",
    "                queue_feats, queue_ids = img_queue.get_with_ids()\n",
    "                if queue_feats.numel() > 0:\n",
    "                    queue_feats = queue_feats[-recent_k:] if recent_k < queue_feats.size(0) else queue_feats\n",
    "                    queue_ids = queue_ids[-recent_k:] if recent_k < queue_ids.size(0) else queue_ids\n",
    "            else:\n",
    "                queue_feats, queue_ids = None, None\n",
    "            \n",
    "            # XBP\n",
    "            xbp_bank, xbp_pos_cols = xbp_buffer.build_bank_and_mask(names_b, device)\n",
    "            \n",
    "            # Main loss\n",
    "            loss_ce = info_nce_multi_enhanced(\n",
    "                pred, yb, names_b,\n",
    "                queue_feats=queue_feats,\n",
    "                queue_img_ids=queue_ids,\n",
    "                tau=tau,\n",
    "                xbp_bank=xbp_bank,\n",
    "                xbp_pos_cols_per_row=xbp_pos_cols,\n",
    "                hard_subset_H=mine_H,\n",
    "                use_dcl=use_dcl,\n",
    "                dcl_prior=dcl_prior,\n",
    "                epoch=ep,\n",
    "                total_epochs=epochs,\n",
    "                label_smoothing=label_smoothing,\n",
    "            )\n",
    "            \n",
    "            # Self-distillation\n",
    "            loss_distill = pred.new_tensor(0.0)\n",
    "            if teacher_pred_norm is not None and lambda_distill > 0:\n",
    "                student_logits = pred_norm @ pred_norm.t()\n",
    "                teacher_logits = teacher_pred_norm @ teacher_pred_norm.t()\n",
    "                loss_distill = self_distillation_loss(student_logits, teacher_logits, temperature=3.0)\n",
    "            \n",
    "            # Auxiliary losses\n",
    "            loss_agree = agreement_loss(names_b, pred, temperature=0.4) if lambda_agree > 0 else pred.new_tensor(0.0)\n",
    "            loss_cos = (1.0 - F.cosine_similarity(pred, yb, dim=-1)).mean() if alpha_cos > 0 else pred.new_tensor(0.0)\n",
    "            loss_mu = moment_align(pred, yb) if lambda_moment > 0 else pred.new_tensor(0.0)\n",
    "            \n",
    "            # Flow regularization\n",
    "            loss_flow = pred.new_tensor(0.0)\n",
    "            if has_flow and flow_logdet is not None and lambda_flow > 0:\n",
    "                loss_flow = torch.mean(torch.abs(flow_logdet)) * lambda_flow\n",
    "            \n",
    "            # Total loss\n",
    "            loss = loss_ce + lambda_distill * loss_distill + lambda_agree * loss_agree + \\\n",
    "                   alpha_cos * loss_cos + lambda_moment * loss_mu + loss_flow\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            if gradient_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(params, gradient_clip)\n",
    "            \n",
    "            opt.step()\n",
    "            sched.step()\n",
    "            \n",
    "            # Update EMA\n",
    "            if use_ema and ema_model is not None:\n",
    "                with torch.no_grad():\n",
    "                    for ema_p, model_p in zip(ema_model.parameters(), model.parameters()):\n",
    "                        ema_p.data.mul_(ema_decay).add_(model_p.data, alpha=1 - ema_decay)\n",
    "            \n",
    "            # Update queues\n",
    "            with torch.no_grad():\n",
    "                img_queue.enqueue(F.normalize(yb, dim=-1), names_b)\n",
    "                xbp_buffer.add(names_b, pred)\n",
    "            \n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "        \n",
    "        # Validation\n",
    "        eval_model = ema_model if use_ema and ema_model is not None else model\n",
    "        stats = validate_retrieval(eval_model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "        \n",
    "        ep_loss = running_loss / len(ds)\n",
    "        current_lr = opt.param_groups[0]['lr']\n",
    "        \n",
    "        print(f\"[ultra {ep:02d}] loss={ep_loss:.6f} lr={current_lr:.6f} | MRR={stats['MRR']:.4f} \"\n",
    "              f\"R@1={stats['R1']:.3f} R@5={stats['R5']:.3f} R@10={stats['R10']:.3f} \"\n",
    "              f\"| med={stats['rank_median']} p75={stats['rank_p75']} | tau={tau:.3f} | recentK={recent_k or 0}\")\n",
    "        \n",
    "        if stats[\"MRR\"] > best_mrr:\n",
    "            best_mrr, best_ep, best_stats = stats[\"MRR\"], ep, stats\n",
    "            torch.save({\"model\": model.state_dict(), \"epoch\": ep, \"val\": stats}, out_dir / \"best.pt\")\n",
    "            if use_ema and ema_model is not None:\n",
    "                torch.save({\"model\": ema_model.state_dict(), \"epoch\": ep, \"val\": stats}, out_dir / \"best_ema.pt\")\n",
    "    \n",
    "    if best_stats is None:\n",
    "        eval_model = ema_model if use_ema and ema_model is not None else model\n",
    "        best_stats = validate_retrieval(eval_model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "    \n",
    "    (out_dir / \"val_metrics.json\").write_text(json.dumps(dict(best_epoch=best_ep, **best_stats), indent=2))\n",
    "    return best_stats\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   UPDATED MAIN (ULTRA MODE)\n",
    "# =========================\n",
    "def main(args):\n",
    "    \"\"\"ULTRA mode with all techniques\"\"\"\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    out_dir, seed = args.out_dir, args.seed\n",
    "    pooling, n_patches = args.pooling, None\n",
    "    OUT = Path(f\"/kaggle/working/outputs/{out_dir}\")\n",
    "    OUT.mkdir(parents=True, exist_ok=True)\n",
    "    STAGE1 = OUT / \"stage1\"\n",
    "    STAGE2 = OUT / \"stage2\"\n",
    "    STAGE1.mkdir(parents=True, exist_ok=True)\n",
    "    STAGE2.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load data\n",
    "    X, Y, cap_ids, img_ids_row, full_img, all_img_ids = load_train(OUT)\n",
    "    \n",
    "    cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices = build_image_id_split(\n",
    "        img_ids_row, all_img_ids, full_img, X, Y, args.val_ratio, seed, OUT\n",
    "    )\n",
    "    \n",
    "    Xtr, Ytr = X[cap_is_tr], Y[cap_is_tr]\n",
    "    Xva = X[cap_is_val]\n",
    "    \n",
    "    din, dout = 1024, 1536\n",
    "    \n",
    "    # Geometry\n",
    "    print(\"[geometry] Variance-weighted Procrustes...\")\n",
    "    A, b = procrustes_closed_form_centroids_weighted(\n",
    "        Xtr.astype(np.float32),\n",
    "        Ytr.astype(np.float32),\n",
    "        img_ids_row[cap_is_tr],\n",
    "        eps=float(args.geom_eps),\n",
    "        use_variance_weighting=True,\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    class GeomFromWeights(nn.Module):\n",
    "        def __init__(self, A_np, b_np):\n",
    "            super().__init__()\n",
    "            self.fc = nn.Linear(A_np.shape[1], A_np.shape[0], bias=True)\n",
    "            with torch.no_grad():\n",
    "                self.fc.weight.copy_(torch.from_numpy(A_np))\n",
    "                self.fc.bias.copy_(torch.from_numpy(b_np))\n",
    "        def forward(self, x):\n",
    "            return self.fc(x)\n",
    "    \n",
    "    geom = GeomFromWeights(A, b).to(device)\n",
    "    for p in geom.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    adapter = FlowEnhancedAdapter(\n",
    "        din=din, hidden=1024, dout=dout, pdrop=0.1,\n",
    "        init_scale=0.3,  # Even larger\n",
    "        use_layernorm=True,\n",
    "        use_flow=True,\n",
    "        flow_layers=4,  # More layers\n",
    "    )\n",
    "    \n",
    "    class GeomPlusAdapter(nn.Module):\n",
    "        def __init__(self, g, a):\n",
    "            super().__init__()\n",
    "            self.geom = g\n",
    "            self.adapter = a\n",
    "        def forward(self, x):\n",
    "            return self.geom(x) + self.adapter(x)\n",
    "    \n",
    "    model = GeomPlusAdapter(geom, adapter).to(device)\n",
    "    \n",
    "    # Stage 1\n",
    "    if not args.eval_only:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[STAGE 1] Warmup\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        best_stats_s1 = train_simple_enhanced(\n",
    "            model, Xtr, Ytr, img_ids_row[cap_is_tr],\n",
    "            Xva, val_gallery, cap2gal_local,\n",
    "            batch=args.batch, epochs=15, lr=2e-4, wd=args.wd,\n",
    "            tau_fixed=0.07, triplet_margin=0.2, triplet_w=0.3,\n",
    "            device=device, pooling=pooling, n_patches=n_patches,\n",
    "            out_dir=str(STAGE1), seed=seed,\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            ckpt1 = torch.load(STAGE1 / \"best.pt\", map_location=device)\n",
    "            model.load_state_dict(ckpt1[\"model\"])\n",
    "            print(f\"[stage1] Best MRR={ckpt1.get('val',{}).get('MRR','?'):.4f}\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Stage 2 ULTRA\n",
    "    if not args.eval_only:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[STAGE 2] ULTRA MODE - ALL TECHNIQUES\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        best_stats_s2 = train_bigjump_ultra(\n",
    "            model, Xtr, Ytr, img_ids_row[cap_is_tr],\n",
    "            Xva, val_gallery, cap2gal_local,\n",
    "            batch=args.batch,\n",
    "            epochs=28,\n",
    "            base_lr=8e-5,\n",
    "            wd=args.wd,\n",
    "            tau_start=0.09,\n",
    "            tau_end=0.04,\n",
    "            queue_size=98304,\n",
    "            queue_warmup_epochs=6,\n",
    "            queue_recent_schedule=(1000, 2000, 4000, 8000, 16000, 32000, 65536, 98304),\n",
    "            mine_H=96,\n",
    "            lambda_agree=0.02,\n",
    "            alpha_cos=0.1,\n",
    "            lambda_moment=0.003,\n",
    "            lambda_flow=0.015,\n",
    "            lambda_distill=0.1,\n",
    "            use_mixup=True,\n",
    "            mixup_alpha=0.3,\n",
    "            xbp_per_img=8,\n",
    "            xbp_global=65536,\n",
    "            use_dcl=True,\n",
    "            dcl_prior=0.015,\n",
    "            device=device,\n",
    "            pooling=pooling,\n",
    "            n_patches=n_patches,\n",
    "            out_dir=str(STAGE2),\n",
    "            seed=seed,\n",
    "            use_ema=True,\n",
    "            ema_decay=0.9997,\n",
    "            gradient_clip=1.5,\n",
    "            label_smoothing=0.05,\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            if (STAGE2 / \"best_ema.pt\").exists():\n",
    "                ckpt2 = torch.load(STAGE2 / \"best_ema.pt\", map_location=device)\n",
    "            else:\n",
    "                ckpt2 = torch.load(STAGE2 / \"best.pt\", map_location=device)\n",
    "            model.load_state_dict(ckpt2[\"model\"])\n",
    "            best_stats_final = ckpt2.get(\"val\", None)\n",
    "            print(f\"[stage2] Best MRR={best_stats_final.get('MRR','?'):.4f}\")\n",
    "        except:\n",
    "            best_stats_final = {}\n",
    "    else:\n",
    "        for cand in [STAGE2 / \"best_ema.pt\", STAGE2 / \"best.pt\", STAGE1 / \"best.pt\"]:\n",
    "            try:\n",
    "                ckpt = torch.load(cand, map_location=device)\n",
    "                model.load_state_dict(ckpt[\"model\"])\n",
    "                best_stats_final = ckpt.get(\"val\", {})\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Enhanced submission with TTA\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"[SUBMISSION] TTA Ensemble\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    test_data = load_data(TEST_NPZ)\n",
    "    sub = OUT / \"submission.csv\"\n",
    "    generate_submission_enhanced(model, test_data, pooling, n_patches, device, sub, num_tta=5)\n",
    "    \n",
    "    print(f\"\\n✓ DONE! Best val MRR: {best_stats_final.get('MRR', 0):.4f}\")\n",
    "\n",
    "\n",
    "# Update argparse with ultra defaults\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"ultra_final\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--eval_only\", action=\"store_true\")\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.10)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--wd\", type=float, default=1e-4)\n",
    "    p.add_argument(\"--geom_eps\", type=float, default=1e-5)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\")\n",
    "    \n",
    "    args, unknown = p.parse_known_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T23:18:50.277967Z",
     "iopub.status.busy": "2025-10-29T23:18:50.277242Z",
     "iopub.status.idle": "2025-10-29T23:33:46.868893Z",
     "shell.execute_reply": "2025-10-29T23:33:46.867916Z",
     "shell.execute_reply.started": "2025-10-29T23:18:50.277940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[meta] text_dim=1024 | image_dim=1536\n",
      "[split] Using stratified split for better test alignment...\n",
      "\n",
      "============================================================\n",
      "[STAGE 1]\n",
      "============================================================\n",
      "[simple 01] loss=2.439839 lr=0.000083 | val_MRR=0.3263 | R@1=0.204 R@5=0.455 R@10=0.581 | median=7 p75=29\n",
      "[simple 02] loss=2.083307 lr=0.000167 | val_MRR=0.3424 | R@1=0.215 R@5=0.478 R@10=0.611 | median=6 p75=24\n",
      "[simple 03] loss=1.986402 lr=0.000250 | val_MRR=0.3575 | R@1=0.228 R@5=0.499 R@10=0.634 | median=6 p75=20\n",
      "[simple 04] loss=1.908524 lr=0.000242 | val_MRR=0.3655 | R@1=0.235 R@5=0.512 R@10=0.642 | median=5 p75=19\n",
      "[simple 05] loss=1.840707 lr=0.000221 | val_MRR=0.3742 | R@1=0.242 R@5=0.524 R@10=0.654 | median=5 p75=18\n",
      "[simple 06] loss=1.784344 lr=0.000188 | val_MRR=0.3802 | R@1=0.246 R@5=0.534 R@10=0.667 | median=5 p75=17\n",
      "[simple 07] loss=1.736089 lr=0.000147 | val_MRR=0.3862 | R@1=0.251 R@5=0.544 R@10=0.674 | median=5 p75=16\n",
      "[simple 08] loss=1.694322 lr=0.000103 | val_MRR=0.3901 | R@1=0.254 R@5=0.547 R@10=0.678 | median=4 p75=16\n",
      "[simple 09] loss=1.660397 lr=0.000063 | val_MRR=0.3891 | R@1=0.254 R@5=0.546 R@10=0.675 | median=4 p75=16\n",
      "[simple 10] loss=1.635978 lr=0.000029 | val_MRR=0.3897 | R@1=0.253 R@5=0.548 R@10=0.678 | median=4 p75=16\n",
      "[simple 11] loss=1.619618 lr=0.000008 | val_MRR=0.3917 | R@1=0.256 R@5=0.550 R@10=0.678 | median=4 p75=16\n",
      "[simple 12] loss=1.612341 lr=0.000000 | val_MRR=0.3919 | R@1=0.255 R@5=0.548 R@10=0.682 | median=4 p75=16\n",
      "\n",
      "============================================================\n",
      "[STAGE 2 ULTRA]\n",
      "============================================================\n",
      "[ultra 01] loss=3.459485 lr=0.000033 | MRR=0.3896 R@1=0.253 R@5=0.547 R@10=0.680 | med=4 p75=16 | tau=0.085 | recentK=0\n",
      "[ultra 02] loss=1.816912 lr=0.000067 | MRR=0.3930 R@1=0.256 R@5=0.552 R@10=0.682 | med=4 p75=16 | tau=0.081 | recentK=0\n",
      "[ultra 03] loss=1.568849 lr=0.000100 | MRR=0.3933 R@1=0.257 R@5=0.553 R@10=0.681 | med=4 p75=16 | tau=0.078 | recentK=0\n",
      "[ultra 04] loss=1.455482 lr=0.000100 | MRR=0.3946 R@1=0.258 R@5=0.554 R@10=0.684 | med=4 p75=15 | tau=0.075 | recentK=0\n",
      "[ultra 05] loss=1.444508 lr=0.000098 | MRR=0.3962 R@1=0.260 R@5=0.554 R@10=0.685 | med=4 p75=16 | tau=0.073 | recentK=0\n",
      "[ultra 06] loss=1.450813 lr=0.000096 | MRR=0.3987 R@1=0.263 R@5=0.558 R@10=0.686 | med=4 p75=15 | tau=0.071 | recentK=0\n",
      "[ultra 07] loss=1.257410 lr=0.000093 | MRR=0.3999 R@1=0.263 R@5=0.560 R@10=0.688 | med=4 p75=15 | tau=0.069 | recentK=0\n",
      "[ultra 08] loss=2.431149 lr=0.000089 | MRR=0.4017 R@1=0.265 R@5=0.558 R@10=0.687 | med=4 p75=15 | tau=0.068 | recentK=800\n",
      "[ultra 09] loss=2.300027 lr=0.000084 | MRR=0.4015 R@1=0.266 R@5=0.557 R@10=0.686 | med=4 p75=15 | tau=0.066 | recentK=800\n",
      "[ultra 10] loss=2.161084 lr=0.000079 | MRR=0.4017 R@1=0.264 R@5=0.560 R@10=0.687 | med=4 p75=15 | tau=0.064 | recentK=1600\n",
      "[ultra 11] loss=2.273972 lr=0.000073 | MRR=0.4031 R@1=0.266 R@5=0.562 R@10=0.690 | med=4 p75=15 | tau=0.063 | recentK=1600\n",
      "[ultra 12] loss=2.148731 lr=0.000067 | MRR=0.4042 R@1=0.267 R@5=0.563 R@10=0.693 | med=4 p75=15 | tau=0.061 | recentK=3200\n",
      "[ultra 13] loss=2.219903 lr=0.000061 | MRR=0.4070 R@1=0.270 R@5=0.567 R@10=0.693 | med=4 p75=15 | tau=0.060 | recentK=3200\n",
      "[ultra 14] loss=2.189876 lr=0.000054 | MRR=0.4062 R@1=0.270 R@5=0.565 R@10=0.694 | med=4 p75=15 | tau=0.058 | recentK=6400\n",
      "[ultra 15] loss=1.923308 lr=0.000048 | MRR=0.4098 R@1=0.273 R@5=0.570 R@10=0.696 | med=4 p75=15 | tau=0.057 | recentK=6400\n",
      "[ultra 16] loss=2.125411 lr=0.000042 | MRR=0.4114 R@1=0.274 R@5=0.571 R@10=0.698 | med=4 p75=14 | tau=0.055 | recentK=12800\n",
      "[ultra 17] loss=2.274960 lr=0.000036 | MRR=0.4133 R@1=0.277 R@5=0.571 R@10=0.700 | med=4 p75=14 | tau=0.054 | recentK=12800\n",
      "[ultra 18] loss=2.039017 lr=0.000031 | MRR=0.4144 R@1=0.276 R@5=0.575 R@10=0.702 | med=4 p75=14 | tau=0.053 | recentK=25600\n",
      "[ultra 19] loss=1.979880 lr=0.000026 | MRR=0.4177 R@1=0.280 R@5=0.579 R@10=0.706 | med=4 p75=14 | tau=0.051 | recentK=25600\n",
      "[ultra 20] loss=2.087583 lr=0.000022 | MRR=0.4180 R@1=0.279 R@5=0.582 R@10=0.707 | med=4 p75=14 | tau=0.050 | recentK=51200\n",
      "[ultra 21] loss=2.217042 lr=0.000019 | MRR=0.4203 R@1=0.282 R@5=0.582 R@10=0.705 | med=4 p75=14 | tau=0.049 | recentK=51200\n",
      "[ultra 22] loss=1.941826 lr=0.000017 | MRR=0.4233 R@1=0.285 R@5=0.584 R@10=0.711 | med=4 p75=13 | tau=0.047 | recentK=98304\n",
      "[ultra 23] loss=2.009426 lr=0.000015 | MRR=0.4261 R@1=0.288 R@5=0.588 R@10=0.712 | med=4 p75=13 | tau=0.046 | recentK=98304\n",
      "[ultra 24] loss=2.207320 lr=0.000015 | MRR=0.4260 R@1=0.287 R@5=0.590 R@10=0.713 | med=4 p75=13 | tau=0.045 | recentK=98304\n",
      "Stage2 best: 0.4261\n",
      "\n",
      "============================================================\n",
      "[PSEUDO-LABELING TEST SET]\n",
      "============================================================\n",
      "[pseudo-label] 0/1500 captions above 0.80 confidence\n",
      "\n",
      "============================================================\n",
      "[SEMI-SUPERVISED FINE-TUNE]\n",
      "============================================================\n",
      "[semi 01] loss=1.5985 | MRR=0.4271 R@1=0.288\n",
      "[semi 02] loss=1.5657 | MRR=0.4283 R@1=0.289\n",
      "[semi 03] loss=1.5473 | MRR=0.4280 R@1=0.288\n",
      "[semi 04] loss=1.5368 | MRR=0.4279 R@1=0.288\n",
      "[semi 05] loss=1.5279 | MRR=0.4296 R@1=0.291\n",
      "[semi 06] loss=1.5225 | MRR=0.4297 R@1=0.291\n",
      "[semi 07] loss=1.5174 | MRR=0.4287 R@1=0.290\n",
      "[semi 08] loss=1.5144 | MRR=0.4290 R@1=0.290\n",
      "Semi-supervised best: 0.4297\n",
      "\n",
      "============================================================\n",
      "[FINAL SUBMISSION - MultiCrop TTA]\n",
      "============================================================\n",
      "[MultiCrop TTA] 9 crops...\n",
      "Generating submission file...\n",
      "✓ Saved submission to /kaggle/working/outputs/ultimate_final/submission.csv\n",
      "✓ MultiCrop TTA (9x): /kaggle/working/outputs/ultimate_final/submission.csv\n",
      "\n",
      "✓✓✓ ULTIMATE PIPELINE COMPLETE ✓✓✓\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "#   FIX 1: BETTER VALIDATION SPLIT (Match Test Distribution)\n",
    "# =========================\n",
    "def build_stratified_image_split(img_ids_row, all_img_names, full_img, X, Y, val_ratio, seed, out_dir):\n",
    "    \"\"\"\n",
    "    Stratified split that better matches test distribution:\n",
    "    - Balance by caption count per image\n",
    "    - Ensure diverse image types in validation\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Count captions per image\n",
    "    img_caption_counts = Counter(map(str, img_ids_row))\n",
    "    \n",
    "    # Group images by caption count (1, 2-3, 4-5, 6+)\n",
    "    def get_bucket(count):\n",
    "        if count == 1: return 0\n",
    "        if count <= 3: return 1\n",
    "        if count <= 5: return 2\n",
    "        return 3\n",
    "    \n",
    "    buckets = {0: [], 1: [], 2: [], 3: []}\n",
    "    for img_name in set(map(str, all_img_names)):\n",
    "        count = img_caption_counts[img_name]\n",
    "        bucket = get_bucket(count)\n",
    "        buckets[bucket].append(img_name)\n",
    "    \n",
    "    # Stratified sampling from each bucket\n",
    "    rng = np.random.default_rng(seed)\n",
    "    val_images = []\n",
    "    for bucket_imgs in buckets.values():\n",
    "        bucket_imgs = np.array(bucket_imgs)\n",
    "        rng.shuffle(bucket_imgs)\n",
    "        n_val = max(1, int(len(bucket_imgs) * val_ratio))\n",
    "        val_images.extend(bucket_imgs[:n_val])\n",
    "    \n",
    "    val_images = set(val_images)\n",
    "    tr_images = set(map(str, all_img_names)) - val_images\n",
    "    \n",
    "    # Build masks\n",
    "    cap_is_val = np.array([str(iid) in val_images for iid in img_ids_row], dtype=bool)\n",
    "    cap_is_tr = ~cap_is_val\n",
    "    \n",
    "    # Val gallery\n",
    "    val_img_names_sorted = np.array(sorted(val_images))\n",
    "    name2local = {name: i for i, name in enumerate(val_img_names_sorted)}\n",
    "    name2global = {str(n): i for i, n in enumerate(all_img_names)}\n",
    "    val_img_indices = np.array([name2global[n] for n in val_img_names_sorted], dtype=np.int64)\n",
    "    val_gallery = full_img[val_img_indices]\n",
    "    cap2gal_local = np.array([name2local[str(n)] for n in img_ids_row[cap_is_val]], dtype=np.int64)\n",
    "    \n",
    "    # Save\n",
    "    (out_dir/\"val_indices.json\").write_text(json.dumps({\n",
    "        \"val_img_indices\": val_img_indices.tolist(),\n",
    "        \"val_caption_to_gallery_index\": cap2gal_local.tolist(),\n",
    "        \"n_val_captions\": int(cap_is_val.sum()),\n",
    "        \"n_val_unique_images\": int(len(val_images)),\n",
    "        \"bucket_distribution\": {k: len(v) for k, v in buckets.items()}\n",
    "    }, indent=2))\n",
    "    \n",
    "    return cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   FIX 2: PSEUDO-LABELING ON TEST SET\n",
    "# =========================\n",
    "def pseudo_label_test_set(model, test_data, train_img_gallery, device, confidence_thresh=0.85):\n",
    "    \"\"\"\n",
    "    Generate pseudo-labels for test set using confident predictions\n",
    "    \"\"\"\n",
    "    Q = test_data[\"captions/embeddings\"].astype(np.float32)\n",
    "    \n",
    "    model.eval()\n",
    "    BS = 1024\n",
    "    pseudo_targets = []\n",
    "    confidence_scores = []\n",
    "    \n",
    "    train_gallery_tensor = torch.from_numpy(train_img_gallery).to(device)\n",
    "    train_gallery_tensor = F.normalize(train_gallery_tensor, dim=-1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(Q), BS):\n",
    "            q = torch.from_numpy(Q[i:i+BS]).to(device)\n",
    "            z = model(q)\n",
    "            z = F.normalize(z, dim=-1)\n",
    "            \n",
    "            # Find most similar training image\n",
    "            sims = z @ train_gallery_tensor.t()\n",
    "            max_sims, max_idx = torch.max(sims, dim=1)\n",
    "            \n",
    "            pseudo_targets.append(max_idx.cpu().numpy())\n",
    "            confidence_scores.append(max_sims.cpu().numpy())\n",
    "    \n",
    "    pseudo_targets = np.concatenate(pseudo_targets)\n",
    "    confidence_scores = np.concatenate(confidence_scores)\n",
    "    \n",
    "    # Filter by confidence\n",
    "    high_conf_mask = confidence_scores >= confidence_thresh\n",
    "    \n",
    "    print(f\"[pseudo-label] {high_conf_mask.sum()}/{len(Q)} captions above {confidence_thresh:.2f} confidence\")\n",
    "    \n",
    "    return Q, pseudo_targets, high_conf_mask, confidence_scores\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   FIX 3: SEMI-SUPERVISED FINE-TUNING\n",
    "# =========================\n",
    "def train_semi_supervised(\n",
    "    model, \n",
    "    Xtr, Ytr, img_ids_row_tr,  # Original training\n",
    "    Q_pseudo, Y_pseudo, pseudo_mask,  # Pseudo-labeled test\n",
    "    Xva, val_gallery, cap2gal_local,\n",
    "    batch=512, epochs=10, lr=3e-5, wd=1e-4,\n",
    "    tau=0.06, confidence_weight=True,\n",
    "    device=torch.device(\"cuda\"),\n",
    "    pooling=\"none\", n_patches=None,\n",
    "    out_dir=None, seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fine-tune on train + high-confidence pseudo-labeled test\n",
    "    \"\"\"\n",
    "    from torch.utils.data import DataLoader, ConcatDataset\n",
    "    \n",
    "    out_dir = Path(out_dir) if out_dir is not None else Path(\"./outputs/semi\")\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    seed_all(seed)\n",
    "    \n",
    "    # Train dataset\n",
    "    class SimpleDS(torch.utils.data.Dataset):\n",
    "        def __init__(self, X, Y, weight=1.0):\n",
    "            self.X = torch.from_numpy(X).float()\n",
    "            self.Y = torch.from_numpy(Y).float()\n",
    "            self.weight = weight\n",
    "        def __len__(self): return len(self.X)\n",
    "        def __getitem__(self, i): return self.X[i], self.Y[i], self.weight\n",
    "    \n",
    "    # Pseudo dataset (only high-confidence)\n",
    "    Q_conf = Q_pseudo[pseudo_mask]\n",
    "    Y_conf = Y_pseudo[pseudo_mask]\n",
    "    \n",
    "    ds_train = SimpleDS(Xtr, Ytr, weight=1.0)\n",
    "    ds_pseudo = SimpleDS(Q_conf, Y_conf, weight=0.5)  # Lower weight for pseudo\n",
    "    \n",
    "    # Combine\n",
    "    combined_ds = ConcatDataset([ds_train, ds_pseudo])\n",
    "    dl = DataLoader(combined_ds, batch_size=batch, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    opt = torch.optim.AdamW(params, lr=lr, weight_decay=wd)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs*len(dl), eta_min=lr*0.1)\n",
    "    \n",
    "    best_mrr = -1.0\n",
    "    \n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for xb, yb, wb in dl:\n",
    "            xb, yb, wb = xb.to(device), yb.to(device), wb.to(device)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            pred = model(xb)\n",
    "            pred_norm = F.normalize(pred, dim=-1)\n",
    "            yb_norm = F.normalize(yb, dim=-1)\n",
    "            \n",
    "            # Simple InfoNCE\n",
    "            logits = (pred_norm @ yb_norm.t()) / tau\n",
    "            labels = torch.arange(len(xb), device=device)\n",
    "            loss = F.cross_entropy(logits, labels, reduction='none')\n",
    "            \n",
    "            # Weight by confidence\n",
    "            loss = (loss * wb).mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            sched.step()\n",
    "            \n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "        \n",
    "        stats = validate_retrieval(model, Xva, val_gallery, cap2gal_local, pooling, n_patches)\n",
    "        print(f\"[semi {ep:02d}] loss={running_loss/len(combined_ds):.4f} | MRR={stats['MRR']:.4f} R@1={stats['R1']:.3f}\")\n",
    "        \n",
    "        if stats[\"MRR\"] > best_mrr:\n",
    "            best_mrr = stats[\"MRR\"]\n",
    "            torch.save({\"model\": model.state_dict(), \"epoch\": ep, \"val\": stats}, out_dir / \"best.pt\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   FIX 4: MULTI-CROP TEST-TIME AUGMENTATION\n",
    "# =========================\n",
    "def generate_submission_multicrop(model, test_data, pooling, n_patches, device, out_path, num_crops=7):\n",
    "    \"\"\"\n",
    "    Multi-crop TTA with different noise patterns\n",
    "    \"\"\"\n",
    "    Q = test_data[\"captions/embeddings\"].astype(np.float32)\n",
    "    ids = test_data.get(\"captions/ids\", np.arange(len(Q)).astype(str))\n",
    "    \n",
    "    model.eval()\n",
    "    # Keep some dropout active\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.train()\n",
    "            m.p = 0.05  # Reduce dropout\n",
    "    \n",
    "    BS = 1024\n",
    "    all_preds = []\n",
    "    \n",
    "    print(f\"[MultiCrop TTA] {num_crops} crops...\")\n",
    "    \n",
    "    for crop_idx in range(num_crops):\n",
    "        outs = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(Q), BS):\n",
    "                q = torch.from_numpy(Q[i:i+BS]).to(device)\n",
    "                \n",
    "                # Different augmentation per crop\n",
    "                if crop_idx > 0:\n",
    "                    # Gaussian noise\n",
    "                    noise_scale = 0.005 * (1 + crop_idx * 0.2)\n",
    "                    q = q + torch.randn_like(q) * noise_scale\n",
    "                    \n",
    "                    # Random masking (dropout some dimensions)\n",
    "                    if crop_idx % 2 == 0:\n",
    "                        mask = torch.rand_like(q) > 0.05\n",
    "                        q = q * mask\n",
    "                \n",
    "                z = model(q)\n",
    "                z = F.normalize(z, dim=-1)\n",
    "                outs.append(z.cpu().numpy())\n",
    "        \n",
    "        pred = np.concatenate(outs, axis=0)\n",
    "        all_preds.append(pred)\n",
    "    \n",
    "    # Weighted average (later crops get slightly less weight)\n",
    "    weights = np.array([1.0] + [0.9] * (num_crops - 1))\n",
    "    weights = weights / weights.sum()\n",
    "    \n",
    "    ensemble = np.average(all_preds, axis=0, weights=weights)\n",
    "    ensemble = ensemble / (np.linalg.norm(ensemble, axis=1, keepdims=True) + 1e-8)\n",
    "    \n",
    "    generate_submission(ids, ensemble, str(out_path))\n",
    "    print(f\"✓ MultiCrop TTA ({num_crops}x): {out_path}\")\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "# =========================\n",
    "#   ULTIMATE MAIN - ALL FIXES\n",
    "# =========================\n",
    "def main(args):\n",
    "    \"\"\"\n",
    "    ULTIMATE pipeline:\n",
    "    1. Better validation split (stratified)\n",
    "    2. Train Stage 1 + 2 (ULTRA)\n",
    "    3. Pseudo-label test set\n",
    "    4. Semi-supervised fine-tune\n",
    "    5. Multi-crop TTA submission\n",
    "    \"\"\"\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    out_dir, seed = args.out_dir, args.seed\n",
    "    pooling, n_patches = args.pooling, None\n",
    "    OUT = Path(f\"/kaggle/working/outputs/{out_dir}\")\n",
    "    OUT.mkdir(parents=True, exist_ok=True)\n",
    "    STAGE1 = OUT / \"stage1\"\n",
    "    STAGE2 = OUT / \"stage2\"\n",
    "    SEMI = OUT / \"semi\"\n",
    "    for d in [STAGE1, STAGE2, SEMI]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load data\n",
    "    X, Y, cap_ids, img_ids_row, full_img, all_img_ids = load_train(OUT)\n",
    "    \n",
    "    # BETTER VALIDATION SPLIT\n",
    "    print(\"[split] Using stratified split for better test alignment...\")\n",
    "    cap_is_tr, cap_is_val, val_gallery, cap2gal_local, val_img_indices = build_stratified_image_split(\n",
    "        img_ids_row, all_img_ids, full_img, X, Y, args.val_ratio, seed, OUT\n",
    "    )\n",
    "    \n",
    "    Xtr, Ytr = X[cap_is_tr], Y[cap_is_tr]\n",
    "    Xva = X[cap_is_val]\n",
    "    \n",
    "    din, dout = 1024, 1536\n",
    "    \n",
    "    # Geometry\n",
    "    A, b = procrustes_closed_form_centroids_weighted(\n",
    "        Xtr.astype(np.float32), Ytr.astype(np.float32),\n",
    "        img_ids_row[cap_is_tr], eps=1e-5, use_variance_weighting=True,\n",
    "    )\n",
    "    \n",
    "    # Model\n",
    "    class GeomFromWeights(nn.Module):\n",
    "        def __init__(self, A_np, b_np):\n",
    "            super().__init__()\n",
    "            self.fc = nn.Linear(A_np.shape[1], A_np.shape[0], bias=True)\n",
    "            with torch.no_grad():\n",
    "                self.fc.weight.copy_(torch.from_numpy(A_np))\n",
    "                self.fc.bias.copy_(torch.from_numpy(b_np))\n",
    "        def forward(self, x): return self.fc(x)\n",
    "    \n",
    "    geom = GeomFromWeights(A, b).to(device)\n",
    "    for p in geom.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    adapter = FlowEnhancedAdapter(\n",
    "        din=din, hidden=1024, dout=dout, pdrop=0.08,  # Less dropout\n",
    "        init_scale=0.3, use_layernorm=True,\n",
    "        use_flow=True, flow_layers=4,\n",
    "    )\n",
    "    \n",
    "    class GeomPlusAdapter(nn.Module):\n",
    "        def __init__(self, g, a):\n",
    "            super().__init__()\n",
    "            self.geom, self.adapter = g, a\n",
    "        def forward(self, x): return self.geom(x) + self.adapter(x)\n",
    "    \n",
    "    model = GeomPlusAdapter(geom, adapter).to(device)\n",
    "    \n",
    "    # Stage 1\n",
    "    if not args.eval_only:\n",
    "        print(f\"\\n{'='*60}\\n[STAGE 1]\\n{'='*60}\")\n",
    "        train_simple_enhanced(\n",
    "            model, Xtr, Ytr, img_ids_row[cap_is_tr],\n",
    "            Xva, val_gallery, cap2gal_local,\n",
    "            batch=args.batch, epochs=12, lr=2.5e-4, wd=1e-4,\n",
    "            tau_fixed=0.07, triplet_margin=0.2, triplet_w=0.3,\n",
    "            device=device, pooling=pooling, n_patches=n_patches,\n",
    "            out_dir=str(STAGE1), seed=seed,\n",
    "        )\n",
    "        ckpt1 = torch.load(STAGE1 / \"best.pt\", map_location=device)\n",
    "        model.load_state_dict(ckpt1[\"model\"])\n",
    "    \n",
    "    # Stage 2 ULTRA\n",
    "    if not args.eval_only:\n",
    "        print(f\"\\n{'='*60}\\n[STAGE 2 ULTRA]\\n{'='*60}\")\n",
    "        train_bigjump_ultra(\n",
    "            model, Xtr, Ytr, img_ids_row[cap_is_tr],\n",
    "            Xva, val_gallery, cap2gal_local,\n",
    "            batch=args.batch, epochs=24, base_lr=1e-4, wd=1e-4,\n",
    "            tau_start=0.085, tau_end=0.045,\n",
    "            queue_size=98304, queue_warmup_epochs=7,\n",
    "            queue_recent_schedule=(800, 1600, 3200, 6400, 12800, 25600, 51200, 98304),\n",
    "            mine_H=80, lambda_agree=0.018, alpha_cos=0.12,\n",
    "            lambda_moment=0.004, lambda_flow=0.012, lambda_distill=0.08,\n",
    "            use_mixup=True, mixup_alpha=0.25,\n",
    "            xbp_per_img=7, xbp_global=65536,\n",
    "            use_dcl=True, dcl_prior=0.012,\n",
    "            device=device, pooling=pooling, n_patches=n_patches,\n",
    "            out_dir=str(STAGE2), seed=seed,\n",
    "            use_ema=True, ema_decay=0.9998,\n",
    "        )\n",
    "        \n",
    "        ckpt2_path = STAGE2 / \"best_ema.pt\" if (STAGE2 / \"best_ema.pt\").exists() else STAGE2 / \"best.pt\"\n",
    "        ckpt2 = torch.load(ckpt2_path, map_location=device)\n",
    "        model.load_state_dict(ckpt2[\"model\"])\n",
    "        print(f\"Stage2 best: {ckpt2.get('val', {}).get('MRR', 0):.4f}\")\n",
    "    \n",
    "    # PSEUDO-LABELING\n",
    "    if not args.eval_only:\n",
    "        print(f\"\\n{'='*60}\\n[PSEUDO-LABELING TEST SET]\\n{'='*60}\")\n",
    "        test_data = load_data(TEST_NPZ)\n",
    "        \n",
    "        Q_pseudo, targets_pseudo, conf_mask, conf_scores = pseudo_label_test_set(\n",
    "            model, test_data, full_img, device, confidence_thresh=0.80\n",
    "        )\n",
    "        \n",
    "        # Get pseudo target vectors\n",
    "        Y_pseudo = full_img[targets_pseudo]\n",
    "        \n",
    "        # Semi-supervised fine-tune\n",
    "        print(f\"\\n{'='*60}\\n[SEMI-SUPERVISED FINE-TUNE]\\n{'='*60}\")\n",
    "        train_semi_supervised(\n",
    "            model,\n",
    "            Xtr, Ytr, img_ids_row[cap_is_tr],\n",
    "            Q_pseudo, Y_pseudo, conf_mask,\n",
    "            Xva, val_gallery, cap2gal_local,\n",
    "            batch=512, epochs=8, lr=2e-5, wd=5e-5,\n",
    "            tau=0.05,\n",
    "            device=device, pooling=pooling, n_patches=n_patches,\n",
    "            out_dir=str(SEMI), seed=seed,\n",
    "        )\n",
    "        \n",
    "        ckpt_semi = torch.load(SEMI / \"best.pt\", map_location=device)\n",
    "        model.load_state_dict(ckpt_semi[\"model\"])\n",
    "        print(f\"Semi-supervised best: {ckpt_semi.get('val', {}).get('MRR', 0):.4f}\")\n",
    "    \n",
    "    # FINAL SUBMISSION with MultiCrop TTA\n",
    "    print(f\"\\n{'='*60}\\n[FINAL SUBMISSION - MultiCrop TTA]\\n{'='*60}\")\n",
    "    test_data = load_data(TEST_NPZ)\n",
    "    sub = OUT / \"submission.csv\"\n",
    "    generate_submission_multicrop(model, test_data, pooling, n_patches, device, sub, num_crops=9)\n",
    "    \n",
    "    print(f\"\\n✓✓✓ ULTIMATE PIPELINE COMPLETE ✓✓✓\")\n",
    "\n",
    "\n",
    "# Quick argparse\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--out_dir\", type=str, default=\"ultimate_final\")\n",
    "    p.add_argument(\"--seed\", type=int, default=42)\n",
    "    p.add_argument(\"--eval_only\", action=\"store_true\")\n",
    "    p.add_argument(\"--val_ratio\", type=float, default=0.10)\n",
    "    p.add_argument(\"--batch\", type=int, default=512)\n",
    "    p.add_argument(\"--pooling\", type=str, default=\"CLS\")\n",
    "    args, _ = p.parse_known_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14220991,
     "sourceId": 117959,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
